{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    Her ilce icin esit sayida veri yok. Bu sayilar ilce_tarih_sayilari degiskeninde tutulu.\\n\\n    Yapilmasi gerekenler:\\n        - Bu grafiklere trend tahmin gibi şeyler uygulamaya calis\\n        - Farkli grafikler cikartmaya calis.\\n        - ML.\\n        - Hava kosullarindan iyi, orta, kotu, cok kotu gibi bir bilgi cikartmaya calis. Belki burada yapay zeka\\n        kullanabilirsin. orda bir formül belirlemek lazim ona göre siniflandirilir.\\n\\n    Sorunlar:\\n        - Weather'da degerler gunluk ortalama seklinde. 1 saat firtina olsa sonra tum gun yagmur yagmasa o gunun\\n        ortalamasi az olur. Burada farkli bir yontem bul.\\n        Gunluk maks min alinabilir\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -1-) Notlar\n",
    "\"\"\"\n",
    "    Her ilce icin esit sayida veri yok. Bu sayilar ilce_tarih_sayilari degiskeninde tutulu.\n",
    "\n",
    "    Yapilmasi gerekenler:\n",
    "        - Bu grafiklere trend tahmin gibi şeyler uygulamaya calis\n",
    "        - Farkli grafikler cikartmaya calis.\n",
    "        - ML.\n",
    "        - Hava kosullarindan iyi, orta, kotu, cok kotu gibi bir bilgi cikartmaya calis. Belki burada yapay zeka\n",
    "        kullanabilirsin. orda bir formül belirlemek lazim ona göre siniflandirilir.\n",
    "\n",
    "    Sorunlar:\n",
    "        - Weather'da degerler gunluk ortalama seklinde. 1 saat firtina olsa sonra tum gun yagmur yagmasa o gunun\n",
    "        ortalamasi az olur. Burada farkli bir yontem bul.\n",
    "        Gunluk maks min alinabilir\n",
    "\"\"\"\n",
    "# 1-) read and preproccess train.csv\n",
    "# 2-) extract ilce and keep preprocessing train.csv\n",
    "# 3-) read and preprocess weather.csv\n",
    "# 4-) read and preprocess holidays.csv\n",
    "# 5-) merge the train data and holidays, return a new dict called dict_holiday\n",
    "# 6-) merge the dict_holiday and weather, return merged_all which contains all of the required columns\n",
    "# 7-) Her ilcenin Bildirimli+Bildirimsiz kesinti grafigi\n",
    "# 8-) Her ilcenin Bildirimsiz+MHO(EWMA) kesinti grafiği\n",
    "# 9-) ort. yagis miktarlari icin ort. kesinti sayisi grafigi (cok mantikli ve gerekli degil)\n",
    "# 10-) test icin birlestirme islemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-) Import required moduls and libraries\n",
    "\n",
    "# bildirimisiz_sum tahmin edilecek\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import math\n",
    "import os\n",
    "from unidecode import unidecode # to convert Turkish characters to English\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose as sm\n",
    "import statsmodels.api as sa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Flatten \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Activation\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tarih         ilce  bildirimsiz_sum  bildirimli_sum\n",
      "19236 2021-01-01  izmir-konak                9               0\n",
      "19237 2021-01-02  izmir-konak               20               0\n",
      "19238 2021-01-03  izmir-konak                7               1\n",
      "19239 2021-01-04  izmir-konak               16               1\n",
      "19240 2021-01-05  izmir-konak                3               0\n",
      "...          ...          ...              ...             ...\n",
      "20355 2024-01-27  izmir-konak               12               3\n",
      "20356 2024-01-28  izmir-konak               13               1\n",
      "20357 2024-01-29  izmir-konak               22               0\n",
      "20358 2024-01-30  izmir-konak               28               1\n",
      "20359 2024-01-31  izmir-konak               16               0\n",
      "\n",
      "[1124 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1-) read and preproccess train.csv\n",
    "train = pd.read_csv(\"./train.csv\", low_memory=False) # 46.944 satir, 4 kolon\n",
    "\n",
    "#print(train[\"tarih\"]) # 1.098 farkli tarih var, 47 farkli ilce var\n",
    "\n",
    "tarihler = []\n",
    "for i in train[\"tarih\"]:\n",
    "    tarihler.append(datetime.strptime(i, \"%Y-%m-%d\"))\n",
    "train[\"tarih\"] = tarihler\n",
    "\n",
    "# print(train.dtypes)\n",
    "\n",
    "dict :{str, pd.DataFrame} = {} # key olarak ilceleri, value olarak o ilcenin verisi (1096 gun) df olarak tutar\n",
    "for label, group in train.groupby(\"ilce\"):\n",
    "    dict[label] = group\n",
    "print(dict[\"izmir-konak\"])\n",
    "ilceler = (list(dict.keys()))\n",
    "#print(dict.keys()) # keys olarak her ilceyi, values olarak o ilcelerin bulundugu satirlari icerir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'izmir-aliaga': 1106, 'izmir-balcova': 698, 'izmir-bayindir': 1105, 'izmir-bayrakli': 1086, 'izmir-bergama': 1120, 'izmir-beydag': 673, 'izmir-bornova': 1124, 'izmir-buca': 1115, 'izmir-cesme': 1125, 'izmir-cigli': 1071, 'izmir-dikili': 1119, 'izmir-foca': 1086, 'izmir-gaziemir': 920, 'izmir-guzelbahce': 856, 'izmir-karabaglar': 1100, 'izmir-karaburun': 1089, 'izmir-karsiyaka': 1085, 'izmir-kemalpasa': 1118, 'izmir-kinik': 914, 'izmir-kiraz': 1097, 'izmir-konak': 1124, 'izmir-menderes': 1125, 'izmir-menemen': 1119, 'izmir-narlidere': 783, 'izmir-odemis': 1124, 'izmir-seferihisar': 1111, 'izmir-selcuk': 872, 'izmir-tire': 1107, 'izmir-torbali': 1124, 'izmir-urla': 1122, 'manisa-ahmetli': 622, 'manisa-akhisar': 1126, 'manisa-alasehir': 1119, 'manisa-demirci': 938, 'manisa-golmarmara': 566, 'manisa-gordes': 1059, 'manisa-kirkagac': 950, 'manisa-koprubasi': 805, 'manisa-kula': 1039, 'manisa-salihli': 1126, 'manisa-sarigol': 1027, 'manisa-saruhanli': 1105, 'manisa-sehzadeler': 1123, 'manisa-selendi': 993, 'manisa-soma': 1086, 'manisa-turgutlu': 1121, 'manisa-yunusemre': 1125}\n"
     ]
    }
   ],
   "source": [
    "# 2-) extract ilce and keep preprocessing train.csv\n",
    "\"\"\"\n",
    "for label in dict.keys(): # her ilce icin bildirimsiz ve bildirimli olarak grafiklerini cikart\n",
    "    print(dict[label][\"bildirimsiz_sum\"])\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.bar(dict[label][\"tarih\"],dict[label][\"bildirimsiz_sum\"])\n",
    "    plt.title(label)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.bar(dict[\"izmir-konak\"][\"tarih\"],dict[\"izmir-konak\"][\"bildirimsiz_sum\"])\n",
    "plt.title(label)\n",
    "plt.margins(0.01)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# ilce tarih sayilarini al hepsinde esit veri yok\n",
    "ilce_tarih_sayilari = {}\n",
    "for name in dict.keys():\n",
    "    ilce_tarih_sayilari[name] = len(list(dict[name][\"tarih\"].to_dict().values()))\n",
    "\n",
    "print(ilce_tarih_sayilari)\n",
    "for name in dict.keys():\n",
    "    dict[name].set_index(\"tarih\", inplace=True)\n",
    "\n",
    "# train.set_index(\"tarih\", inplace=True) # train'in tarih kolonunu indexe cevir\n",
    "# print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'lat', 'lon', 't_2m:C', 'effective_cloud_cover:p',\n",
      "       'global_rad:W', 'relative_humidity_2m:p', 'wind_dir_10m:d',\n",
      "       'wind_speed_10m:ms', 'prob_precip_1h:p', 't_apparent:C', 'name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 3-) read and preprocess weather.csv  (runtime: 9s)\n",
    "\n",
    "weather = pd.read_csv(\"./weather.csv\", low_memory=False)\n",
    "print(weather.columns) # onemli kolonlar: date, t_apparent:C (hissedilen sicaklik), wind_dir_10m:d (ruzgar yonu),\n",
    "# wind_speed_10m:ms (ruzgar hizi), prob_precip_1h:p (yagis), ilce\n",
    "\n",
    "# ilceleri ayir\n",
    "ilce_weather = {} # keys olarak ilceleri, values olarak o ilcelerin saatlik (1165 gun) hava durumlarini tutar\n",
    "for label, group in weather.groupby(\"name\"):\n",
    "    ilce_weather[label.lower()] = group\n",
    "\n",
    "# tarihleri tarih formatina cevir\n",
    "#print(ilce_weather[\"izmir-konak\"].dtypes)\n",
    "for name in ilce_weather.keys():\n",
    "\n",
    "    tarihler = [] # duzenli tarihleri burada tut\n",
    "    for date in ilce_weather[name][\"date\"]:\n",
    "        tarihler.append(datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    ilce_weather[name][\"date\"] = tarihler # duzenli tarihleri date kolonuna ata\n",
    "    ilce_weather[name].set_index(\"date\", inplace=True) # tarihleri indexe cevir\n",
    "    ilce_weather[name][\"tarih\"] = ilce_weather[name].index # tarih kolonunu tekrardan olustur\n",
    "\n",
    "ilce_weather_day = {} # ilce hava durumu verilerini gunluk olarak tut\n",
    "for name in ilce_weather.keys():\n",
    "    ilce_weather_day[name] = ilce_weather[name].resample(\"D\").mean(numeric_only=True)# index'teki tarihleri gune cevir\n",
    "    ilce_weather_day[name][\"tarih\"] = ilce_weather_day[name].index\n",
    "    \n",
    "#print(ilce_weather[\"izmir-konak\"][\"tarih\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-01\n",
      "lat                               float64\n",
      "lon                               float64\n",
      "t_2m:C                            float64\n",
      "effective_cloud_cover:p           float64\n",
      "global_rad:W                      float64\n",
      "relative_humidity_2m:p            float64\n",
      "wind_dir_10m:d                    float64\n",
      "wind_speed_10m:ms                 float64\n",
      "prob_precip_1h:p                  float64\n",
      "t_apparent:C                      float64\n",
      "name                               object\n",
      "tarih                      datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 3.1-) her ilcenin hava durumunda her gununu ayri ayri df lere koyup dict te tut (runtime: 3m 45s)\n",
    "\n",
    "ilce_weather_detailed = {} \n",
    "# {izmir-konak: {2021-01-01 : df , 2021-01-02 : df ,...} , manisa-akhisar: {2021-01-01 : df , 2021-01-02 : df ,...} }\n",
    "\n",
    "\n",
    "for name in ilce_weather.keys():\n",
    "    ilce_weather_detailed[name] = {}\n",
    "    for label,group in ilce_weather[name].groupby(\"date\"):\n",
    "\n",
    "        gun = label.strftime('%Y-%m-%d')\n",
    "        if gun in ilce_weather_detailed[name]:\n",
    "            ilce_weather_detailed[name][gun] = pd.concat([ilce_weather_detailed[name][gun], group], ignore_index=True)\n",
    "        else:\n",
    "            ilce_weather_detailed[name][gun] = group.copy()\n",
    "\n",
    "\n",
    "print((list(ilce_weather_detailed[\"izmir-konak\"].keys())[0]))\n",
    "print((list(ilce_weather_detailed[\"izmir-konak\"].values())[0]).dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                lat      lon  Sicaklik_max  Sicaklik_min  Bulutluluk_max  \\\n",
      "2021-01-01  38.4177  27.1283          15.3          11.9            90.0   \n",
      "2021-01-02  38.4177  27.1283          17.4          11.0            57.5   \n",
      "2021-01-03  38.4177  27.1283          15.3          11.2            99.8   \n",
      "2021-01-04  38.4177  27.1283          17.7          10.5            97.4   \n",
      "2021-01-05  38.4177  27.1283          16.7          11.2            99.7   \n",
      "\n",
      "            Bulutluluk_min  Guneslilik_max  Guneslilik_min  Bagil_nem_max  \\\n",
      "2021-01-01            28.2           275.4             0.0           93.5   \n",
      "2021-01-02            10.4           374.0             0.0           90.9   \n",
      "2021-01-03            12.4           151.9             0.0           84.6   \n",
      "2021-01-04             9.2           357.0             0.0           85.6   \n",
      "2021-01-05             5.4           362.3             0.0          100.0   \n",
      "\n",
      "            Bagil_nem_min  ...         Ilce      Tarih   Sicaklik  Bulutluluk  \\\n",
      "2021-01-01           82.3  ...  izmir-konak 2021-01-01  13.095833   59.033333   \n",
      "2021-01-02           64.9  ...  izmir-konak 2021-01-02  13.379167   29.912500   \n",
      "2021-01-03           72.9  ...  izmir-konak 2021-01-03  12.587500   69.916667   \n",
      "2021-01-04           55.8  ...  izmir-konak 2021-01-04  13.783333   45.604167   \n",
      "2021-01-05           59.6  ...  izmir-konak 2021-01-05  13.895833   35.670833   \n",
      "\n",
      "            Guneslilik  Bagil_nem  Ruzgar_yonu  Ruzgar_hizi      Yagis  \\\n",
      "2021-01-01   65.212500  87.962500   137.558333     3.129167   1.137500   \n",
      "2021-01-02   91.225000  80.720833   134.820833     2.158333   1.000000   \n",
      "2021-01-03   34.962500  79.725000   142.316667     2.300000   2.520833   \n",
      "2021-01-04   79.400000  71.362500   138.641667     3.979167   1.000000   \n",
      "2021-01-05   92.666667  82.308333   161.516667     2.591667  12.279167   \n",
      "\n",
      "           Hissedilen_sicaklik  \n",
      "2021-01-01           13.891667  \n",
      "2021-01-02           14.250000  \n",
      "2021-01-03           12.937500  \n",
      "2021-01-04           13.787500  \n",
      "2021-01-05           14.850000  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3.2-) 3.1'de ayrilan ilce gunlerini simdi her gun icin degerlerin min max'ini bulup ilce df'lerini tekrar olustur\n",
    "\n",
    "# runtime: 1m 4s\n",
    "weather_last = {} # key olarak ilceleri, value olarak da o ilcelerin hava durumu degerlerini min-max ile tutar\n",
    "for name in ilce_weather_detailed.keys():\n",
    "    weather_last[name] = pd.DataFrame()\n",
    "\n",
    "    for date, day_df in ilce_weather_detailed[name].items():\n",
    "        \n",
    "        # max min leri al\n",
    "        max_values = day_df.max()\n",
    "        min_values = day_df.min()\n",
    "\n",
    "        # satır oluştur\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Tarih\": [datetime.strptime(date, \"%Y-%m-%d\")],\n",
    "            \"lat\": [day_df[\"lat\"].iloc[0]],\n",
    "            \"lon\": [day_df[\"lon\"].iloc[0]],\n",
    "            \"Sicaklik_max\": [max_values[\"t_2m:C\"]],\n",
    "            \"Sicaklik_min\": [min_values[\"t_2m:C\"]],\n",
    "            \"Bulutluluk_max\": [max_values.get(\"effective_cloud_cover:p\", None)],\n",
    "            \"Bulutluluk_min\": [min_values.get(\"effective_cloud_cover:p\", None)],\n",
    "            \"Guneslilik_max\": [max_values.get(\"global_rad:W\", None)],  \n",
    "            \"Guneslilik_min\": [min_values.get(\"global_rad:W\", None)],  \n",
    "            \"Bagil_nem_max\": [max_values.get(\"relative_humidity_2m:p\", None)],\n",
    "            \"Bagil_nem_min\": [min_values.get(\"relative_humidity_2m:p\", None)],\n",
    "            \"Ruzgar_yonu_max\": [max_values.get(\"wind_dir_10m:d\", None)],\n",
    "            \"Ruzgar_yonu_min\": [min_values.get(\"wind_dir_10m:d\", None)],\n",
    "            \"Ruzgar_hizi_max\": [max_values.get(\"wind_speed_10m:ms\", None)],\n",
    "            \"Ruzgar_hizi_min\": [max_values.get(\"wind_speed_10m:ms\", None)],\n",
    "            \"Yagis_max\": [max_values.get(\"prob_precip_1h:p\", None)],\n",
    "            \"Yagis_min\": [min_values.get(\"prob_precip_1h:p\", None)],\n",
    "            \"Hissedilen_sicaklik_max\": [max_values.get(\"t_apparent:C\", None)],\n",
    "            \"Hissedilen_sicaklik_min\": [min_values.get(\"t_apparent:C\", None)],\n",
    "            \"Ilce\": [day_df[\"name\"].iloc[0].lower()]  # Ilce ekle\n",
    "        })\n",
    "\n",
    "        # her gunu o ilcenin df ine ekle\n",
    "        weather_last[name] = pd.concat([weather_last[name], new_row], ignore_index=True)\n",
    "\n",
    "  \n",
    "new_column_names = {\n",
    "    \"lat\" : \"lat\", \"lot\" : \"lot\", \"Sicaklik_max\" : \"Sicaklik_max\", \"Sicaklik_min\" : \"Sicaklik_min\",\n",
    "    \"Bulutluluk_max\" : \"Bulutluluk_max\", \"Bulutluluk_min\" : \"Bulutluluk_min\", \"Guneslilik_max\" : \"Guneslilik_max\",\n",
    "    \"Guneslilik_min\" : \"Guneslilik_min\", \"Bagil_nem_max\" : \"Bagil_nem_max\", \"Bagil_nem_min\" : \"Bagil_nem_min\",\n",
    "    \"Ruzgar_yonu_max\" : \"Ruzgar_yonu_max\", \"Ruzgar_yonu_min\" : \"Ruzgar_yonu_min\", \"Ruzgar_hizi_max\" : \"Ruzgar_hizi_max\",\n",
    "    \"Ruzgar_hizi_min\" : \"Ruzgar_hizi_min\", \"Yagis_max\" : \"Yagis_max\", \"Yagis_min\" : \"Yagis_min\",\n",
    "    \"Hissedilen_sicaklik_max\" : \"Hissedilen_sicaklik_max\", \"Hissedilen_sicaklik_min\" : \"Hissedilen_sicaklik_min\",\n",
    "    \"Ilce\" : \"Ilce\", \"t_2m:C\" : \"Sicaklik\", \"effective_cloud_cover:p\" : \"Bulutluluk\", \"global_rad:W\" : \"Guneslilik\",\n",
    "    \"relative_humidity_2m:p\" : \"Bagil_nem\", \"wind_dir_10m:d\" : \"Ruzgar_yonu\", \"wind_speed_10m:ms\" : \"Ruzgar_hizi\",\n",
    "    \"prob_precip_1h:p\" : \"Yagis\", \"t_apparent:C\" : \"Hissedilen_sicaklik\", \"Tarih\" : \"Tarih\"\n",
    "}\n",
    "\n",
    "for name in weather_last.keys():\n",
    "    weather_last[name].set_index(\"Tarih\", inplace=True) # tarih kolonunu indexe ata\n",
    "    weather_last[name][\"Tarih\"] = weather_last[name].index # tarih kolonunu tekrardan olustur\n",
    "\n",
    "    weather_last[name] = pd.concat([weather_last[name], ilce_weather_day[name][[\"t_2m:C\",\"effective_cloud_cover:p\",\n",
    "    \"global_rad:W\", \"relative_humidity_2m:p\",\"wind_dir_10m:d\",\"wind_speed_10m:ms\",\"prob_precip_1h:p\",\n",
    "    \"t_apparent:C\"]]], axis=1) # mean leri ekle\n",
    "    \n",
    "    weather_last[name] = weather_last[name].rename(columns=new_column_names) # kolonlari tekrar isimlendir\n",
    "    \n",
    "\n",
    "print(weather_last[\"izmir-konak\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3-) K-means ile gunleri ozetleme\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "for name in weather_last.keys():\n",
    "\n",
    "    x = x = weather_last[name].drop(columns=[\"Ilce\",\"Tarih\"]).iloc[:, 3:].values\n",
    "    #print(x)\n",
    "    \"\"\"\n",
    "    wcss_list= []\n",
    "\n",
    "    for i in range(1, 11):  \n",
    "\n",
    "        kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 42)  \n",
    "\n",
    "        kmeans.fit(x)  \n",
    "\n",
    "        wcss_list.append(kmeans.inertia_) \n",
    "    \n",
    "    plt.plot(range(1, 11), wcss_list)  \n",
    "    plt.title('The Elobw Method Graph')  \n",
    "    plt.xlabel('Number of clusters(k)')  \n",
    "    plt.ylabel('wcss_list')  \n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    # k = 3 or 7\n",
    "    #training the K-means model on a dataset  \n",
    "\n",
    "    kmeans = KMeans(n_clusters=4, init='k-means++', random_state= 42)  \n",
    "\n",
    "    y_predict= kmeans.fit_predict(x)\n",
    "\n",
    "    # kolona ekle\n",
    "    weather_last[name][\"Ozet\"] = y_predict\n",
    "    #print(weather_last[name].head())\n",
    "    #visulaizing the clusters  \n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.scatter(x[y_predict == 0, 0], x[y_predict == 0, 1], s = 100, c = 'blue', label = 'Cluster 1') #for first cluster  \n",
    "    plt.scatter(x[y_predict == 1, 0], x[y_predict == 1, 1], s = 100, c = 'green', label = 'Cluster 2') #for second cluster  \n",
    "    plt.scatter(x[y_predict== 2, 0], x[y_predict == 2, 1], s = 100, c = 'red', label = 'Cluster 3') #for third cluster  \n",
    "    plt.scatter(x[y_predict == 3, 0], x[y_predict == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4') #for fourth cluster  \n",
    "    plt.scatter(x[y_predict == 4, 0], x[y_predict == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5') #for fifth cluster  \n",
    "    #plt.scatter(x[y_predict == 5, 0], x[y_predict == 5, 1], s = 100, c = 'black', label = 'Cluster 6') #for fifth cluster  \n",
    "    #plt.scatter(x[y_predict == 6, 0], x[y_predict == 6, 1], s = 100, c = 'gray', label = 'Cluster 7') #for fifth cluster  \n",
    "    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroid')\n",
    "    plt.title('Clusters of customers')  \n",
    "    plt.xlabel('Annual Income (k$)')  \n",
    "    plt.ylabel('Spending Score (1-100)')  \n",
    "    plt.legend()  \n",
    "    plt.show()  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tatil Adı'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 4-) read and preprocess holidays.csv\n",
    "\n",
    "holiday = pd.read_csv(\"./holidays.csv\", low_memory=False)\n",
    "\n",
    "# print(holiday.head())\n",
    "\n",
    "holiday[\"tarih\"] = holiday['Yıl'].astype(str) + '-' + holiday['Ay'].astype(str) + '-' + holiday['Gün'].astype(str)\n",
    "holiday['tarih'] = pd.to_datetime(holiday['tarih'], format='%Y-%m-%d')\n",
    "holiday.set_index(\"tarih\", inplace=True)\n",
    "holiday = holiday.drop(columns=[\"Yıl\", \"Ay\", \"Gün\"])\n",
    "\n",
    "print(holiday.columns) # index olarak tarihi (YY-AA-GG), Bayram_Flag olarak da bayram ismini tutar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                tarih         ilce  bildirimsiz_sum  bildirimli_sum  \\\n",
      "tarih                                                                 \n",
      "2021-01-01 2021-01-01  izmir-konak                9               0   \n",
      "2021-01-02 2021-01-02  izmir-konak               20               0   \n",
      "2021-01-03 2021-01-03  izmir-konak                7               1   \n",
      "2021-01-04 2021-01-04  izmir-konak               16               1   \n",
      "2021-01-05 2021-01-05  izmir-konak                3               0   \n",
      "...               ...          ...              ...             ...   \n",
      "2024-01-27 2024-01-27  izmir-konak               12               3   \n",
      "2024-01-28 2024-01-28  izmir-konak               13               1   \n",
      "2024-01-29 2024-01-29  izmir-konak               22               0   \n",
      "2024-01-30 2024-01-30  izmir-konak               28               1   \n",
      "2024-01-31 2024-01-31  izmir-konak               16               0   \n",
      "\n",
      "                 Tatil Adı  \n",
      "tarih                       \n",
      "2021-01-01  New Year's Day  \n",
      "2021-01-02             NaN  \n",
      "2021-01-03             NaN  \n",
      "2021-01-04             NaN  \n",
      "2021-01-05             NaN  \n",
      "...                    ...  \n",
      "2024-01-27             NaN  \n",
      "2024-01-28             NaN  \n",
      "2024-01-29             NaN  \n",
      "2024-01-30             NaN  \n",
      "2024-01-31             NaN  \n",
      "\n",
      "[1124 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 5-) merge the train data and holidays, return a new dict called dict_holiday\n",
    "\n",
    "def merge_holiday(df1, df2=holiday):\n",
    "    merged_df = pd.merge(df1, df2[\"Tatil Adı\"], left_index=True, right_index=True, how=\"left\")\n",
    "    #df1[\"Bayramlar\"] = df2[\"Bayram_Flag\"]\n",
    "    return merged_df\n",
    "\n",
    "dict_holiday = {}\n",
    "for name in dict.keys():\n",
    "    dict_holiday[name] = merge_holiday(dict[name],holiday)\n",
    "    dict_holiday[name]['tarih'] = dict_holiday[name].index\n",
    "    dict_holiday[name] = dict_holiday[name].reindex(columns=[\"tarih\", \"ilce\", \"bildirimsiz_sum\", \"bildirimli_sum\", \"Tatil Adı\"])\n",
    "    \n",
    "print(dict_holiday[\"izmir-konak\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Tarih         Ilce  Bildirimsiz_sum  Bildirimli_sum  \\\n",
      "tarih                                                                 \n",
      "2021-01-01 2021-01-01  izmir-konak                9               0   \n",
      "2021-01-02 2021-01-02  izmir-konak               20               0   \n",
      "2021-01-03 2021-01-03  izmir-konak                7               1   \n",
      "2021-01-04 2021-01-04  izmir-konak               16               1   \n",
      "2021-01-05 2021-01-05  izmir-konak                3               0   \n",
      "\n",
      "               Bayram_Flag  Sicaklik_max  Sicaklik_min  Bagil_nem_max  \\\n",
      "tarih                                                                   \n",
      "2021-01-01  New Year's Day          15.3          11.9           93.5   \n",
      "2021-01-02             NaN          17.4          11.0           90.9   \n",
      "2021-01-03             NaN          15.3          11.2           84.6   \n",
      "2021-01-04             NaN          17.7          10.5           85.6   \n",
      "2021-01-05             NaN          16.7          11.2          100.0   \n",
      "\n",
      "            Bagil_nem_min  Ruzgar_hizi_max  Ruzgar_hizi_min  Yagis_max  \\\n",
      "tarih                                                                    \n",
      "2021-01-01           82.3              4.0              4.0        4.3   \n",
      "2021-01-02           64.9              3.3              3.3        1.0   \n",
      "2021-01-03           72.9              3.3              3.3       27.9   \n",
      "2021-01-04           55.8              6.6              6.6        1.0   \n",
      "2021-01-05           59.6              5.9              5.9       94.4   \n",
      "\n",
      "            Yagis_min   Sicaklik  Bagil_nem  Ruzgar_hizi      Yagis  Ozet  Gün  \n",
      "tarih                                                                           \n",
      "2021-01-01        1.0  13.095833  87.962500     3.129167   1.137500     2    1  \n",
      "2021-01-02        1.0  13.379167  80.720833     2.158333   1.000000     2    2  \n",
      "2021-01-03        1.0  12.587500  79.725000     2.300000   2.520833     2    3  \n",
      "2021-01-04        1.0  13.783333  71.362500     3.979167   1.000000     2    4  \n",
      "2021-01-05        1.0  13.895833  82.308333     2.591667  12.279167     2    5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okkes\\AppData\\Local\\Temp\\ipykernel_25084\\2656318892.py:35: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  merged_all_month[name] = merged_all[name].resample(\"M\").sum(numeric_only=True)\n"
     ]
    }
   ],
   "source": [
    "# 6-) merge the dict_holiday and weather, return merged_all which contains all of the required columns\n",
    "\n",
    "def merge_weather(df1, df2):\n",
    "    merged_df = pd.merge(df1, df2[[\"Sicaklik_max\", \"Sicaklik_min\",\"Bagil_nem_max\",\n",
    "    \"Bagil_nem_min\",\"Ruzgar_hizi_max\", \"Ruzgar_hizi_min\",\"Yagis_max\", \"Yagis_min\",\n",
    "    \"Sicaklik\",\"Bagil_nem\",\"Ruzgar_hizi\",\"Yagis\",\"Ozet\"]], left_index=True, right_index=True, how=\"left\")\n",
    "    return merged_df\n",
    "\n",
    "\"\"\" ekstra eklenebilecek kolonlar : (bunlari ustteki diger kolonarin arkasina ekleyebilirsin, ayni sekilde alttaki isimlendirmeye de eklemeyi unutma)\n",
    "\"Bulutluluk_max\", \"Bulutluluk_min\", \"Guneslilik_max\", \"Guneslilik_min\",\"Ruzgar_yonu_max\", \"Ruzgar_yonu_min\",\"Hissedilen_sicaklik_max\", \"Hissedilen_sicaklik_min\"\n",
    ",\"Bulutluluk\",\"Guneslilik\",\"Ruzgar_yonu\",\"Hissedilen_sicaklik\"\n",
    "\"\"\"\n",
    "merged_all = {} # key olarak tum ilceler, values olarak kesintiler, bayramlar, hava durumu verilerini (1096 gun) tutan df'i tutar\n",
    "for name in dict_holiday.keys():\n",
    "    merged_all[name] = merge_weather(dict_holiday[name], weather_last[name])\n",
    "\n",
    "    merged_all[name].columns = [\"Tarih\", \"Ilce\", \"Bildirimsiz_sum\", \"Bildirimli_sum\", # tekrar isimlendir\n",
    "    \"Bayram_Flag\", \"Sicaklik_max\", \"Sicaklik_min\",\"Bagil_nem_max\",\"Bagil_nem_min\",\n",
    "    \"Ruzgar_hizi_max\", \"Ruzgar_hizi_min\",\"Yagis_max\", \"Yagis_min\",\"Sicaklik\",\"Bagil_nem\",\"Ruzgar_hizi\",\"Yagis\",\"Ozet\"]\n",
    "    \n",
    "    merged_all[name]['Gün'] = range(1, len(merged_all[name]) + 1)\n",
    "\n",
    "print(merged_all[\"izmir-konak\"].head())\n",
    "\n",
    "all_in_one = pd.concat(merged_all.values(), ignore_index=True) # tum ilceleri birlestir\n",
    "#print(\"\\nall_in_one: \\n\\n\",all_in_one.dtypes)\n",
    "\n",
    "merged_all_week = {}\n",
    "for name in merged_all.keys():\n",
    "    merged_all_week[name] = merged_all[name].resample(\"W\").sum(numeric_only=True)\n",
    "#print(merged_all_week[\"izmir-konak\"])\n",
    "\n",
    "merged_all_month = {}\n",
    "for name in merged_all.keys():\n",
    "    merged_all_month[name] = merged_all[name].resample(\"M\").sum(numeric_only=True)\n",
    "#print(merged_all_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if not os.path.exists(\"graphs\"):\\n    os.makedirs(\"graphs\")\\n    print(\"images klasörü olustu\")\\nif not os.path.exists(\"./graphs/bildirimli_siz\"):\\n    os.makedirs(\"./graphs/bildirimli_siz\")\\n    print(\"bildirimli_siz klasoru olustu\")\\n\\n\\nfor name in merged_all_week.keys():\\n    plt.figure(figsize=(17,8))\\n    plt.plot(merged_all_week[name].index,merged_all_week[name][\"Bildirimsiz_sum\"], label=\"Bildirimsiz\")\\n    plt.plot(merged_all_week[name].index,merged_all_week[name][\"Bildirimli_sum\"], label=\"Bildirimli\")\\n    plt.xticks(rotation=90)\\n    plt.title(\"{} Bildirimli Bildirimsiz (Haftalik)\".format(name), fontweight=\"bold\", fontsize=15)\\n    plt.xlabel(\"Tarih\", fontsize=13)\\n    plt.ylabel(\"Kesinti Sayisi\", fontsize=13)\\n\\n    plt.margins(0.01)\\n    plt.legend()\\n    plt.grid()\\n    plt.subplots_adjust(bottom=0.15)\\n    plt.tight_layout()\\n    #plt.savefig(\"./graphs/bildirimli_siz/{}.png\".format(name))\\n    #plt.show()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7-) Her ilcenin Bildirimli+Bildirimsiz kesinti grafigi (runtime: 19s)\n",
    "\n",
    "\"\"\"if not os.path.exists(\"graphs\"):\n",
    "    os.makedirs(\"graphs\")\n",
    "    print(\"images klasörü olustu\")\n",
    "if not os.path.exists(\"./graphs/bildirimli_siz\"):\n",
    "    os.makedirs(\"./graphs/bildirimli_siz\")\n",
    "    print(\"bildirimli_siz klasoru olustu\")\n",
    "\n",
    "\n",
    "for name in merged_all_week.keys():\n",
    "    plt.figure(figsize=(17,8))\n",
    "    plt.plot(merged_all_week[name].index,merged_all_week[name][\"Bildirimsiz_sum\"], label=\"Bildirimsiz\")\n",
    "    plt.plot(merged_all_week[name].index,merged_all_week[name][\"Bildirimli_sum\"], label=\"Bildirimli\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"{} Bildirimli Bildirimsiz (Haftalik)\".format(name), fontweight=\"bold\", fontsize=15)\n",
    "    plt.xlabel(\"Tarih\", fontsize=13)\n",
    "    plt.ylabel(\"Kesinti Sayisi\", fontsize=13)\n",
    "\n",
    "    plt.margins(0.01)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"./graphs/bildirimli_siz/{}.png\".format(name))\n",
    "    #plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nayristirma2 = sm(merged_all_week[\"izmir-aliaga\"][\"Bildirimsiz_sum\"], model=\"mul\", period=4)\\n\\nanaliz = pd.concat([\\n    ayristirma2.observed,\\n    ayristirma2.trend,\\n    ayristirma2.seasonal,\\n    ayristirma2.observed/ayristirma2.seasonal # orijinal veri / S = T * E, regr. da üzerine tahmin yapılacak sey\\n], axis=1)\\nanaliz.columns = [\"Orijinal Gözlem\", \"Trend\", \"Mevsimsellik\", \"Mevsimsellik Düzeltme\"]\\n\\nindeks = np.arange(1,len(merged_all_week[\"izmir-aliaga\"].index) + 1)\\n\\n\\nX = sa.add_constant(indeks)\\nmodel = sa.OLS(analiz[\"Mevsimsellik Düzeltme\"], X)\\nsonuc = model.fit()\\nrsquared_value = sonuc.rsquared\\ny = pd.date_range(analiz.index[-1] + pd.DateOffset(weeks=4), periods=4,freq=\"W\") # 4 tane ekstra ay ekle\\n\\nyeni_satirlar = pd.DataFrame(index=y)\\nanaliz = pd.concat([analiz, yeni_satirlar])\\n\\n# not: bu degerleri ayarla\\nmev = [\\n    1.038656,\\n    0.973940,\\n    0.987404,\\n    1.038656\\n]\\n\\nnan_indices = analiz.index[analiz[\\'Mevsimsellik\\'].isna()]\\nfor i, index in enumerate(nan_indices):\\n    if i < len(mev):\\n        analiz.at[index, \\'Mevsimsellik\\'] = mev[i]\\n#print(analiz[\"Mevsimsellik\"])\\n\\ngirdi = np.arange(1,len(merged_all_week[\"izmir-aliaga\"].index) + 5)\\nregmodel = sonuc.predict(sa.add_constant(girdi))\\n\\nanaliz[\"Tahmin\"] = analiz[\"Mevsimsellik\"] * regmodel\\n\\n\\nprint(analiz.head())\\n\\nplt.text(analiz.index[0], max(analiz[\"Mevsimsellik Düzeltme\"]), \"R-squared value: {:.3f}\".format(rsquared_value), fontsize=10, verticalalignment=\\'top\\')\\n#plt.text(analiz.index[-1], max(analiz[\"Mevsimsellik Düzeltme\"]), \"R-squared value: {:.3f}\".format(rsquared_value), fontsize=10, verticalalignment=\\'top\\', horizontalalignment=\\'left\\')\\nplt.scatter(analiz.index, analiz[\"Mevsimsellik Düzeltme\"], label=\"Mevsimsellik Düzeltme\", color=\"blue\")\\n#plt.plot(analiz[\"Orijinal Gözlem\"], label=\"Orijinal Gözlem\", color=\"purple\")\\nplt.plot(analiz.index, analiz[\"Tahmin\"], label=\"Trend\", color=\"red\")\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8-) Her ilcenin Bildirimsiz+MHO(EWMA) kesinti grafiği (runtime: 18s)\n",
    "\n",
    "\"\"\"if not os.path.exists(\"graphs\"):\n",
    "    os.makedirs(\"graphs\")\n",
    "    print(\"images klasörü olustu\")\n",
    "if not os.path.exists(\"./graphs/bildirimsiz_detailed\"):\n",
    "    os.makedirs(\"./graphs/bildirimsiz_detailed\")\n",
    "    print(\"bildirimsiz_detailed klasoru olustu\")\n",
    "\n",
    "for name in merged_all_week.keys():\n",
    "\n",
    "    plt.figure(figsize=(17,8))\n",
    "    plt.plot(merged_all_week[name].index,merged_all_week[name][\"Bildirimsiz_sum\"], label=\"Bildirimsiz\")\n",
    "    plt.title(\"{} - Bildirimsiz (Haftalik)\".format(name), fontweight=\"bold\", fontsize=15)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Tarih\", fontsize=13)\n",
    "    plt.ylabel(\"Kesinti Sayisi\", fontsize=13)\n",
    "\n",
    "    window_size = 3  # Hareketli ortalama penceresi\n",
    "    merged_all_week[name]['Moving_Average'] = merged_all_week[name][\"Bildirimsiz_sum\"].rolling(window=window_size, center=True).mean()\n",
    "    #plt.plot(merged_all_week[name]['Moving_Average'], label=\"MHO\", color=\"black\")\n",
    "\n",
    "    ortalama = merged_all_week[name][\"Bildirimsiz_sum\"].mean()\n",
    "    plt.axhline(y=ortalama, color='orange', linestyle='--', label='Ortalama %{:.1f}'.format(ortalama),linewidth=2.2)\n",
    "    alpha = 0.2  # Yumuşatma parametresi \n",
    "    # formul : EMA_t = α × X_t + (1 - α) × EMA_{t-1}\n",
    "    merged_all_week[name]['EWMA'] = merged_all_week[name][\"Bildirimsiz_sum\"].ewm(alpha=alpha, adjust=False).mean()\n",
    "\n",
    "    plt.plot(merged_all_week[name]['EWMA'], label=\"EWMA\", color=\"red\", lw=2.9)\n",
    "\n",
    "\n",
    "    plt.margins(0.01)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"./graphs/bildirimsiz_detailed/{}.png\".format(name))\n",
    "    #plt.show()\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "ayristirma2 = sm(merged_all_week[\"izmir-aliaga\"][\"Bildirimsiz_sum\"], model=\"mul\", period=4)\n",
    "\n",
    "analiz = pd.concat([\n",
    "    ayristirma2.observed,\n",
    "    ayristirma2.trend,\n",
    "    ayristirma2.seasonal,\n",
    "    ayristirma2.observed/ayristirma2.seasonal # orijinal veri / S = T * E, regr. da üzerine tahmin yapılacak sey\n",
    "], axis=1)\n",
    "analiz.columns = [\"Orijinal Gözlem\", \"Trend\", \"Mevsimsellik\", \"Mevsimsellik Düzeltme\"]\n",
    "\n",
    "indeks = np.arange(1,len(merged_all_week[\"izmir-aliaga\"].index) + 1)\n",
    "\n",
    "\n",
    "X = sa.add_constant(indeks)\n",
    "model = sa.OLS(analiz[\"Mevsimsellik Düzeltme\"], X)\n",
    "sonuc = model.fit()\n",
    "rsquared_value = sonuc.rsquared\n",
    "y = pd.date_range(analiz.index[-1] + pd.DateOffset(weeks=4), periods=4,freq=\"W\") # 4 tane ekstra ay ekle\n",
    "\n",
    "yeni_satirlar = pd.DataFrame(index=y)\n",
    "analiz = pd.concat([analiz, yeni_satirlar])\n",
    "\n",
    "# not: bu degerleri ayarla\n",
    "mev = [\n",
    "    1.038656,\n",
    "    0.973940,\n",
    "    0.987404,\n",
    "    1.038656\n",
    "]\n",
    "\n",
    "nan_indices = analiz.index[analiz['Mevsimsellik'].isna()]\n",
    "for i, index in enumerate(nan_indices):\n",
    "    if i < len(mev):\n",
    "        analiz.at[index, 'Mevsimsellik'] = mev[i]\n",
    "#print(analiz[\"Mevsimsellik\"])\n",
    "\n",
    "girdi = np.arange(1,len(merged_all_week[\"izmir-aliaga\"].index) + 5)\n",
    "regmodel = sonuc.predict(sa.add_constant(girdi))\n",
    "\n",
    "analiz[\"Tahmin\"] = analiz[\"Mevsimsellik\"] * regmodel\n",
    "\n",
    "\n",
    "print(analiz.head())\n",
    "\n",
    "plt.text(analiz.index[0], max(analiz[\"Mevsimsellik Düzeltme\"]), \"R-squared value: {:.3f}\".format(rsquared_value), fontsize=10, verticalalignment='top')\n",
    "#plt.text(analiz.index[-1], max(analiz[\"Mevsimsellik Düzeltme\"]), \"R-squared value: {:.3f}\".format(rsquared_value), fontsize=10, verticalalignment='top', horizontalalignment='left')\n",
    "plt.scatter(analiz.index, analiz[\"Mevsimsellik Düzeltme\"], label=\"Mevsimsellik Düzeltme\", color=\"blue\")\n",
    "#plt.plot(analiz[\"Orijinal Gözlem\"], label=\"Orijinal Gözlem\", color=\"purple\")\n",
    "plt.plot(analiz.index, analiz[\"Tahmin\"], label=\"Trend\", color=\"red\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5.0: 30.0, 6.0: 26.285714285714285, 7.0: 34.170212765957444, 8.2: 31.0, 8.5: 36.0, 8.6: 34.0, 8.9: 37.0, 10.3: 26.0, 11.6: 26.0, 12.7: 35.0, 16.6: 37.0, 18.2: 44.0, 18.9: 28.0, 20.7: 35.0, 22.1: 26.0, 23.7: 33.0, 27.7: 25.0, 28.8: 52.5, 29.0: 32.0, 41.3: 35.0, 44.0: 69.0, 44.3: 27.0, 52.6: 22.0, 54.3: 32.0, 54.5: 13.0, 55.0: 20.0, 56.5: 18.0, 57.2: 43.0, 58.5: 37.0, 60.0: 44.0, 60.1: 28.0, 61.6: 29.0, 67.1: 32.0, 69.3: 45.0, 73.1: 22.0, 73.7: 32.0, 77.0: 61.0, 80.7: 41.0, 85.5: 23.0, 88.3: 38.0, 88.4: 37.0, 91.3: 49.0, 98.6: 72.0, 99.9: 41.0, 100.8: 54.0, 101.0: 31.0, 101.3: 27.0, 102.4: 28.0, 102.9: 18.0, 104.2: 40.0, 105.8: 53.0, 106.6: 30.0, 107.8: 20.0, 108.7: 35.0, 120.2: 40.0, 120.4: 28.0, 122.3: 31.0, 125.6: 54.0, 127.6: 39.0, 139.2: 53.0, 141.70000000000002: 35.0, 143.8: 68.0, 154.6: 27.0, 157.2: 41.0, 157.60000000000002: 31.0, 159.3: 47.0, 162.0: 58.0, 164.8: 32.0, 174.4: 29.0, 175.5: 37.0, 175.7: 33.0, 178.0: 27.0, 178.5: 53.0, 178.6: 60.0, 179.1: 53.0, 180.0: 30.0, 180.6: 28.0, 184.0: 43.0, 186.3: 68.0, 190.4: 35.0, 191.2: 84.0, 191.5: 33.0, 191.6: 32.0, 197.8: 66.0, 202.89999999999998: 35.0, 209.8: 45.0, 212.5: 40.0, 215.6: 59.0, 216.9: 37.0, 219.0: 30.0, 223.6: 25.0, 233.6: 35.0, 237.3: 64.0, 241.2: 35.0, 244.1: 39.0, 246.5: 62.0, 252.1: 52.0, 263.8: 64.0, 272.5: 27.0, 280.1: 60.0, 300.6: 35.0, 308.1: 40.0, 323.4: 76.0, 327.6: 65.0, 335.0: 35.0, 352.9: 85.0, 393.6: 48.0, 413.7: 40.0}\n",
      "     Ort. Yagis  Ort. Kesinti\n",
      "0           5.0     30.000000\n",
      "1           6.0     26.285714\n",
      "2           7.0     34.170213\n",
      "3           8.2     31.000000\n",
      "4           8.5     36.000000\n",
      "..          ...           ...\n",
      "103       327.6     65.000000\n",
      "104       335.0     35.000000\n",
      "105       352.9     85.000000\n",
      "106       393.6     48.000000\n",
      "107       413.7     40.000000\n",
      "\n",
      "[108 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9-) ort. yagis miktarlari icin ort. kesinti sayisi grafigi (cok mantikli, gerekli degil)\n",
    "\n",
    "yagis_dict = {}\n",
    "for label,group in merged_all_week[\"izmir-aliaga\"].groupby(\"Yagis_max\"):\n",
    "    yagis_dict[label] = group\n",
    "\n",
    "yagis_dict_toplamlari = {}\n",
    "for deger in yagis_dict.keys():\n",
    "    yagis_dict_toplamlari[deger] = yagis_dict[deger][\"Bildirimsiz_sum\"].mean()\n",
    "print(yagis_dict_toplamlari)\n",
    "\n",
    "hesaplamalar = pd.DataFrame(list(yagis_dict_toplamlari.items()), columns=['Ort. Yagis', 'Ort. Kesinti'])\n",
    "print(hesaplamalar)\n",
    "window_size = 3  # Hareketli ortalama penceresi\n",
    "hesaplamalar['Moving_Average'] = hesaplamalar[\"Ort. Kesinti\"].rolling(window=window_size, center=True).mean()\n",
    "\n",
    "alpha = 0.3  # Yumuşatma parametresi \n",
    "# formul : EMA_t = α × X_t + (1 - α) × EMA_{t-1}\n",
    "hesaplamalar['EWMA'] = hesaplamalar[\"Ort. Kesinti\"].ewm(alpha=alpha, adjust=False).mean()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "#plt.bar(merged_all_week[\"izmir-aliaga\"][\"Yagis\"],merged_all_week[\"izmir-aliaga\"][\"Bildirimsiz_sum\"], width=0.05, label=\"Bildirimsiz\")\n",
    "plt.scatter(yagis_dict_toplamlari.keys(), yagis_dict_toplamlari.values(), label=\"Ort. Kesinti\")\n",
    "#plt.plot(hesaplamalar[\"Ort. Yagis\"], hesaplamalar['Moving_Average'], label=\"MHO\", color=\"red\")\n",
    "plt.plot(hesaplamalar[\"Ort. Yagis\"], hesaplamalar['EWMA'], label=\"EWMA\", color=\"red\")\n",
    "plt.margins(0.01)\n",
    "plt.title(\"Izmir_Aliaga Yagis - Bildirimsiz (Haftalik)\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Ortalama Yagis Miktari\")\n",
    "plt.ylabel(\"Ortalama Elektrik Kesintisi\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tarih         ilce  bildirimli_sum\n",
      "18   2024-02-01  izmir-konak               4\n",
      "65   2024-02-02  izmir-konak               1\n",
      "112  2024-02-03  izmir-konak               1\n",
      "159  2024-02-04  izmir-konak               0\n",
      "206  2024-02-05  izmir-konak               2\n",
      "Index(['Tarih', 'Ilce', 'Bildirimli_sum'], dtype='object')\n",
      "                Tarih         Ilce  Bildirimli_sum Bayram_Flag  Sicaklik_max  \\\n",
      "tarih                                                                          \n",
      "2024-02-01 2024-02-01  izmir-konak               4         NaN          11.9   \n",
      "2024-02-02 2024-02-02  izmir-konak               1         NaN          12.8   \n",
      "2024-02-03 2024-02-03  izmir-konak               1         NaN          12.5   \n",
      "2024-02-04 2024-02-04  izmir-konak               0         NaN          13.4   \n",
      "2024-02-05 2024-02-05  izmir-konak               2         NaN          17.6   \n",
      "2024-02-06 2024-02-06  izmir-konak               1         NaN          20.2   \n",
      "2024-02-07 2024-02-07  izmir-konak               0         NaN          18.3   \n",
      "2024-02-08 2024-02-08  izmir-konak               3         NaN          18.4   \n",
      "2024-02-09 2024-02-09  izmir-konak               1         NaN          17.4   \n",
      "2024-02-10 2024-02-10  izmir-konak               4         NaN          18.2   \n",
      "2024-02-11 2024-02-11  izmir-konak               0         NaN          18.5   \n",
      "2024-02-12 2024-02-12  izmir-konak               0         NaN          17.2   \n",
      "2024-02-13 2024-02-13  izmir-konak               0         NaN          16.6   \n",
      "2024-02-14 2024-02-14  izmir-konak               0         NaN          15.8   \n",
      "2024-02-15 2024-02-15  izmir-konak               0         NaN          12.6   \n",
      "2024-02-16 2024-02-16  izmir-konak               0         NaN          14.5   \n",
      "2024-02-17 2024-02-17  izmir-konak               4         NaN          14.4   \n",
      "2024-02-18 2024-02-18  izmir-konak               0         NaN          15.0   \n",
      "2024-02-19 2024-02-19  izmir-konak               1         NaN          14.0   \n",
      "2024-02-20 2024-02-20  izmir-konak               0         NaN          13.9   \n",
      "2024-02-21 2024-02-21  izmir-konak               0         NaN          14.6   \n",
      "2024-02-22 2024-02-22  izmir-konak               2         NaN          16.0   \n",
      "2024-02-23 2024-02-23  izmir-konak               3         NaN          16.9   \n",
      "2024-02-24 2024-02-24  izmir-konak               1         NaN          19.0   \n",
      "2024-02-25 2024-02-25  izmir-konak               1         NaN          19.2   \n",
      "2024-02-26 2024-02-26  izmir-konak               0         NaN          18.5   \n",
      "2024-02-27 2024-02-27  izmir-konak               3         NaN          19.5   \n",
      "2024-02-28 2024-02-28  izmir-konak               0         NaN          21.0   \n",
      "2024-02-29 2024-02-29  izmir-konak               0         NaN          22.1   \n",
      "\n",
      "            Sicaklik_min  Bagil_nem_max  Bagil_nem_min  Ruzgar_hizi_max  \\\n",
      "tarih                                                                     \n",
      "2024-02-01           4.6           89.5           50.8              2.9   \n",
      "2024-02-02           3.7           92.1           48.5              3.3   \n",
      "2024-02-03           5.6           88.7           49.0              4.7   \n",
      "2024-02-04           5.9           86.1           56.0              1.6   \n",
      "2024-02-05           7.1           95.7           59.0              2.7   \n",
      "2024-02-06           9.3           95.3           60.8              3.0   \n",
      "2024-02-07          12.0           95.7           67.3              6.9   \n",
      "2024-02-08          12.7           89.8           62.3              6.5   \n",
      "2024-02-09          10.8           94.2           60.1              3.5   \n",
      "2024-02-10          11.0           93.2           66.3              6.2   \n",
      "2024-02-11          13.8           82.0           54.5              8.0   \n",
      "2024-02-12          12.1           90.0           65.2              7.9   \n",
      "2024-02-13           8.9           96.1           52.5              3.9   \n",
      "2024-02-14           8.0           99.9           47.6              5.6   \n",
      "2024-02-15           8.2           80.6           59.9              5.3   \n",
      "2024-02-16           7.0           84.0           53.4              4.2   \n",
      "2024-02-17           7.4           87.0           53.2              4.0   \n",
      "2024-02-18           6.8           87.2           53.2              4.0   \n",
      "2024-02-19           6.3           84.7           49.8              3.7   \n",
      "2024-02-20           5.1           89.9           52.6              2.9   \n",
      "2024-02-21           6.1           88.8           44.0              3.4   \n",
      "2024-02-22           8.0           75.4           40.9              2.5   \n",
      "2024-02-23           8.6           95.3           62.4              4.3   \n",
      "2024-02-24           9.7           97.4           55.6              2.8   \n",
      "2024-02-25          10.6           90.8           48.1              3.1   \n",
      "2024-02-26          10.9           84.1           47.7              5.4   \n",
      "2024-02-27          11.8           87.6           50.0              2.6   \n",
      "2024-02-28          10.7           91.7           44.1              2.4   \n",
      "2024-02-29           9.9           92.8           41.2              2.6   \n",
      "\n",
      "            Ruzgar_hizi_min  Yagis_max  Yagis_min   Sicaklik  Bagil_nem  \\\n",
      "tarih                                                                     \n",
      "2024-02-01              2.9        1.0        1.0   7.416667  76.075000   \n",
      "2024-02-02              3.3        1.0        1.0   7.537500  76.600000   \n",
      "2024-02-03              4.7        1.0        1.0   8.354167  70.429167   \n",
      "2024-02-04              1.6        8.7        1.0   9.300000  72.108333   \n",
      "2024-02-05              2.7        1.0        1.0  11.412500  81.879167   \n",
      "2024-02-06              3.0        1.0        1.0  13.341667  82.562500   \n",
      "2024-02-07              6.9        4.6        1.0  14.958333  84.025000   \n",
      "2024-02-08              6.5        1.0        1.0  14.925000  80.550000   \n",
      "2024-02-09              3.5       57.1        1.0  13.379167  83.950000   \n",
      "2024-02-10              6.2       14.1        1.0  14.108333  79.545833   \n",
      "2024-02-11              8.0       94.2        1.0  15.645833  70.191667   \n",
      "2024-02-12              7.9       95.0        1.0  14.679167  78.145833   \n",
      "2024-02-13              3.9       31.7        1.0  11.904167  82.216667   \n",
      "2024-02-14              5.6        1.0        1.0  11.454167  76.887500   \n",
      "2024-02-15              5.3       68.7        1.0   9.841667  72.545833   \n",
      "2024-02-16              4.2        1.0        1.0   9.875000  72.495833   \n",
      "2024-02-17              4.0        1.0        1.0  10.062500  73.662500   \n",
      "2024-02-18              4.0        1.0        1.0  10.137500  73.129167   \n",
      "2024-02-19              3.7        1.0        1.0   9.700000  70.825000   \n",
      "2024-02-20              2.9        1.0        1.0   9.154167  75.720833   \n",
      "2024-02-21              3.4        8.3        1.0   9.941667  69.854167   \n",
      "2024-02-22              2.5        1.0        1.0  11.979167  60.583333   \n",
      "2024-02-23              4.3        1.0        1.0  12.425000  79.912500   \n",
      "2024-02-24              2.8        1.0        1.0  13.795833  81.883333   \n",
      "2024-02-25              3.1       25.7        1.0  14.058333  71.991667   \n",
      "2024-02-26              5.4       31.1        1.0  14.300000  67.937500   \n",
      "2024-02-27              2.6        1.0        1.0  14.954167  75.770833   \n",
      "2024-02-28              2.4        1.0        1.0  15.362500  73.537500   \n",
      "2024-02-29              2.6       85.1        1.0  15.991667  68.441667   \n",
      "\n",
      "            Ruzgar_hizi      Yagis  Ozet  Gün  \n",
      "tarih                                          \n",
      "2024-02-01     2.054167   1.000000     3    1  \n",
      "2024-02-02     1.691667   1.000000     3    2  \n",
      "2024-02-03     2.483333   1.000000     3    3  \n",
      "2024-02-04     1.083333   1.616667     3    4  \n",
      "2024-02-05     2.004167   1.000000     3    5  \n",
      "2024-02-06     2.337500   1.000000     3    6  \n",
      "2024-02-07     4.529167   1.245833     2    7  \n",
      "2024-02-08     4.483333   1.000000     2    8  \n",
      "2024-02-09     2.491667   5.058333     3    9  \n",
      "2024-02-10     4.133333   2.512500     2   10  \n",
      "2024-02-11     6.191667  15.691667     2   11  \n",
      "2024-02-12     6.387500  37.950000     2   12  \n",
      "2024-02-13     2.108333   3.087500     3   13  \n",
      "2024-02-14     2.820833   1.000000     3   14  \n",
      "2024-02-15     4.150000   7.166667     2   15  \n",
      "2024-02-16     2.641667   1.000000     3   16  \n",
      "2024-02-17     2.487500   1.000000     3   17  \n",
      "2024-02-18     2.637500   1.000000     3   18  \n",
      "2024-02-19     2.166667   1.000000     3   19  \n",
      "2024-02-20     1.504167   1.000000     3   20  \n",
      "2024-02-21     1.695833   1.562500     3   21  \n",
      "2024-02-22     1.137500   1.000000     3   22  \n",
      "2024-02-23     2.583333   1.000000     2   23  \n",
      "2024-02-24     2.112500   1.000000     3   24  \n",
      "2024-02-25     2.170833   2.216667     0   25  \n",
      "2024-02-26     2.712500   5.658333     2   26  \n",
      "2024-02-27     1.112500   1.000000     3   27  \n",
      "2024-02-28     1.566667   1.000000     3   28  \n",
      "2024-02-29     1.633333  14.195833     0   29  \n"
     ]
    }
   ],
   "source": [
    "# 10-) test icin birlestirme islemleri\n",
    "\n",
    "test = pd.read_csv(\"./test.csv\", low_memory=False) # 47 ilce icin 28 gunluk veriler var. (tarih, ilce, bildirimli_sum)\n",
    "#print(test)\n",
    "\n",
    "dict_test :{str, pd.DataFrame} = {} # key olarak ilceleri, value olarak ilcelerin 4 ocak - 31 ocak arasi verilerini df olarak tutar\n",
    "for label, group in test.groupby(\"ilce\"):\n",
    "    dict_test[label] = group\n",
    "\n",
    "print(dict_test[\"izmir-konak\"].head())\n",
    "\n",
    "for name in dict_test.keys():\n",
    "\n",
    "    tarihler = [] # duzgun tarihleri tutacak\n",
    "    for date in dict_test[name][\"tarih\"]:\n",
    "        tarihler.append(datetime.strptime(date, \"%Y-%m-%d\")) \n",
    "\n",
    "    dict_test[name][\"tarih\"] = tarihler # duzeltilmis tarihleri ata\n",
    "\n",
    "    dict_test[name].set_index(\"tarih\", inplace=True) # tarih kolonunu index'e ata\n",
    "    dict_test[name][\"Tarih\"] = dict_test[name].index # tarih kolonunu yeniden olustur\n",
    "    dict_test[name] = dict_test[name].iloc[:, [2, 0, 1]] # kolon siralarini duzenle\n",
    "    dict_test[name].columns = [\"Tarih\", \"Ilce\", \"Bildirimli_sum\"] # kolon isimlerini duzenle\n",
    "\n",
    "print(dict_test[\"izmir-konak\"].columns)\n",
    "\n",
    "\n",
    "dict_test_merged = {} # birlestirilenleri tutacak dict\n",
    "for name in dict_test.keys():\n",
    "\n",
    "    gecici = merge_holiday(dict_test[name], holiday) # test'e holiday ekle\n",
    "    dict_test_merged[name] = merge_weather(gecici, weather_last[name]) # sonra weather'i ekle\n",
    "\n",
    "    dict_test_merged[name].columns = [\"Tarih\", \"Ilce\", \"Bildirimli_sum\", # tekrar isimlendir\n",
    "    \"Bayram_Flag\", \"Sicaklik_max\", \"Sicaklik_min\",\"Bagil_nem_max\",\"Bagil_nem_min\",\n",
    "    \"Ruzgar_hizi_max\", \"Ruzgar_hizi_min\",\"Yagis_max\", \"Yagis_min\",\"Sicaklik\",\"Bagil_nem\",\"Ruzgar_hizi\",\"Yagis\",\"Ozet\"]\n",
    "\n",
    "    dict_test_merged[name]['Gün'] = range(1, len(dict_test_merged[name]) + 1) # gun kolonu ekle (1-28 arasi oluyor)\n",
    "\n",
    "print(dict_test_merged[\"izmir-konak\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKINE OGRENMESI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpus = tf.config.list_physical_devices('GPU')\n",
    "#logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#print((gpus), \"Physical GPU,\\n\", (logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config islemleri\n",
    "\n",
    "\n",
    "#tf.config.set_soft_device_placement(True) # otomatik dogru cihaz kullanimi\n",
    "#strategy = tf.distribute.MirroredStrategy() # birden fazla gpu kullanimi\n",
    "#tf.debugging.set_log_device_placement(True) # hangi cihazlarin kullanildigi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 2s 38ms/step - loss: 42.0675 - mae: 5.0123 - val_loss: 37.2626 - val_mae: 4.4796\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 31.1034 - mae: 3.9016 - val_loss: 24.8147 - val_mae: 3.1762\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 19.9072 - mae: 2.9661 - val_loss: 16.1082 - val_mae: 2.6537\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.5894 - mae: 2.9167 - val_loss: 15.8681 - val_mae: 2.7887\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.1246 - mae: 2.8164 - val_loss: 15.7471 - val_mae: 2.6303\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.1116 - mae: 2.7864 - val_loss: 15.5170 - val_mae: 2.6718\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.9896 - mae: 2.7768 - val_loss: 15.4990 - val_mae: 2.6368\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 15.9745 - mae: 2.7952 - val_loss: 15.3313 - val_mae: 2.6627\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 15.9153 - mae: 2.7676 - val_loss: 15.2603 - val_mae: 2.6630\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 15.8355 - mae: 2.7765 - val_loss: 15.1969 - val_mae: 2.6718\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 15.7957 - mae: 2.7872 - val_loss: 15.1621 - val_mae: 2.6487\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 15.8217 - mae: 2.7631 - val_loss: 15.0838 - val_mae: 2.6612\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.7406 - mae: 2.7781 - val_loss: 15.0535 - val_mae: 2.6618\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.6891 - mae: 2.7688 - val_loss: 15.0229 - val_mae: 2.6403\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.7069 - mae: 2.7866 - val_loss: 14.9321 - val_mae: 2.6587\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.6161 - mae: 2.7723 - val_loss: 15.0154 - val_mae: 2.6062\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.6483 - mae: 2.7389 - val_loss: 14.9287 - val_mae: 2.6151\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.5260 - mae: 2.7633 - val_loss: 14.8395 - val_mae: 2.6344\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 15.5450 - mae: 2.7842 - val_loss: 14.8042 - val_mae: 2.6186\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 15.5103 - mae: 2.7306 - val_loss: 14.8972 - val_mae: 2.5846\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 15.4118 - mae: 2.7530 - val_loss: 14.6915 - val_mae: 2.6406\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.4508 - mae: 2.7622 - val_loss: 14.7044 - val_mae: 2.6048\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3858 - mae: 2.7496 - val_loss: 14.7733 - val_mae: 2.5760\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3908 - mae: 2.7626 - val_loss: 14.6142 - val_mae: 2.5952\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3157 - mae: 2.7428 - val_loss: 14.7140 - val_mae: 2.5625\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3054 - mae: 2.7170 - val_loss: 14.5146 - val_mae: 2.5975\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.2612 - mae: 2.7600 - val_loss: 14.4713 - val_mae: 2.6193\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.3430 - mae: 2.7227 - val_loss: 14.5628 - val_mae: 2.5575\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1761 - mae: 2.7577 - val_loss: 14.4080 - val_mae: 2.5994\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1299 - mae: 2.7276 - val_loss: 14.3782 - val_mae: 2.5831\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.0760 - mae: 2.7255 - val_loss: 14.3888 - val_mae: 2.5692\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.1359 - mae: 2.7528 - val_loss: 14.4545 - val_mae: 2.5443\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.0999 - mae: 2.6896 - val_loss: 14.3147 - val_mae: 2.5710\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.0438 - mae: 2.7523 - val_loss: 14.2554 - val_mae: 2.5636\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.9815 - mae: 2.6880 - val_loss: 14.2728 - val_mae: 2.5585\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.9460 - mae: 2.7431 - val_loss: 14.2088 - val_mae: 2.5593\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.9881 - mae: 2.6900 - val_loss: 14.1871 - val_mae: 2.5638\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 14.8271 - mae: 2.7197 - val_loss: 14.1624 - val_mae: 2.5598\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.0148 - mae: 2.7234 - val_loss: 14.0538 - val_mae: 2.5895\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.7592 - mae: 2.6906 - val_loss: 14.2923 - val_mae: 2.5098\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8188 - mae: 2.6959 - val_loss: 13.9593 - val_mae: 2.5879\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.6668 - mae: 2.7007 - val_loss: 14.1701 - val_mae: 2.5198\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.6890 - mae: 2.6748 - val_loss: 14.1548 - val_mae: 2.5231\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6775 - mae: 2.7088 - val_loss: 14.0170 - val_mae: 2.5369\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6506 - mae: 2.6971 - val_loss: 14.0841 - val_mae: 2.5195\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.7569 - mae: 2.7183 - val_loss: 13.9339 - val_mae: 2.5555\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5813 - mae: 2.6751 - val_loss: 14.0254 - val_mae: 2.5208\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5004 - mae: 2.6837 - val_loss: 13.9965 - val_mae: 2.5199\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.4928 - mae: 2.6880 - val_loss: 13.9074 - val_mae: 2.5377\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.4472 - mae: 2.6746 - val_loss: 13.9536 - val_mae: 2.5239\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 12.0600 - mae: 2.6585\n",
      "Mean Absolute Error on Test Data: 2.6585211753845215\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.045247450099168196\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 19ms/step - loss: 5.1653 - mae: 1.7653 - val_loss: 2.5912 - val_mae: 1.2529\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.6962 - mae: 1.3586 - val_loss: 1.6775 - val_mae: 0.8489\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.6251 - mae: 1.0603 - val_loss: 1.1735 - val_mae: 0.8015\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1265 - mae: 1.0621 - val_loss: 1.3674 - val_mae: 1.0091\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1202 - mae: 1.1206 - val_loss: 1.2777 - val_mae: 0.9572\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0900 - mae: 1.0742 - val_loss: 1.1741 - val_mae: 0.8844\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0670 - mae: 1.0574 - val_loss: 1.1940 - val_mae: 0.9027\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0579 - mae: 1.0722 - val_loss: 1.2226 - val_mae: 0.9238\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0493 - mae: 1.0677 - val_loss: 1.1872 - val_mae: 0.8975\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.0428 - mae: 1.0622 - val_loss: 1.1948 - val_mae: 0.9049\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.0372 - mae: 1.0632 - val_loss: 1.2016 - val_mae: 0.9100\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.0338 - mae: 1.0623 - val_loss: 1.1856 - val_mae: 0.8984\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0291 - mae: 1.0625 - val_loss: 1.1951 - val_mae: 0.9057\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.0247 - mae: 1.0636 - val_loss: 1.2007 - val_mae: 0.9101\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0170 - mae: 1.0582 - val_loss: 1.1990 - val_mae: 0.9105\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.0145 - mae: 1.0585 - val_loss: 1.1947 - val_mae: 0.9089\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0076 - mae: 1.0576 - val_loss: 1.1965 - val_mae: 0.9114\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0084 - mae: 1.0677 - val_loss: 1.2039 - val_mae: 0.9167\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9979 - mae: 1.0549 - val_loss: 1.1788 - val_mae: 0.8990\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.0055 - mae: 1.0421 - val_loss: 1.1624 - val_mae: 0.8864\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0005 - mae: 1.0613 - val_loss: 1.2265 - val_mae: 0.9330\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9850 - mae: 1.0548 - val_loss: 1.1815 - val_mae: 0.9023\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9864 - mae: 1.0447 - val_loss: 1.1776 - val_mae: 0.9011\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9801 - mae: 1.0542 - val_loss: 1.1948 - val_mae: 0.9143\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9721 - mae: 1.0530 - val_loss: 1.1775 - val_mae: 0.9019\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9681 - mae: 1.0441 - val_loss: 1.1778 - val_mae: 0.9031\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9655 - mae: 1.0554 - val_loss: 1.2174 - val_mae: 0.9310\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9696 - mae: 1.0647 - val_loss: 1.1656 - val_mae: 0.8941\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9616 - mae: 1.0303 - val_loss: 1.1643 - val_mae: 0.8929\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9464 - mae: 1.0484 - val_loss: 1.2232 - val_mae: 0.9359\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9499 - mae: 1.0499 - val_loss: 1.1873 - val_mae: 0.9113\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9361 - mae: 1.0463 - val_loss: 1.1826 - val_mae: 0.9084\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9466 - mae: 1.0560 - val_loss: 1.1962 - val_mae: 0.9161\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9509 - mae: 1.0309 - val_loss: 1.1546 - val_mae: 0.8882\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9228 - mae: 1.0419 - val_loss: 1.2094 - val_mae: 0.9285\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9201 - mae: 1.0463 - val_loss: 1.1988 - val_mae: 0.9197\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9158 - mae: 1.0356 - val_loss: 1.1800 - val_mae: 0.9065\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9150 - mae: 1.0447 - val_loss: 1.2092 - val_mae: 0.9266\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9136 - mae: 1.0297 - val_loss: 1.1571 - val_mae: 0.8900\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9019 - mae: 1.0210 - val_loss: 1.2205 - val_mae: 0.9358\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9026 - mae: 1.0536 - val_loss: 1.2023 - val_mae: 0.9233\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8863 - mae: 1.0294 - val_loss: 1.1665 - val_mae: 0.8976\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.8928 - mae: 1.0330 - val_loss: 1.2108 - val_mae: 0.9298\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8809 - mae: 1.0364 - val_loss: 1.1943 - val_mae: 0.9171\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8829 - mae: 1.0234 - val_loss: 1.1584 - val_mae: 0.8914\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8859 - mae: 1.0452 - val_loss: 1.2243 - val_mae: 0.9365\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8792 - mae: 1.0293 - val_loss: 1.1713 - val_mae: 0.8973\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8637 - mae: 1.0181 - val_loss: 1.1777 - val_mae: 0.9046\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8595 - mae: 1.0384 - val_loss: 1.2239 - val_mae: 0.9354\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8539 - mae: 1.0290 - val_loss: 1.1901 - val_mae: 0.9120\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3782 - mae: 0.9437\n",
      "Mean Absolute Error on Test Data: 0.9436827301979065\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.08272197821691396\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 33.1616 - mae: 4.3467 - val_loss: 32.7856 - val_mae: 4.3438\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 24.1139 - mae: 3.3673 - val_loss: 21.5224 - val_mae: 3.2537\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 15.7460 - mae: 2.6570 - val_loss: 13.9926 - val_mae: 2.7664\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.3746 - mae: 2.8274 - val_loss: 13.7418 - val_mae: 2.7859\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.8883 - mae: 2.6829 - val_loss: 14.0760 - val_mae: 2.7333\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.8238 - mae: 2.6551 - val_loss: 13.7939 - val_mae: 2.7454\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7828 - mae: 2.6791 - val_loss: 13.8623 - val_mae: 2.7343\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7478 - mae: 2.6523 - val_loss: 13.7216 - val_mae: 2.7412\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7097 - mae: 2.6515 - val_loss: 13.7641 - val_mae: 2.7352\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.6912 - mae: 2.6676 - val_loss: 13.6352 - val_mae: 2.7489\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6904 - mae: 2.6907 - val_loss: 13.7936 - val_mae: 2.7308\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6825 - mae: 2.6260 - val_loss: 13.8369 - val_mae: 2.7286\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6823 - mae: 2.6470 - val_loss: 13.6297 - val_mae: 2.7532\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.6466 - mae: 2.7062 - val_loss: 13.8143 - val_mae: 2.7313\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6319 - mae: 2.6215 - val_loss: 13.8899 - val_mae: 2.7269\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.5738 - mae: 2.6555 - val_loss: 13.7871 - val_mae: 2.7355\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.5525 - mae: 2.6607 - val_loss: 13.7881 - val_mae: 2.7349\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.6120 - mae: 2.6500 - val_loss: 13.6700 - val_mae: 2.7503\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.5174 - mae: 2.6593 - val_loss: 13.8232 - val_mae: 2.7344\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5456 - mae: 2.6287 - val_loss: 13.9128 - val_mae: 2.7283\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5273 - mae: 2.6747 - val_loss: 13.7830 - val_mae: 2.7394\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5044 - mae: 2.6372 - val_loss: 13.8258 - val_mae: 2.7361\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.4523 - mae: 2.6544 - val_loss: 13.7926 - val_mae: 2.7399\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.4763 - mae: 2.6752 - val_loss: 13.9213 - val_mae: 2.7300\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.4850 - mae: 2.6047 - val_loss: 13.9273 - val_mae: 2.7303\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.4581 - mae: 2.6771 - val_loss: 13.8263 - val_mae: 2.7412\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.4167 - mae: 2.6341 - val_loss: 13.8547 - val_mae: 2.7416\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.4028 - mae: 2.6419 - val_loss: 14.0302 - val_mae: 2.7305\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.3881 - mae: 2.6374 - val_loss: 13.8418 - val_mae: 2.7495\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.4694 - mae: 2.6533 - val_loss: 14.0636 - val_mae: 2.7310\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.3770 - mae: 2.6702 - val_loss: 13.9288 - val_mae: 2.7415\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2961 - mae: 2.6271 - val_loss: 13.9683 - val_mae: 2.7392\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.3043 - mae: 2.6480 - val_loss: 14.0349 - val_mae: 2.7363\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2700 - mae: 2.6262 - val_loss: 14.0161 - val_mae: 2.7373\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.2428 - mae: 2.6425 - val_loss: 13.9715 - val_mae: 2.7433\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2389 - mae: 2.6417 - val_loss: 14.0293 - val_mae: 2.7406\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2515 - mae: 2.6609 - val_loss: 14.0792 - val_mae: 2.7401\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.1821 - mae: 2.6236 - val_loss: 14.1443 - val_mae: 2.7368\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.2137 - mae: 2.6057 - val_loss: 14.1081 - val_mae: 2.7430\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1592 - mae: 2.6485 - val_loss: 14.0373 - val_mae: 2.7488\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2290 - mae: 2.6214 - val_loss: 14.1602 - val_mae: 2.7415\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3320 - mae: 2.7041 - val_loss: 14.1736 - val_mae: 2.7390\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2098 - mae: 2.5842 - val_loss: 14.1889 - val_mae: 2.7388\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.1360 - mae: 2.6381 - val_loss: 14.0113 - val_mae: 2.7697\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1426 - mae: 2.6456 - val_loss: 14.2257 - val_mae: 2.7436\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0669 - mae: 2.6275 - val_loss: 14.2012 - val_mae: 2.7441\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0718 - mae: 2.6192 - val_loss: 14.2215 - val_mae: 2.7424\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1033 - mae: 2.6509 - val_loss: 14.2326 - val_mae: 2.7419\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0302 - mae: 2.5969 - val_loss: 14.1934 - val_mae: 2.7468\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.0284 - mae: 2.6382 - val_loss: 14.2058 - val_mae: 2.7523\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.8283 - mae: 2.6918\n",
      "Mean Absolute Error on Test Data: 2.69181227684021\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.010266551720839012\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 17ms/step - loss: 32.8350 - mae: 3.7383 - val_loss: 37.7149 - val_mae: 3.3120\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.9919 - mae: 2.7504 - val_loss: 29.5601 - val_mae: 2.7990\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.3515 - mae: 2.7487 - val_loss: 28.8411 - val_mae: 3.0132\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.3924 - mae: 2.7616 - val_loss: 28.7482 - val_mae: 2.8524\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.1238 - mae: 2.6890 - val_loss: 28.6142 - val_mae: 2.9067\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.0772 - mae: 2.6980 - val_loss: 28.5768 - val_mae: 2.8808\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.0385 - mae: 2.6683 - val_loss: 28.5762 - val_mae: 2.8766\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 19.0001 - mae: 2.6978 - val_loss: 28.4730 - val_mae: 2.9044\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.9572 - mae: 2.6851 - val_loss: 28.4764 - val_mae: 2.8712\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.9783 - mae: 2.6603 - val_loss: 28.3542 - val_mae: 2.8951\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 18.9763 - mae: 2.6603 - val_loss: 28.3298 - val_mae: 2.8645\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.8454 - mae: 2.6701 - val_loss: 28.2315 - val_mae: 2.8959\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.8668 - mae: 2.6652 - val_loss: 28.2234 - val_mae: 2.8529\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.8043 - mae: 2.6361 - val_loss: 28.0816 - val_mae: 2.8903\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.8349 - mae: 2.6994 - val_loss: 28.0125 - val_mae: 2.8980\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.7780 - mae: 2.6389 - val_loss: 28.0049 - val_mae: 2.8466\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.7457 - mae: 2.6170 - val_loss: 27.8868 - val_mae: 2.8838\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.6908 - mae: 2.6731 - val_loss: 27.8127 - val_mae: 2.8637\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.6708 - mae: 2.6884 - val_loss: 27.7532 - val_mae: 2.8699\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5579 - mae: 2.6310 - val_loss: 27.7128 - val_mae: 2.8411\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5499 - mae: 2.6203 - val_loss: 27.5957 - val_mae: 2.8670\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.4822 - mae: 2.6282 - val_loss: 27.5490 - val_mae: 2.8425\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5338 - mae: 2.6616 - val_loss: 27.4942 - val_mae: 2.8274\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.4156 - mae: 2.5838 - val_loss: 27.3785 - val_mae: 2.8218\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.4337 - mae: 2.6461 - val_loss: 27.2625 - val_mae: 2.8305\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.3130 - mae: 2.5781 - val_loss: 27.2449 - val_mae: 2.7991\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 18.3017 - mae: 2.6329 - val_loss: 27.0051 - val_mae: 2.8423\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.1993 - mae: 2.5914 - val_loss: 26.9460 - val_mae: 2.8134\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.1792 - mae: 2.5880 - val_loss: 26.8209 - val_mae: 2.8111\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.1247 - mae: 2.5951 - val_loss: 26.7767 - val_mae: 2.7951\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.0858 - mae: 2.5891 - val_loss: 26.6470 - val_mae: 2.8069\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.9733 - mae: 2.5762 - val_loss: 26.4959 - val_mae: 2.8102\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.9239 - mae: 2.5665 - val_loss: 26.3539 - val_mae: 2.8003\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.9831 - mae: 2.6203 - val_loss: 26.3324 - val_mae: 2.7783\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.9743 - mae: 2.4918 - val_loss: 26.1889 - val_mae: 2.7761\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.9472 - mae: 2.6420 - val_loss: 26.0752 - val_mae: 2.8077\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.7446 - mae: 2.5363 - val_loss: 26.0633 - val_mae: 2.7750\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.7701 - mae: 2.5135 - val_loss: 25.8957 - val_mae: 2.8020\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.6573 - mae: 2.6029 - val_loss: 25.7877 - val_mae: 2.8074\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.7054 - mae: 2.4983 - val_loss: 25.7550 - val_mae: 2.7718\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.6110 - mae: 2.5963 - val_loss: 25.5793 - val_mae: 2.8115\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.8878 - mae: 2.4868 - val_loss: 25.5317 - val_mae: 2.7761\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.5621 - mae: 2.5221 - val_loss: 25.4195 - val_mae: 2.7809\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.4601 - mae: 2.5763 - val_loss: 25.3556 - val_mae: 2.7936\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.3520 - mae: 2.5133 - val_loss: 25.4119 - val_mae: 2.7584\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.3988 - mae: 2.4687 - val_loss: 25.2178 - val_mae: 2.7807\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.3672 - mae: 2.5543 - val_loss: 25.1995 - val_mae: 2.7811\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 17.4238 - mae: 2.4770 - val_loss: 25.1270 - val_mae: 2.7376\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2974 - mae: 2.5260 - val_loss: 24.9991 - val_mae: 2.7573\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2018 - mae: 2.5170 - val_loss: 24.9548 - val_mae: 2.7911\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.7076 - mae: 2.6733\n",
      "Mean Absolute Error on Test Data: 2.6733152866363525\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.04923155265467494\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 15ms/step - loss: 65.3334 - mae: 6.3656 - val_loss: 56.3992 - val_mae: 5.9092\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 49.6891 - mae: 5.1301 - val_loss: 37.1336 - val_mae: 4.2873\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 30.8337 - mae: 3.6415 - val_loss: 21.4327 - val_mae: 3.2367\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.0700 - mae: 3.4055 - val_loss: 21.0736 - val_mae: 3.4554\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.0014 - mae: 3.4527 - val_loss: 20.5616 - val_mae: 3.2950\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.5725 - mae: 3.2745 - val_loss: 20.6449 - val_mae: 3.2344\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.4310 - mae: 3.2673 - val_loss: 20.3399 - val_mae: 3.2765\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3585 - mae: 3.3615 - val_loss: 20.1886 - val_mae: 3.3171\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.2933 - mae: 3.2967 - val_loss: 20.1583 - val_mae: 3.2323\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.1044 - mae: 3.2982 - val_loss: 19.9591 - val_mae: 3.2803\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.0529 - mae: 3.2901 - val_loss: 19.9216 - val_mae: 3.2347\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 23.0061 - mae: 3.2724 - val_loss: 19.8159 - val_mae: 3.2387\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 22.8962 - mae: 3.2913 - val_loss: 19.7067 - val_mae: 3.2602\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 22.8471 - mae: 3.2825 - val_loss: 19.8378 - val_mae: 3.1981\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.8425 - mae: 3.2732 - val_loss: 19.5736 - val_mae: 3.2689\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.7251 - mae: 3.3192 - val_loss: 19.5045 - val_mae: 3.2525\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.7288 - mae: 3.2613 - val_loss: 19.5365 - val_mae: 3.2176\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.6273 - mae: 3.2885 - val_loss: 19.6181 - val_mae: 3.2047\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.9674 - mae: 3.2185 - val_loss: 19.6967 - val_mae: 3.2022\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 22.6830 - mae: 3.3328 - val_loss: 19.4064 - val_mae: 3.2619\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 22.5058 - mae: 3.3028 - val_loss: 19.3397 - val_mae: 3.2141\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 22.3720 - mae: 3.2413 - val_loss: 19.3739 - val_mae: 3.1966\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 22.3368 - mae: 3.2725 - val_loss: 19.1709 - val_mae: 3.2459\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.3989 - mae: 3.2487 - val_loss: 19.2203 - val_mae: 3.2250\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.2360 - mae: 3.3055 - val_loss: 19.1458 - val_mae: 3.2489\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 22.3505 - mae: 3.3253 - val_loss: 19.2836 - val_mae: 3.2193\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.0579 - mae: 3.2402 - val_loss: 19.0775 - val_mae: 3.2222\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.0651 - mae: 3.2921 - val_loss: 19.0431 - val_mae: 3.2056\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 21.9778 - mae: 3.2599 - val_loss: 18.9190 - val_mae: 3.2157\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 21.8400 - mae: 3.2530 - val_loss: 18.9944 - val_mae: 3.1902\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.9544 - mae: 3.2743 - val_loss: 18.9466 - val_mae: 3.1974\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.8246 - mae: 3.2379 - val_loss: 18.8546 - val_mae: 3.2046\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.7585 - mae: 3.2409 - val_loss: 18.8573 - val_mae: 3.2066\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.7050 - mae: 3.2533 - val_loss: 18.8033 - val_mae: 3.2231\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.7597 - mae: 3.3128 - val_loss: 18.8012 - val_mae: 3.2122\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.7435 - mae: 3.2137 - val_loss: 18.8718 - val_mae: 3.2002\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 22.0091 - mae: 3.3374 - val_loss: 18.8518 - val_mae: 3.2167\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.6208 - mae: 3.2331 - val_loss: 18.7995 - val_mae: 3.1792\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.5244 - mae: 3.2151 - val_loss: 18.7378 - val_mae: 3.1982\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.6775 - mae: 3.3142 - val_loss: 18.8026 - val_mae: 3.1813\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.4661 - mae: 3.2368 - val_loss: 18.6924 - val_mae: 3.1905\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.4678 - mae: 3.2627 - val_loss: 18.7495 - val_mae: 3.1799\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.3882 - mae: 3.2427 - val_loss: 18.7189 - val_mae: 3.1849\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.3955 - mae: 3.2473 - val_loss: 18.7189 - val_mae: 3.1843\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.4518 - mae: 3.2671 - val_loss: 18.6702 - val_mae: 3.1916\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.3266 - mae: 3.2226 - val_loss: 18.7764 - val_mae: 3.1716\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 21.2982 - mae: 3.2337 - val_loss: 18.6689 - val_mae: 3.1947\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.2673 - mae: 3.2262 - val_loss: 18.7487 - val_mae: 3.1739\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.3240 - mae: 3.2347 - val_loss: 18.6694 - val_mae: 3.1864\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.1278 - mae: 3.2054 - val_loss: 18.9607 - val_mae: 3.1546\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 23.5532 - mae: 3.2633\n",
      "Mean Absolute Error on Test Data: 3.2633354663848877\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.0973121016060936\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 24ms/step - loss: 7.3276 - mae: 1.7575 - val_loss: 2.7507 - val_mae: 1.0742\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5.1551 - mae: 1.2736 - val_loss: 1.8043 - val_mae: 0.9980\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.3248 - mae: 1.3192 - val_loss: 2.0659 - val_mae: 1.2371\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.3289 - mae: 1.4253 - val_loss: 1.9686 - val_mae: 1.1826\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.2367 - mae: 1.3592 - val_loss: 1.8584 - val_mae: 1.1111\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.2187 - mae: 1.3186 - val_loss: 1.8233 - val_mae: 1.0871\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.2027 - mae: 1.2978 - val_loss: 1.8012 - val_mae: 1.0682\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.1858 - mae: 1.2996 - val_loss: 1.8142 - val_mae: 1.0840\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.1728 - mae: 1.2994 - val_loss: 1.8411 - val_mae: 1.1085\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.1541 - mae: 1.3339 - val_loss: 1.8819 - val_mae: 1.1395\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.1311 - mae: 1.3105 - val_loss: 1.7995 - val_mae: 1.0814\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.1244 - mae: 1.3085 - val_loss: 1.8203 - val_mae: 1.1004\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.1370 - mae: 1.2874 - val_loss: 1.7678 - val_mae: 1.0588\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.0945 - mae: 1.3078 - val_loss: 1.8585 - val_mae: 1.1326\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.0919 - mae: 1.3397 - val_loss: 1.8344 - val_mae: 1.1170\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.0709 - mae: 1.2870 - val_loss: 1.7754 - val_mae: 1.0735\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.0366 - mae: 1.2931 - val_loss: 1.8561 - val_mae: 1.1388\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 4.0871 - mae: 1.3663 - val_loss: 1.9846 - val_mae: 1.2078\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.0489 - mae: 1.3357 - val_loss: 1.8056 - val_mae: 1.1059\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.0214 - mae: 1.2863 - val_loss: 1.7783 - val_mae: 1.0880\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.0293 - mae: 1.3232 - val_loss: 1.8574 - val_mae: 1.1460\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.9931 - mae: 1.2971 - val_loss: 1.7593 - val_mae: 1.0766\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.9916 - mae: 1.2839 - val_loss: 1.8396 - val_mae: 1.1322\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.0085 - mae: 1.3522 - val_loss: 1.9157 - val_mae: 1.1734\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3.9880 - mae: 1.3149 - val_loss: 1.7886 - val_mae: 1.0977\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.9669 - mae: 1.2917 - val_loss: 1.7930 - val_mae: 1.1080\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.9622 - mae: 1.3025 - val_loss: 1.8022 - val_mae: 1.1158\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3.9685 - mae: 1.3249 - val_loss: 1.8010 - val_mae: 1.1171\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 3.9641 - mae: 1.2841 - val_loss: 1.7224 - val_mae: 1.0596\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.9710 - mae: 1.3041 - val_loss: 1.8814 - val_mae: 1.1627\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.9642 - mae: 1.3279 - val_loss: 1.7760 - val_mae: 1.1039\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.9883 - mae: 1.2704 - val_loss: 1.7108 - val_mae: 1.0490\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.0236 - mae: 1.3351 - val_loss: 1.8775 - val_mae: 1.1646\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.9546 - mae: 1.2945 - val_loss: 1.6844 - val_mae: 1.0216\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.9336 - mae: 1.2716 - val_loss: 1.8124 - val_mae: 1.1264\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3.9292 - mae: 1.3338 - val_loss: 1.8097 - val_mae: 1.1249\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3.9696 - mae: 1.2759 - val_loss: 1.7164 - val_mae: 1.0568\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.9714 - mae: 1.3482 - val_loss: 1.8952 - val_mae: 1.1703\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.9064 - mae: 1.3168 - val_loss: 1.7531 - val_mae: 1.0799\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3.9673 - mae: 1.2672 - val_loss: 1.7456 - val_mae: 1.0786\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.9220 - mae: 1.3257 - val_loss: 1.8715 - val_mae: 1.1572\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3.9095 - mae: 1.3308 - val_loss: 1.8059 - val_mae: 1.1145\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3.8924 - mae: 1.3117 - val_loss: 1.7925 - val_mae: 1.1033\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.9054 - mae: 1.2920 - val_loss: 1.7787 - val_mae: 1.1000\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.8752 - mae: 1.2922 - val_loss: 1.7446 - val_mae: 1.0769\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 3.8818 - mae: 1.2848 - val_loss: 1.7660 - val_mae: 1.0947\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3.9001 - mae: 1.3238 - val_loss: 1.8031 - val_mae: 1.1166\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.8711 - mae: 1.3002 - val_loss: 1.7473 - val_mae: 1.0796\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.8683 - mae: 1.2842 - val_loss: 1.7720 - val_mae: 1.0971\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.8616 - mae: 1.3028 - val_loss: 1.7572 - val_mae: 1.0862\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9250 - mae: 1.4773\n",
      "Mean Absolute Error on Test Data: 1.4773205518722534\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.13773767243042379\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 12ms/step - loss: 128.0417 - mae: 9.1826 - val_loss: 105.5426 - val_mae: 8.2451\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 101.8464 - mae: 7.6001 - val_loss: 73.8321 - val_mae: 6.1960\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 65.6582 - mae: 5.3319 - val_loss: 42.2492 - val_mae: 4.2458\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 45.6116 - mae: 4.5314 - val_loss: 38.6438 - val_mae: 4.5750\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.3035 - mae: 4.5750 - val_loss: 37.5589 - val_mae: 4.3043\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.6642 - mae: 4.4703 - val_loss: 37.4486 - val_mae: 4.3553\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 43.8770 - mae: 4.5436 - val_loss: 37.2682 - val_mae: 4.3360\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.6467 - mae: 4.3881 - val_loss: 37.2131 - val_mae: 4.2640\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.1081 - mae: 4.4256 - val_loss: 37.1512 - val_mae: 4.3741\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 43.2192 - mae: 4.4991 - val_loss: 36.8969 - val_mae: 4.3099\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.0121 - mae: 4.4029 - val_loss: 36.7887 - val_mae: 4.2831\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.9188 - mae: 4.4262 - val_loss: 36.6844 - val_mae: 4.2970\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.9894 - mae: 4.3858 - val_loss: 36.6108 - val_mae: 4.3011\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.8132 - mae: 4.4942 - val_loss: 36.5871 - val_mae: 4.3219\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 42.5739 - mae: 4.4071 - val_loss: 36.4284 - val_mae: 4.2635\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 42.4975 - mae: 4.3990 - val_loss: 36.3453 - val_mae: 4.2796\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.4172 - mae: 4.3556 - val_loss: 36.3168 - val_mae: 4.2525\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 42.2041 - mae: 4.4177 - val_loss: 36.3623 - val_mae: 4.3167\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.1091 - mae: 4.4094 - val_loss: 36.1709 - val_mae: 4.2537\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.1827 - mae: 4.3373 - val_loss: 36.1391 - val_mae: 4.2392\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.9814 - mae: 4.3956 - val_loss: 35.9798 - val_mae: 4.2467\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 41.9866 - mae: 4.3454 - val_loss: 35.9046 - val_mae: 4.2386\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.6226 - mae: 4.3508 - val_loss: 35.9079 - val_mae: 4.2027\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.7032 - mae: 4.3026 - val_loss: 35.8928 - val_mae: 4.2100\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 41.4276 - mae: 4.3430 - val_loss: 35.8097 - val_mae: 4.2455\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.4373 - mae: 4.3837 - val_loss: 35.7736 - val_mae: 4.2122\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.2673 - mae: 4.3041 - val_loss: 35.7843 - val_mae: 4.2020\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 41.2895 - mae: 4.3316 - val_loss: 35.7163 - val_mae: 4.2013\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.3047 - mae: 4.3930 - val_loss: 35.6884 - val_mae: 4.2113\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.0102 - mae: 4.3581 - val_loss: 35.6772 - val_mae: 4.1969\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.8523 - mae: 4.3502 - val_loss: 35.6276 - val_mae: 4.2011\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 40.7486 - mae: 4.3137 - val_loss: 35.5007 - val_mae: 4.1490\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.6404 - mae: 4.2841 - val_loss: 35.4832 - val_mae: 4.1911\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 40.6916 - mae: 4.2733 - val_loss: 35.4916 - val_mae: 4.1589\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.6591 - mae: 4.3523 - val_loss: 35.4654 - val_mae: 4.1400\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 40.4486 - mae: 4.2342 - val_loss: 35.4109 - val_mae: 4.1157\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.5329 - mae: 4.3452 - val_loss: 35.3313 - val_mae: 4.1733\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.3698 - mae: 4.2300 - val_loss: 35.4237 - val_mae: 4.1018\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.0464 - mae: 4.3185 - val_loss: 35.6390 - val_mae: 4.2540\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.1417 - mae: 4.3021 - val_loss: 35.4434 - val_mae: 4.1080\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 39.8192 - mae: 4.2667 - val_loss: 35.5347 - val_mae: 4.1851\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 40.0493 - mae: 4.2721 - val_loss: 35.3162 - val_mae: 4.1311\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.7353 - mae: 4.2841 - val_loss: 35.2626 - val_mae: 4.1324\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.7485 - mae: 4.2048 - val_loss: 35.2541 - val_mae: 4.1034\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.5673 - mae: 4.2560 - val_loss: 35.2903 - val_mae: 4.1354\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.5187 - mae: 4.2274 - val_loss: 35.3676 - val_mae: 4.1230\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.4400 - mae: 4.2330 - val_loss: 35.3889 - val_mae: 4.1000\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.4524 - mae: 4.2025 - val_loss: 35.3725 - val_mae: 4.1109\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.2898 - mae: 4.2091 - val_loss: 35.4370 - val_mae: 4.0803\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.4617 - mae: 4.2926 - val_loss: 35.2902 - val_mae: 4.1161\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 39.3101 - mae: 4.2775\n",
      "Mean Absolute Error on Test Data: 4.277543067932129\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.07623286806701768\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 11ms/step - loss: 69.3936 - mae: 6.5531 - val_loss: 55.3984 - val_mae: 5.8650\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 52.1942 - mae: 5.1520 - val_loss: 36.0175 - val_mae: 4.1801\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 33.8961 - mae: 3.5805 - val_loss: 22.1608 - val_mae: 3.2811\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 26.6850 - mae: 3.3305 - val_loss: 21.7655 - val_mae: 3.4861\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.9605 - mae: 3.4675 - val_loss: 21.4102 - val_mae: 3.3772\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.8368 - mae: 3.3233 - val_loss: 21.3442 - val_mae: 3.3337\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 26.6964 - mae: 3.3660 - val_loss: 21.2802 - val_mae: 3.3715\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.6816 - mae: 3.3116 - val_loss: 21.2763 - val_mae: 3.3091\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 26.5969 - mae: 3.3036 - val_loss: 21.1728 - val_mae: 3.3280\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.5592 - mae: 3.3926 - val_loss: 21.1726 - val_mae: 3.3818\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.4156 - mae: 3.3560 - val_loss: 21.0994 - val_mae: 3.3080\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 26.4100 - mae: 3.3018 - val_loss: 21.0506 - val_mae: 3.3146\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.3841 - mae: 3.3048 - val_loss: 21.0289 - val_mae: 3.3102\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.3852 - mae: 3.3442 - val_loss: 20.9958 - val_mae: 3.3348\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 26.3328 - mae: 3.2828 - val_loss: 21.0254 - val_mae: 3.2885\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.2709 - mae: 3.3231 - val_loss: 20.9838 - val_mae: 3.3335\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.3203 - mae: 3.2680 - val_loss: 20.9609 - val_mae: 3.2740\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.2123 - mae: 3.3197 - val_loss: 20.8683 - val_mae: 3.3179\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.2005 - mae: 3.2835 - val_loss: 20.8505 - val_mae: 3.2948\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.1029 - mae: 3.2680 - val_loss: 20.8245 - val_mae: 3.3266\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.2327 - mae: 3.3976 - val_loss: 20.8022 - val_mae: 3.3016\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.9595 - mae: 3.3228 - val_loss: 20.8137 - val_mae: 3.2778\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.9996 - mae: 3.2584 - val_loss: 20.8477 - val_mae: 3.2548\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 25.8597 - mae: 3.2607 - val_loss: 20.7625 - val_mae: 3.3050\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 25.7728 - mae: 3.2620 - val_loss: 20.7709 - val_mae: 3.2706\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.7772 - mae: 3.2611 - val_loss: 20.7476 - val_mae: 3.2690\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.7122 - mae: 3.2403 - val_loss: 20.7415 - val_mae: 3.2689\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.7553 - mae: 3.2258 - val_loss: 20.6743 - val_mae: 3.2936\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 25.5487 - mae: 3.2408 - val_loss: 20.7515 - val_mae: 3.2748\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.5083 - mae: 3.2926 - val_loss: 20.6974 - val_mae: 3.2905\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.6295 - mae: 3.1886 - val_loss: 20.6357 - val_mae: 3.2547\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.9118 - mae: 3.4373 - val_loss: 20.7772 - val_mae: 3.3541\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.3729 - mae: 3.2598 - val_loss: 20.7608 - val_mae: 3.2749\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.2729 - mae: 3.2247 - val_loss: 20.6546 - val_mae: 3.2764\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.1968 - mae: 3.2749 - val_loss: 20.6700 - val_mae: 3.2950\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 25.0966 - mae: 3.2535 - val_loss: 20.6655 - val_mae: 3.2778\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 25.1189 - mae: 3.2568 - val_loss: 20.6837 - val_mae: 3.2914\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 25.0235 - mae: 3.2313 - val_loss: 20.6769 - val_mae: 3.2787\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.9716 - mae: 3.2510 - val_loss: 20.6185 - val_mae: 3.2489\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.0589 - mae: 3.1559 - val_loss: 20.5919 - val_mae: 3.2747\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 24.9661 - mae: 3.3105 - val_loss: 20.6253 - val_mae: 3.2732\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.7743 - mae: 3.2282 - val_loss: 20.7514 - val_mae: 3.2908\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.7571 - mae: 3.1931 - val_loss: 20.6823 - val_mae: 3.2781\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.6678 - mae: 3.2560 - val_loss: 20.7134 - val_mae: 3.2623\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.6585 - mae: 3.1708 - val_loss: 20.8193 - val_mae: 3.2627\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.5756 - mae: 3.1628 - val_loss: 20.8781 - val_mae: 3.3816\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.4467 - mae: 3.8055 - val_loss: 20.5110 - val_mae: 3.3335\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.2513 - mae: 3.0970 - val_loss: 20.7935 - val_mae: 3.1961\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.7881 - mae: 3.2968 - val_loss: 20.8311 - val_mae: 3.3960\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 25.1071 - mae: 3.4764 - val_loss: 20.9616 - val_mae: 3.3724\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 20.5110 - mae: 3.3970\n",
      "Mean Absolute Error on Test Data: 3.3970353603363037\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.05190558797555578\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 9ms/step - loss: 192.0256 - mae: 12.1028 - val_loss: 161.7383 - val_mae: 10.7821\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 150.3200 - mae: 10.2628 - val_loss: 109.7780 - val_mae: 8.2791\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 87.6432 - mae: 7.0825 - val_loss: 55.6610 - val_mae: 5.5891\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 48.6714 - mae: 5.2969 - val_loss: 50.1839 - val_mae: 5.5141\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 47.1810 - mae: 5.4064 - val_loss: 48.2726 - val_mae: 5.3450\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 46.1710 - mae: 5.2550 - val_loss: 47.8060 - val_mae: 5.2894\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 46.0483 - mae: 5.2928 - val_loss: 47.9446 - val_mae: 5.3160\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 45.8447 - mae: 5.2108 - val_loss: 47.3410 - val_mae: 5.2350\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 45.5043 - mae: 5.1826 - val_loss: 47.5362 - val_mae: 5.2734\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 45.4364 - mae: 5.2530 - val_loss: 47.6999 - val_mae: 5.2979\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 45.2051 - mae: 5.1832 - val_loss: 47.1017 - val_mae: 5.2217\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 45.1873 - mae: 5.2385 - val_loss: 47.7740 - val_mae: 5.3169\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 44.8371 - mae: 5.1697 - val_loss: 46.9221 - val_mae: 5.2079\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 44.8709 - mae: 5.1240 - val_loss: 46.9957 - val_mae: 5.2325\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.6347 - mae: 5.1877 - val_loss: 46.8776 - val_mae: 5.2209\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.5224 - mae: 5.1209 - val_loss: 46.8205 - val_mae: 5.2160\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 44.4909 - mae: 5.1810 - val_loss: 46.8735 - val_mae: 5.2222\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 44.2333 - mae: 5.1488 - val_loss: 46.6229 - val_mae: 5.1932\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 44.4307 - mae: 5.0804 - val_loss: 46.7167 - val_mae: 5.2114\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.9779 - mae: 5.1348 - val_loss: 46.8768 - val_mae: 5.2366\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.9336 - mae: 5.1366 - val_loss: 46.5861 - val_mae: 5.2046\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.0336 - mae: 5.0776 - val_loss: 46.7849 - val_mae: 5.2319\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 43.9623 - mae: 5.1729 - val_loss: 46.5677 - val_mae: 5.2091\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.6556 - mae: 5.1113 - val_loss: 46.3138 - val_mae: 5.1778\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.7370 - mae: 5.1335 - val_loss: 46.4427 - val_mae: 5.1951\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.6071 - mae: 5.0505 - val_loss: 46.2522 - val_mae: 5.1748\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.4026 - mae: 5.0724 - val_loss: 46.3565 - val_mae: 5.1904\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.4485 - mae: 5.0595 - val_loss: 46.4294 - val_mae: 5.2040\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.3674 - mae: 5.0717 - val_loss: 46.2080 - val_mae: 5.1771\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.5442 - mae: 5.1561 - val_loss: 46.2329 - val_mae: 5.1813\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.4689 - mae: 5.0399 - val_loss: 46.1377 - val_mae: 5.1744\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.2277 - mae: 5.0877 - val_loss: 46.0749 - val_mae: 5.1684\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.0433 - mae: 5.0569 - val_loss: 46.0966 - val_mae: 5.1774\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.9678 - mae: 5.0347 - val_loss: 46.0651 - val_mae: 5.1831\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 43.1662 - mae: 5.1277 - val_loss: 45.8754 - val_mae: 5.1582\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.9868 - mae: 5.0050 - val_loss: 46.0448 - val_mae: 5.1827\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.7899 - mae: 5.0533 - val_loss: 46.0830 - val_mae: 5.1932\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.9283 - mae: 5.0126 - val_loss: 46.0897 - val_mae: 5.1962\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.5887 - mae: 5.0373 - val_loss: 45.9049 - val_mae: 5.1758\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.5679 - mae: 5.0204 - val_loss: 45.7502 - val_mae: 5.1580\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 42.7199 - mae: 5.0595 - val_loss: 46.4227 - val_mae: 5.2481\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.0873 - mae: 4.9926 - val_loss: 45.7389 - val_mae: 5.1595\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.4412 - mae: 5.0440 - val_loss: 46.0426 - val_mae: 5.1997\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.3544 - mae: 5.0180 - val_loss: 46.0925 - val_mae: 5.2067\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.3048 - mae: 5.0172 - val_loss: 45.7607 - val_mae: 5.1691\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.4197 - mae: 4.9925 - val_loss: 45.8036 - val_mae: 5.1778\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.2091 - mae: 5.0132 - val_loss: 45.7094 - val_mae: 5.1688\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 42.2739 - mae: 5.0038 - val_loss: 45.7460 - val_mae: 5.1749\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 42.2605 - mae: 4.9992 - val_loss: 45.9158 - val_mae: 5.1999\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 42.1895 - mae: 5.0030 - val_loss: 45.8180 - val_mae: 5.1908\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 51.2529 - mae: 5.2677\n",
      "Mean Absolute Error on Test Data: 5.267653465270996\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.044061499660255965\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 15ms/step - loss: 26.4127 - mae: 3.9611 - val_loss: 16.9168 - val_mae: 3.0329\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6393 - mae: 2.8717 - val_loss: 9.5941 - val_mae: 2.2711\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7062 - mae: 2.3729 - val_loss: 9.6478 - val_mae: 2.5811\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.6089 - mae: 2.4824 - val_loss: 8.8324 - val_mae: 2.3902\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3787 - mae: 2.3701 - val_loss: 8.7782 - val_mae: 2.3785\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 10.3224 - mae: 2.4004 - val_loss: 8.9489 - val_mae: 2.4313\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2876 - mae: 2.3846 - val_loss: 8.7817 - val_mae: 2.3797\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.2676 - mae: 2.3665 - val_loss: 8.8452 - val_mae: 2.4066\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3133 - mae: 2.4331 - val_loss: 8.8234 - val_mae: 2.4021\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4314 - mae: 2.3532 - val_loss: 8.7219 - val_mae: 2.3677\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3654 - mae: 2.4390 - val_loss: 8.8456 - val_mae: 2.4056\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2378 - mae: 2.3641 - val_loss: 8.7122 - val_mae: 2.3647\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3258 - mae: 2.4106 - val_loss: 8.7286 - val_mae: 2.3730\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2385 - mae: 2.3592 - val_loss: 8.8203 - val_mae: 2.3997\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2772 - mae: 2.4325 - val_loss: 8.8028 - val_mae: 2.3959\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3071 - mae: 2.3379 - val_loss: 8.6917 - val_mae: 2.3589\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 10.1848 - mae: 2.4135 - val_loss: 9.0446 - val_mae: 2.4644\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.1493 - mae: 2.3897 - val_loss: 8.6702 - val_mae: 2.3406\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2538 - mae: 2.3825 - val_loss: 8.7635 - val_mae: 2.3777\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1461 - mae: 2.3508 - val_loss: 8.7253 - val_mae: 2.3645\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1810 - mae: 2.3840 - val_loss: 8.8001 - val_mae: 2.3937\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1412 - mae: 2.3669 - val_loss: 8.7995 - val_mae: 2.3987\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.1440 - mae: 2.3641 - val_loss: 8.7713 - val_mae: 2.3889\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1098 - mae: 2.3602 - val_loss: 8.7769 - val_mae: 2.3915\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1105 - mae: 2.3825 - val_loss: 8.7320 - val_mae: 2.3781\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0708 - mae: 2.3648 - val_loss: 8.7513 - val_mae: 2.3938\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0683 - mae: 2.3506 - val_loss: 8.6582 - val_mae: 2.3600\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0980 - mae: 2.3869 - val_loss: 8.7215 - val_mae: 2.3811\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.0873 - mae: 2.3347 - val_loss: 8.6875 - val_mae: 2.3696\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 10.0348 - mae: 2.3747 - val_loss: 8.8148 - val_mae: 2.4135\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0216 - mae: 2.3577 - val_loss: 8.6275 - val_mae: 2.3405\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0582 - mae: 2.3723 - val_loss: 8.6937 - val_mae: 2.3685\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.0992 - mae: 2.3244 - val_loss: 8.8177 - val_mae: 2.4137\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.0287 - mae: 2.3702 - val_loss: 8.6316 - val_mae: 2.3526\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.0651 - mae: 2.3738 - val_loss: 8.7649 - val_mae: 2.3805\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.0092 - mae: 2.3185 - val_loss: 8.6234 - val_mae: 2.3520\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.9559 - mae: 2.3661 - val_loss: 8.7775 - val_mae: 2.4061\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.9684 - mae: 2.3506 - val_loss: 8.6772 - val_mae: 2.3699\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.9531 - mae: 2.3700 - val_loss: 8.7385 - val_mae: 2.3822\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.9166 - mae: 2.3393 - val_loss: 8.6682 - val_mae: 2.3532\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.9681 - mae: 2.3102 - val_loss: 8.6561 - val_mae: 2.3690\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.9087 - mae: 2.3580 - val_loss: 8.6592 - val_mae: 2.3594\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.8995 - mae: 2.3172 - val_loss: 8.5880 - val_mae: 2.3450\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.8766 - mae: 2.3449 - val_loss: 8.7708 - val_mae: 2.3967\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.8690 - mae: 2.3291 - val_loss: 8.6871 - val_mae: 2.3707\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.8489 - mae: 2.3205 - val_loss: 8.6856 - val_mae: 2.3683\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.8480 - mae: 2.3423 - val_loss: 8.7007 - val_mae: 2.3696\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.8061 - mae: 2.3224 - val_loss: 8.7318 - val_mae: 2.3798\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.7983 - mae: 2.3290 - val_loss: 8.6631 - val_mae: 2.3635\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.8699 - mae: 2.3082 - val_loss: 8.6861 - val_mae: 2.3834\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.8971 - mae: 2.2516\n",
      "Mean Absolute Error on Test Data: 2.2515511512756348\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.019897644373922163\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 16ms/step - loss: 38.8627 - mae: 5.1955 - val_loss: 33.7928 - val_mae: 4.4021\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 22.7832 - mae: 3.6104 - val_loss: 17.8255 - val_mae: 2.7799\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 12.2862 - mae: 2.6131 - val_loss: 14.7725 - val_mae: 2.8822\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.8091 - mae: 2.6537 - val_loss: 14.3759 - val_mae: 2.7019\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.5181 - mae: 2.5384 - val_loss: 14.3804 - val_mae: 2.6907\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.4994 - mae: 2.5569 - val_loss: 14.2883 - val_mae: 2.7358\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.4231 - mae: 2.5728 - val_loss: 14.2817 - val_mae: 2.6956\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.5038 - mae: 2.5308 - val_loss: 14.2505 - val_mae: 2.6935\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.4565 - mae: 2.5963 - val_loss: 14.1644 - val_mae: 2.7314\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 11.3527 - mae: 2.5653 - val_loss: 14.1381 - val_mae: 2.6908\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.3338 - mae: 2.5392 - val_loss: 14.1409 - val_mae: 2.7049\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.3280 - mae: 2.5647 - val_loss: 14.1247 - val_mae: 2.7036\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.3292 - mae: 2.5344 - val_loss: 14.0956 - val_mae: 2.6901\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.3375 - mae: 2.5595 - val_loss: 14.0756 - val_mae: 2.6806\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.2854 - mae: 2.5292 - val_loss: 14.0268 - val_mae: 2.6888\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.2479 - mae: 2.5367 - val_loss: 14.1143 - val_mae: 2.6823\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.2577 - mae: 2.5609 - val_loss: 14.0970 - val_mae: 2.7153\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.2321 - mae: 2.5559 - val_loss: 14.0814 - val_mae: 2.7014\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.2177 - mae: 2.5476 - val_loss: 14.0870 - val_mae: 2.6741\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.2441 - mae: 2.5319 - val_loss: 14.0258 - val_mae: 2.6888\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.2583 - mae: 2.5900 - val_loss: 14.0976 - val_mae: 2.7312\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.1620 - mae: 2.5359 - val_loss: 14.0582 - val_mae: 2.6823\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 11.1935 - mae: 2.5264 - val_loss: 13.9321 - val_mae: 2.7075\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.1454 - mae: 2.5585 - val_loss: 13.8896 - val_mae: 2.6860\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.1400 - mae: 2.5219 - val_loss: 13.9229 - val_mae: 2.6848\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.1290 - mae: 2.5492 - val_loss: 14.0109 - val_mae: 2.7072\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.1067 - mae: 2.5494 - val_loss: 13.9694 - val_mae: 2.7142\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.1096 - mae: 2.5539 - val_loss: 13.9089 - val_mae: 2.6920\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.0946 - mae: 2.5336 - val_loss: 13.9598 - val_mae: 2.7061\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.2055 - mae: 2.6012 - val_loss: 14.0573 - val_mae: 2.7078\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.3051 - mae: 2.5256 - val_loss: 13.9685 - val_mae: 2.7186\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.2715 - mae: 2.6302 - val_loss: 13.9137 - val_mae: 2.6989\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.1428 - mae: 2.5074 - val_loss: 13.9519 - val_mae: 2.6689\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 11.0980 - mae: 2.5630 - val_loss: 13.9168 - val_mae: 2.7013\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.0621 - mae: 2.5515 - val_loss: 13.9005 - val_mae: 2.6879\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.0667 - mae: 2.5146 - val_loss: 14.0212 - val_mae: 2.7059\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.0846 - mae: 2.5780 - val_loss: 14.0389 - val_mae: 2.7063\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.9862 - mae: 2.5286 - val_loss: 14.0181 - val_mae: 2.6671\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.1519 - mae: 2.5046 - val_loss: 13.9459 - val_mae: 2.7144\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.1182 - mae: 2.6041 - val_loss: 13.9635 - val_mae: 2.7152\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.0085 - mae: 2.5113 - val_loss: 14.0113 - val_mae: 2.6798\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10.9569 - mae: 2.5360 - val_loss: 13.9594 - val_mae: 2.7121\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10.9949 - mae: 2.5242 - val_loss: 14.0115 - val_mae: 2.7150\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 11.0924 - mae: 2.5933 - val_loss: 14.1004 - val_mae: 2.6810\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.9744 - mae: 2.5143 - val_loss: 14.0164 - val_mae: 2.6898\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.9469 - mae: 2.5098 - val_loss: 14.0298 - val_mae: 2.6994\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10.9106 - mae: 2.5428 - val_loss: 13.9589 - val_mae: 2.7061\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10.8824 - mae: 2.5367 - val_loss: 14.0513 - val_mae: 2.6956\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10.9224 - mae: 2.5240 - val_loss: 13.9852 - val_mae: 2.6927\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.8805 - mae: 2.5136 - val_loss: 14.0127 - val_mae: 2.6903\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 16.7223 - mae: 2.9251\n",
      "Mean Absolute Error on Test Data: 2.925076484680176\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.07782106187419935\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 14ms/step - loss: 22.6337 - mae: 3.7911 - val_loss: 18.6581 - val_mae: 3.2220\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.7241 - mae: 2.5845 - val_loss: 10.1409 - val_mae: 2.3638\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.3231 - mae: 2.1904 - val_loss: 9.4581 - val_mae: 2.4337\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.4152 - mae: 2.2383 - val_loss: 9.3361 - val_mae: 2.3626\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2613 - mae: 2.1932 - val_loss: 9.3594 - val_mae: 2.3502\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2354 - mae: 2.1732 - val_loss: 9.3419 - val_mae: 2.3556\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2175 - mae: 2.1749 - val_loss: 9.3447 - val_mae: 2.3534\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2446 - mae: 2.1931 - val_loss: 9.3368 - val_mae: 2.3653\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.2381 - mae: 2.1564 - val_loss: 9.4029 - val_mae: 2.3443\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1797 - mae: 2.1681 - val_loss: 9.3533 - val_mae: 2.3797\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1833 - mae: 2.1785 - val_loss: 9.4063 - val_mae: 2.3439\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1836 - mae: 2.1647 - val_loss: 9.3548 - val_mae: 2.3578\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 8.1491 - mae: 2.1627 - val_loss: 9.3751 - val_mae: 2.3501\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.1395 - mae: 2.1582 - val_loss: 9.3544 - val_mae: 2.3589\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.1200 - mae: 2.1515 - val_loss: 9.3737 - val_mae: 2.3515\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.1085 - mae: 2.1529 - val_loss: 9.3718 - val_mae: 2.3545\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.1294 - mae: 2.1692 - val_loss: 9.3832 - val_mae: 2.3528\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.1494 - mae: 2.1533 - val_loss: 9.3800 - val_mae: 2.3539\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.1040 - mae: 2.1476 - val_loss: 9.3974 - val_mae: 2.3446\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.1522 - mae: 2.1644 - val_loss: 9.3968 - val_mae: 2.3490\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.1019 - mae: 2.1356 - val_loss: 9.3832 - val_mae: 2.3502\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0761 - mae: 2.1555 - val_loss: 9.3901 - val_mae: 2.3552\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.1228 - mae: 2.1333 - val_loss: 9.3748 - val_mae: 2.3588\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0783 - mae: 2.1698 - val_loss: 9.3792 - val_mae: 2.3568\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0427 - mae: 2.1309 - val_loss: 9.4317 - val_mae: 2.3360\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0971 - mae: 2.1559 - val_loss: 9.3981 - val_mae: 2.3523\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0291 - mae: 2.1346 - val_loss: 9.4246 - val_mae: 2.3398\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0531 - mae: 2.1401 - val_loss: 9.3891 - val_mae: 2.3457\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0366 - mae: 2.1312 - val_loss: 9.4086 - val_mae: 2.3434\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1269 - mae: 2.1780 - val_loss: 9.4066 - val_mae: 2.3468\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0694 - mae: 2.1077 - val_loss: 9.4243 - val_mae: 2.3369\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0215 - mae: 2.1402 - val_loss: 9.3749 - val_mae: 2.3540\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0762 - mae: 2.1262 - val_loss: 9.3830 - val_mae: 2.3501\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 8.0669 - mae: 2.1863 - val_loss: 9.3765 - val_mae: 2.3587\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.9958 - mae: 2.1187 - val_loss: 9.4238 - val_mae: 2.3354\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.9778 - mae: 2.1275 - val_loss: 9.3788 - val_mae: 2.3470\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.9973 - mae: 2.1430 - val_loss: 9.4453 - val_mae: 2.3343\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0539 - mae: 2.1272 - val_loss: 9.3746 - val_mae: 2.3583\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.9574 - mae: 2.1335 - val_loss: 9.4510 - val_mae: 2.3266\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0548 - mae: 2.1139 - val_loss: 9.3674 - val_mae: 2.3666\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.9835 - mae: 2.1408 - val_loss: 9.4129 - val_mae: 2.3321\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.9543 - mae: 2.1327 - val_loss: 9.3823 - val_mae: 2.3642\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 8.0024 - mae: 2.1264 - val_loss: 9.4066 - val_mae: 2.3513\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.9326 - mae: 2.1401 - val_loss: 9.4169 - val_mae: 2.3432\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.9353 - mae: 2.1061 - val_loss: 9.3756 - val_mae: 2.3483\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.9434 - mae: 2.1328 - val_loss: 9.4088 - val_mae: 2.3375\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.8906 - mae: 2.1208 - val_loss: 9.3987 - val_mae: 2.3476\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.9078 - mae: 2.1217 - val_loss: 9.3742 - val_mae: 2.3523\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.8922 - mae: 2.1312 - val_loss: 9.3862 - val_mae: 2.3496\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.8671 - mae: 2.1173 - val_loss: 9.4549 - val_mae: 2.3300\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.3445 - mae: 2.1538\n",
      "Mean Absolute Error on Test Data: 2.1537787914276123\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.024516263148287476\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 1s 14ms/step - loss: 8.0852 - mae: 2.0105 - val_loss: 6.9870 - val_mae: 1.8147\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.1122 - mae: 1.4392 - val_loss: 4.6912 - val_mae: 1.5334\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.4455 - mae: 1.5193 - val_loss: 4.4179 - val_mae: 1.5977\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.3395 - mae: 1.5118 - val_loss: 4.4594 - val_mae: 1.5557\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.2789 - mae: 1.4568 - val_loss: 4.4830 - val_mae: 1.5492\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.2608 - mae: 1.4450 - val_loss: 4.4956 - val_mae: 1.5489\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.2578 - mae: 1.4530 - val_loss: 4.4544 - val_mae: 1.5590\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.2406 - mae: 1.4451 - val_loss: 4.5032 - val_mae: 1.5479\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.2316 - mae: 1.4586 - val_loss: 4.4540 - val_mae: 1.5620\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.2218 - mae: 1.4373 - val_loss: 4.5237 - val_mae: 1.5461\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.2337 - mae: 1.4155 - val_loss: 4.4738 - val_mae: 1.5578\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.2199 - mae: 1.4937 - val_loss: 4.4135 - val_mae: 1.5988\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.2348 - mae: 1.4745 - val_loss: 4.4926 - val_mae: 1.5540\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.2161 - mae: 1.4288 - val_loss: 4.4704 - val_mae: 1.5606\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.2059 - mae: 1.4736 - val_loss: 4.4318 - val_mae: 1.5776\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.2406 - mae: 1.5112 - val_loss: 4.4324 - val_mae: 1.5805\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.1821 - mae: 1.4626 - val_loss: 4.5351 - val_mae: 1.5517\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.2053 - mae: 1.4350 - val_loss: 4.4926 - val_mae: 1.5608\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1992 - mae: 1.4207 - val_loss: 4.5353 - val_mae: 1.5492\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.1730 - mae: 1.4300 - val_loss: 4.4675 - val_mae: 1.5663\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.2082 - mae: 1.4863 - val_loss: 4.4315 - val_mae: 1.5818\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.1637 - mae: 1.4255 - val_loss: 4.5725 - val_mae: 1.5421\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1904 - mae: 1.3983 - val_loss: 4.5251 - val_mae: 1.5487\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1545 - mae: 1.4254 - val_loss: 4.4963 - val_mae: 1.5589\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1638 - mae: 1.4409 - val_loss: 4.5306 - val_mae: 1.5515\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.1616 - mae: 1.4470 - val_loss: 4.5085 - val_mae: 1.5581\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1623 - mae: 1.4182 - val_loss: 4.5148 - val_mae: 1.5497\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.1582 - mae: 1.4352 - val_loss: 4.4954 - val_mae: 1.5572\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1758 - mae: 1.4056 - val_loss: 4.4760 - val_mae: 1.5618\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.2427 - mae: 1.5196 - val_loss: 4.4336 - val_mae: 1.5852\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.1484 - mae: 1.4211 - val_loss: 4.6147 - val_mae: 1.5444\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 4.1589 - mae: 1.4564 - val_loss: 4.4631 - val_mae: 1.5776\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.1074 - mae: 1.4450 - val_loss: 4.5336 - val_mae: 1.5561\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.1196 - mae: 1.4307 - val_loss: 4.4861 - val_mae: 1.5677\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1114 - mae: 1.4524 - val_loss: 4.4656 - val_mae: 1.5750\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1573 - mae: 1.4889 - val_loss: 4.5318 - val_mae: 1.5704\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1569 - mae: 1.3959 - val_loss: 4.6570 - val_mae: 1.5517\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.1088 - mae: 1.4078 - val_loss: 4.5254 - val_mae: 1.5722\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0888 - mae: 1.4337 - val_loss: 4.5383 - val_mae: 1.5652\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.0834 - mae: 1.4219 - val_loss: 4.5066 - val_mae: 1.5726\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.1413 - mae: 1.4834 - val_loss: 4.4755 - val_mae: 1.5785\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0913 - mae: 1.4668 - val_loss: 4.5119 - val_mae: 1.5721\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0772 - mae: 1.4200 - val_loss: 4.6070 - val_mae: 1.5584\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.0654 - mae: 1.4141 - val_loss: 4.5268 - val_mae: 1.5660\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0664 - mae: 1.4258 - val_loss: 4.5461 - val_mae: 1.5615\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.0588 - mae: 1.4131 - val_loss: 4.5237 - val_mae: 1.5653\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.0713 - mae: 1.4525 - val_loss: 4.4667 - val_mae: 1.5816\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.0719 - mae: 1.4664 - val_loss: 4.5446 - val_mae: 1.5654\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0752 - mae: 1.3997 - val_loss: 4.5544 - val_mae: 1.5624\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0701 - mae: 1.4489 - val_loss: 4.4476 - val_mae: 1.5794\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.9527 - mae: 1.5035\n",
      "Mean Absolute Error on Test Data: 1.5035037994384766\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "R-squared: -0.005440229331746371\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 1s 15ms/step - loss: 6.7614 - mae: 1.8502 - val_loss: 5.6869 - val_mae: 1.5199\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4.1999 - mae: 1.3979 - val_loss: 4.0817 - val_mae: 1.4242\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.7072 - mae: 1.4452 - val_loss: 4.0448 - val_mae: 1.4416\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.6252 - mae: 1.3853 - val_loss: 4.0741 - val_mae: 1.3834\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.5997 - mae: 1.3624 - val_loss: 4.0314 - val_mae: 1.3866\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.5665 - mae: 1.3745 - val_loss: 3.9903 - val_mae: 1.3997\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.5423 - mae: 1.3882 - val_loss: 3.9749 - val_mae: 1.3942\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.5378 - mae: 1.3591 - val_loss: 3.9928 - val_mae: 1.3752\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3.4985 - mae: 1.3802 - val_loss: 3.9365 - val_mae: 1.4079\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.4999 - mae: 1.3947 - val_loss: 3.9406 - val_mae: 1.3790\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.5114 - mae: 1.3386 - val_loss: 3.9677 - val_mae: 1.3514\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.4799 - mae: 1.3677 - val_loss: 3.9053 - val_mae: 1.4005\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.4425 - mae: 1.3615 - val_loss: 3.9408 - val_mae: 1.3536\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.4504 - mae: 1.3629 - val_loss: 3.9047 - val_mae: 1.3750\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.4231 - mae: 1.3428 - val_loss: 3.9449 - val_mae: 1.3366\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.4457 - mae: 1.3261 - val_loss: 3.8985 - val_mae: 1.3527\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.4547 - mae: 1.3299 - val_loss: 3.8775 - val_mae: 1.3701\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.4142 - mae: 1.3666 - val_loss: 3.8774 - val_mae: 1.3644\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3.4209 - mae: 1.3220 - val_loss: 3.8888 - val_mae: 1.3516\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.3753 - mae: 1.3351 - val_loss: 3.8546 - val_mae: 1.3904\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.3967 - mae: 1.3936 - val_loss: 3.8550 - val_mae: 1.3966\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.3553 - mae: 1.3448 - val_loss: 3.8783 - val_mae: 1.3580\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.3564 - mae: 1.3338 - val_loss: 3.8648 - val_mae: 1.3818\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.3456 - mae: 1.3474 - val_loss: 3.8900 - val_mae: 1.3559\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.3726 - mae: 1.3165 - val_loss: 3.8926 - val_mae: 1.3541\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.3493 - mae: 1.3261 - val_loss: 3.8525 - val_mae: 1.4085\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.3633 - mae: 1.3940 - val_loss: 3.8566 - val_mae: 1.3957\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.3634 - mae: 1.3257 - val_loss: 3.8996 - val_mae: 1.3452\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3.3200 - mae: 1.3255 - val_loss: 3.8543 - val_mae: 1.4144\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.4549 - mae: 1.4365 - val_loss: 3.8483 - val_mae: 1.3846\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.3158 - mae: 1.3154 - val_loss: 3.8566 - val_mae: 1.3594\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.3278 - mae: 1.3816 - val_loss: 3.8520 - val_mae: 1.4232\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.3637 - mae: 1.3326 - val_loss: 3.8628 - val_mae: 1.3581\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.3869 - mae: 1.3939 - val_loss: 3.8530 - val_mae: 1.3910\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.3911 - mae: 1.3137 - val_loss: 3.8840 - val_mae: 1.3444\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.2947 - mae: 1.3485 - val_loss: 3.8418 - val_mae: 1.4176\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2751 - mae: 1.3347 - val_loss: 3.8532 - val_mae: 1.3653\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2869 - mae: 1.3484 - val_loss: 3.8338 - val_mae: 1.3871\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.3246 - mae: 1.3133 - val_loss: 3.8614 - val_mae: 1.3465\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2784 - mae: 1.3514 - val_loss: 3.8211 - val_mae: 1.4001\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.2508 - mae: 1.3345 - val_loss: 3.8334 - val_mae: 1.3719\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2574 - mae: 1.3252 - val_loss: 3.8251 - val_mae: 1.3927\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2991 - mae: 1.4022 - val_loss: 3.8647 - val_mae: 1.4306\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2490 - mae: 1.3189 - val_loss: 3.8631 - val_mae: 1.3301\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2886 - mae: 1.3395 - val_loss: 3.8161 - val_mae: 1.3917\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.2304 - mae: 1.3265 - val_loss: 3.8138 - val_mae: 1.3887\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2244 - mae: 1.3402 - val_loss: 3.8045 - val_mae: 1.3914\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3.2044 - mae: 1.3281 - val_loss: 3.8101 - val_mae: 1.3788\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.2024 - mae: 1.3406 - val_loss: 3.8002 - val_mae: 1.3982\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.2038 - mae: 1.3360 - val_loss: 3.8006 - val_mae: 1.3697\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.8793 - mae: 1.4714\n",
      "Mean Absolute Error on Test Data: 1.4714223146438599\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.0237063614914087\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 10ms/step - loss: 46.9286 - mae: 5.3899 - val_loss: 48.6984 - val_mae: 4.7224\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.2594 - mae: 4.2589 - val_loss: 35.2542 - val_mae: 3.6247\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 22.0074 - mae: 3.2400 - val_loss: 26.5568 - val_mae: 3.2758\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.4722 - mae: 3.2649 - val_loss: 26.4434 - val_mae: 3.4529\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 18.1319 - mae: 3.2018 - val_loss: 26.0527 - val_mae: 3.3098\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.1071 - mae: 3.1223 - val_loss: 25.9568 - val_mae: 3.2703\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.0055 - mae: 3.1604 - val_loss: 25.7033 - val_mae: 3.3313\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.9154 - mae: 3.1347 - val_loss: 25.6002 - val_mae: 3.2747\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.8125 - mae: 3.1272 - val_loss: 25.4663 - val_mae: 3.3050\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.7725 - mae: 3.1341 - val_loss: 25.3090 - val_mae: 3.2944\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.7787 - mae: 3.1365 - val_loss: 25.2607 - val_mae: 3.2646\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.6766 - mae: 3.1149 - val_loss: 25.1592 - val_mae: 3.2786\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.6473 - mae: 3.1078 - val_loss: 25.0515 - val_mae: 3.2907\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 17.6458 - mae: 3.1349 - val_loss: 25.0264 - val_mae: 3.2625\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.5992 - mae: 3.0930 - val_loss: 24.9164 - val_mae: 3.2722\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.4767 - mae: 3.0805 - val_loss: 24.9347 - val_mae: 3.2412\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 17.4970 - mae: 3.0892 - val_loss: 24.8410 - val_mae: 3.2947\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.5067 - mae: 3.0878 - val_loss: 24.8412 - val_mae: 3.2446\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.4213 - mae: 3.0977 - val_loss: 24.7966 - val_mae: 3.2630\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.3277 - mae: 3.0877 - val_loss: 24.7928 - val_mae: 3.2501\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.2774 - mae: 3.0578 - val_loss: 24.7666 - val_mae: 3.2551\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.2446 - mae: 3.0822 - val_loss: 24.7045 - val_mae: 3.2823\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 17.1712 - mae: 3.0517 - val_loss: 24.8050 - val_mae: 3.2183\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0940 - mae: 3.0553 - val_loss: 24.6424 - val_mae: 3.2726\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.1162 - mae: 3.0603 - val_loss: 24.5950 - val_mae: 3.2283\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.0459 - mae: 3.0461 - val_loss: 24.7001 - val_mae: 3.2509\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.9830 - mae: 3.0586 - val_loss: 24.6283 - val_mae: 3.2732\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8902 - mae: 3.0412 - val_loss: 24.6212 - val_mae: 3.2074\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8710 - mae: 3.0211 - val_loss: 24.6033 - val_mae: 3.2235\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.7954 - mae: 3.0387 - val_loss: 24.6226 - val_mae: 3.2371\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.7693 - mae: 3.0210 - val_loss: 24.7212 - val_mae: 3.2181\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.7639 - mae: 3.0320 - val_loss: 24.6698 - val_mae: 3.2778\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6419 - mae: 3.0195 - val_loss: 24.6869 - val_mae: 3.1953\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6510 - mae: 3.0065 - val_loss: 24.5928 - val_mae: 3.2027\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.6371 - mae: 3.0307 - val_loss: 24.8189 - val_mae: 3.1911\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.6105 - mae: 2.9911 - val_loss: 24.7587 - val_mae: 3.2500\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.5100 - mae: 3.0210 - val_loss: 24.7177 - val_mae: 3.2331\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.4897 - mae: 3.0297 - val_loss: 24.7487 - val_mae: 3.2189\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4620 - mae: 2.9691 - val_loss: 24.6903 - val_mae: 3.2052\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3806 - mae: 3.0191 - val_loss: 24.8292 - val_mae: 3.2283\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.3057 - mae: 2.9803 - val_loss: 24.8643 - val_mae: 3.2001\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2913 - mae: 2.9624 - val_loss: 24.9858 - val_mae: 3.2302\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2666 - mae: 3.0160 - val_loss: 24.8539 - val_mae: 3.2252\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2265 - mae: 2.9892 - val_loss: 24.9144 - val_mae: 3.1976\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2472 - mae: 2.9672 - val_loss: 24.8635 - val_mae: 3.2125\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1636 - mae: 2.9643 - val_loss: 24.8952 - val_mae: 3.2247\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2254 - mae: 2.9617 - val_loss: 24.9079 - val_mae: 3.2146\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.1022 - mae: 2.9992 - val_loss: 24.9861 - val_mae: 3.2397\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.0371 - mae: 2.9725 - val_loss: 24.9747 - val_mae: 3.2026\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0845 - mae: 2.9402 - val_loss: 24.8451 - val_mae: 3.2431\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.4966 - mae: 3.2180\n",
      "Mean Absolute Error on Test Data: 3.21795916557312\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.09818022776552127\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 15ms/step - loss: 41.1104 - mae: 4.5226 - val_loss: 45.4856 - val_mae: 4.4760\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 31.3636 - mae: 3.5372 - val_loss: 33.3665 - val_mae: 3.4103\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 21.8461 - mae: 2.8649 - val_loss: 25.4584 - val_mae: 3.2100\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 20.0082 - mae: 3.1169 - val_loss: 24.8442 - val_mae: 3.3390\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.5267 - mae: 2.9104 - val_loss: 24.9740 - val_mae: 3.1294\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 19.1159 - mae: 2.8222 - val_loss: 24.3441 - val_mae: 3.1747\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.8799 - mae: 2.9069 - val_loss: 23.9145 - val_mae: 3.1999\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 18.7103 - mae: 2.8414 - val_loss: 23.8859 - val_mae: 3.1200\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.5621 - mae: 2.8082 - val_loss: 23.7347 - val_mae: 3.1062\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.4962 - mae: 2.8489 - val_loss: 23.4332 - val_mae: 3.1257\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.3535 - mae: 2.7970 - val_loss: 23.2339 - val_mae: 3.1226\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.2565 - mae: 2.8662 - val_loss: 23.0815 - val_mae: 3.1254\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.1926 - mae: 2.8126 - val_loss: 23.1989 - val_mae: 3.0831\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.0315 - mae: 2.7571 - val_loss: 23.1153 - val_mae: 3.0784\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.9908 - mae: 2.7909 - val_loss: 22.8365 - val_mae: 3.1099\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 17.9328 - mae: 2.7547 - val_loss: 22.8408 - val_mae: 3.0948\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.8489 - mae: 2.7546 - val_loss: 22.7487 - val_mae: 3.1109\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.8628 - mae: 2.8279 - val_loss: 22.8942 - val_mae: 3.0770\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.6929 - mae: 2.7376 - val_loss: 22.7251 - val_mae: 3.0990\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.6639 - mae: 2.7595 - val_loss: 22.5967 - val_mae: 3.1218\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.5504 - mae: 2.7621 - val_loss: 22.8356 - val_mae: 3.0785\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.5738 - mae: 2.7571 - val_loss: 22.6906 - val_mae: 3.1014\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.4450 - mae: 2.7271 - val_loss: 22.7271 - val_mae: 3.0923\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.3607 - mae: 2.7462 - val_loss: 22.5594 - val_mae: 3.1183\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 17.3861 - mae: 2.7576 - val_loss: 22.7648 - val_mae: 3.0768\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2826 - mae: 2.7397 - val_loss: 22.5415 - val_mae: 3.1132\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2438 - mae: 2.7561 - val_loss: 22.6697 - val_mae: 3.0919\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.3392 - mae: 2.6865 - val_loss: 22.5759 - val_mae: 3.1084\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 17.1170 - mae: 2.7229 - val_loss: 22.4983 - val_mae: 3.1344\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0782 - mae: 2.7363 - val_loss: 22.6138 - val_mae: 3.1064\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0511 - mae: 2.6975 - val_loss: 22.5512 - val_mae: 3.1210\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.9996 - mae: 2.7265 - val_loss: 22.5457 - val_mae: 3.1315\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.9289 - mae: 2.7134 - val_loss: 22.7186 - val_mae: 3.0940\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.8780 - mae: 2.6757 - val_loss: 22.5687 - val_mae: 3.1309\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8400 - mae: 2.7482 - val_loss: 22.5952 - val_mae: 3.1323\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8521 - mae: 2.7184 - val_loss: 22.7473 - val_mae: 3.1056\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.7823 - mae: 2.6818 - val_loss: 22.6302 - val_mae: 3.1226\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8463 - mae: 2.6539 - val_loss: 22.5972 - val_mae: 3.1457\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.7770 - mae: 2.7133 - val_loss: 22.7465 - val_mae: 3.1239\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.6332 - mae: 2.6952 - val_loss: 22.6685 - val_mae: 3.1309\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6839 - mae: 2.7227 - val_loss: 22.7219 - val_mae: 3.1330\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.6492 - mae: 2.6416 - val_loss: 22.7137 - val_mae: 3.1399\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5543 - mae: 2.6950 - val_loss: 22.8106 - val_mae: 3.1272\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4599 - mae: 2.6573 - val_loss: 22.6982 - val_mae: 3.1540\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.4969 - mae: 2.7269 - val_loss: 22.8835 - val_mae: 3.1245\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.5915 - mae: 2.6305 - val_loss: 22.9035 - val_mae: 3.1277\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4391 - mae: 2.7078 - val_loss: 22.8869 - val_mae: 3.1455\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3814 - mae: 2.6376 - val_loss: 22.8521 - val_mae: 3.1545\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3608 - mae: 2.6924 - val_loss: 22.9034 - val_mae: 3.1445\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3299 - mae: 2.6494 - val_loss: 23.0451 - val_mae: 3.1324\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 23.3727 - mae: 3.0293\n",
      "Mean Absolute Error on Test Data: 3.029310464859009\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.08003028801889966\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 15ms/step - loss: 39.7187 - mae: 5.0158 - val_loss: 53.6085 - val_mae: 5.1530\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 28.4960 - mae: 3.9161 - val_loss: 38.6650 - val_mae: 3.8822\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.4080 - mae: 2.9255 - val_loss: 27.5649 - val_mae: 3.2727\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.8969 - mae: 2.9627 - val_loss: 26.7065 - val_mae: 3.4030\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.7177 - mae: 2.8775 - val_loss: 27.4471 - val_mae: 3.2736\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.5432 - mae: 2.8345 - val_loss: 27.1354 - val_mae: 3.3068\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.4882 - mae: 2.8574 - val_loss: 27.1254 - val_mae: 3.3036\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.4105 - mae: 2.8297 - val_loss: 27.2911 - val_mae: 3.2759\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.3536 - mae: 2.8160 - val_loss: 27.1357 - val_mae: 3.2930\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.3157 - mae: 2.8376 - val_loss: 26.8385 - val_mae: 3.3300\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.2577 - mae: 2.8499 - val_loss: 27.0246 - val_mae: 3.2883\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2248 - mae: 2.8004 - val_loss: 27.1093 - val_mae: 3.2668\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.1433 - mae: 2.8221 - val_loss: 26.8214 - val_mae: 3.3035\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1154 - mae: 2.8145 - val_loss: 27.0754 - val_mae: 3.2566\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.0528 - mae: 2.8059 - val_loss: 26.7826 - val_mae: 3.2852\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.0600 - mae: 2.7849 - val_loss: 26.9864 - val_mae: 3.2530\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.9629 - mae: 2.8057 - val_loss: 26.6315 - val_mae: 3.2924\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.9425 - mae: 2.8186 - val_loss: 26.7316 - val_mae: 3.2734\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.8809 - mae: 2.7711 - val_loss: 26.8499 - val_mae: 3.2499\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.8568 - mae: 2.7894 - val_loss: 26.6929 - val_mae: 3.2645\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.9846 - mae: 2.7523 - val_loss: 26.5897 - val_mae: 3.2777\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7917 - mae: 2.8071 - val_loss: 26.5345 - val_mae: 3.2734\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7321 - mae: 2.7915 - val_loss: 26.7367 - val_mae: 3.2360\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.7265 - mae: 2.7585 - val_loss: 26.6930 - val_mae: 3.2410\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6476 - mae: 2.7518 - val_loss: 26.6375 - val_mae: 3.2503\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6888 - mae: 2.7916 - val_loss: 26.8145 - val_mae: 3.2350\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6222 - mae: 2.7375 - val_loss: 26.4879 - val_mae: 3.2490\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.5938 - mae: 2.7895 - val_loss: 26.5691 - val_mae: 3.2489\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5795 - mae: 2.7262 - val_loss: 26.4092 - val_mae: 3.2457\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5156 - mae: 2.7585 - val_loss: 26.3534 - val_mae: 3.2507\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.5488 - mae: 2.7803 - val_loss: 26.5774 - val_mae: 3.2309\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.4520 - mae: 2.7322 - val_loss: 26.2096 - val_mae: 3.2680\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 13.4641 - mae: 2.7835 - val_loss: 26.5145 - val_mae: 3.2271\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3861 - mae: 2.7391 - val_loss: 26.2827 - val_mae: 3.2385\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3429 - mae: 2.7309 - val_loss: 26.1762 - val_mae: 3.2572\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3959 - mae: 2.7488 - val_loss: 26.6011 - val_mae: 3.2302\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3683 - mae: 2.7443 - val_loss: 26.1603 - val_mae: 3.2648\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3753 - mae: 2.7279 - val_loss: 26.3748 - val_mae: 3.2451\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.3104 - mae: 2.7693 - val_loss: 26.5429 - val_mae: 3.2278\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2549 - mae: 2.7009 - val_loss: 26.1773 - val_mae: 3.2560\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2539 - mae: 2.7512 - val_loss: 26.4111 - val_mae: 3.2248\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.1629 - mae: 2.7187 - val_loss: 26.2344 - val_mae: 3.2439\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 13.2361 - mae: 2.6989 - val_loss: 26.2430 - val_mae: 3.2602\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.2741 - mae: 2.7757 - val_loss: 26.4570 - val_mae: 3.2284\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1615 - mae: 2.6926 - val_loss: 26.2038 - val_mae: 3.2517\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.2534 - mae: 2.7801 - val_loss: 26.3928 - val_mae: 3.2251\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0856 - mae: 2.6976 - val_loss: 26.3920 - val_mae: 3.2329\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.1188 - mae: 2.7395 - val_loss: 26.2384 - val_mae: 3.2411\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.1045 - mae: 2.7182 - val_loss: 26.3189 - val_mae: 3.2377\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.0201 - mae: 2.7198 - val_loss: 26.1534 - val_mae: 3.2498\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 12.5965 - mae: 2.7413\n",
      "Mean Absolute Error on Test Data: 2.7412703037261963\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.03450968990945291\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 14ms/step - loss: 68.5206 - mae: 6.5077 - val_loss: 44.8061 - val_mae: 5.1760\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 46.2028 - mae: 4.7751 - val_loss: 24.6601 - val_mae: 3.3019\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 27.3044 - mae: 3.3944 - val_loss: 18.4935 - val_mae: 3.1985\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.8092 - mae: 3.6114 - val_loss: 18.6420 - val_mae: 3.2334\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.4784 - mae: 3.4902 - val_loss: 18.1972 - val_mae: 3.1129\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.3851 - mae: 3.4326 - val_loss: 18.3263 - val_mae: 3.1540\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 24.3280 - mae: 3.5087 - val_loss: 18.4882 - val_mae: 3.1903\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.2604 - mae: 3.4861 - val_loss: 18.2782 - val_mae: 3.1398\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.1352 - mae: 3.4105 - val_loss: 18.0983 - val_mae: 3.0795\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 24.2292 - mae: 3.4564 - val_loss: 18.1609 - val_mae: 3.1008\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 24.2572 - mae: 3.3337 - val_loss: 18.0070 - val_mae: 3.0345\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 24.0942 - mae: 3.4325 - val_loss: 18.2145 - val_mae: 3.1188\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.9494 - mae: 3.4652 - val_loss: 18.3847 - val_mae: 3.1620\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.0832 - mae: 3.5403 - val_loss: 18.3775 - val_mae: 3.1478\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 23.8077 - mae: 3.4098 - val_loss: 18.0631 - val_mae: 3.0451\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.9247 - mae: 3.3300 - val_loss: 18.1094 - val_mae: 3.0799\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.8890 - mae: 3.4760 - val_loss: 18.1848 - val_mae: 3.1073\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.8736 - mae: 3.3443 - val_loss: 17.9692 - val_mae: 3.0284\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.8375 - mae: 3.4565 - val_loss: 18.2706 - val_mae: 3.1262\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 23.7014 - mae: 3.3533 - val_loss: 17.9695 - val_mae: 3.0209\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.7890 - mae: 3.3176 - val_loss: 18.1316 - val_mae: 3.0809\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.7341 - mae: 3.4360 - val_loss: 18.4221 - val_mae: 3.1406\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 23.6588 - mae: 3.3960 - val_loss: 18.1344 - val_mae: 3.0704\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.7187 - mae: 3.4306 - val_loss: 18.0766 - val_mae: 3.0513\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.7793 - mae: 3.3208 - val_loss: 18.1085 - val_mae: 3.0703\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.5565 - mae: 3.3775 - val_loss: 18.0976 - val_mae: 3.0635\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.5675 - mae: 3.3464 - val_loss: 18.1462 - val_mae: 3.0724\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.5017 - mae: 3.3623 - val_loss: 18.0836 - val_mae: 3.0651\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 23.5512 - mae: 3.3791 - val_loss: 18.0029 - val_mae: 3.0325\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.6794 - mae: 3.3153 - val_loss: 18.3035 - val_mae: 3.1229\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.5514 - mae: 3.4428 - val_loss: 18.1430 - val_mae: 3.0778\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 23.4522 - mae: 3.3413 - val_loss: 18.3046 - val_mae: 3.1163\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 24.1508 - mae: 3.6056 - val_loss: 18.3471 - val_mae: 3.0963\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 23.6020 - mae: 3.2939 - val_loss: 18.1486 - val_mae: 3.0196\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 23.4175 - mae: 3.3123 - val_loss: 18.3633 - val_mae: 3.1212\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3980 - mae: 3.3988 - val_loss: 18.1760 - val_mae: 3.0614\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.4203 - mae: 3.3434 - val_loss: 18.2369 - val_mae: 3.0965\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 23.3397 - mae: 3.3710 - val_loss: 18.2440 - val_mae: 3.1016\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 23.3226 - mae: 3.3531 - val_loss: 18.1773 - val_mae: 3.0678\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3454 - mae: 3.4005 - val_loss: 18.2340 - val_mae: 3.0899\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3110 - mae: 3.3354 - val_loss: 18.1862 - val_mae: 3.0701\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 23.3967 - mae: 3.4357 - val_loss: 18.2361 - val_mae: 3.0833\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3505 - mae: 3.2828 - val_loss: 18.1579 - val_mae: 3.0331\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3008 - mae: 3.2850 - val_loss: 18.3230 - val_mae: 3.1142\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3175 - mae: 3.4683 - val_loss: 18.4012 - val_mae: 3.1347\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 23.2814 - mae: 3.3230 - val_loss: 18.1740 - val_mae: 3.0582\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 23.2104 - mae: 3.3787 - val_loss: 18.1995 - val_mae: 3.0717\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 23.2674 - mae: 3.2946 - val_loss: 18.2193 - val_mae: 3.0709\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3542 - mae: 3.4365 - val_loss: 18.1398 - val_mae: 3.0633\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.1576 - mae: 3.2797 - val_loss: 18.0958 - val_mae: 3.0390\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 22.2829 - mae: 3.5674\n",
      "Mean Absolute Error on Test Data: 3.5673794746398926\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.0739347312960954\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 1s 16ms/step - loss: 5.2804 - mae: 1.6195 - val_loss: 3.5706 - val_mae: 1.3178\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.0890 - mae: 1.2478 - val_loss: 3.0846 - val_mae: 1.3628\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.9109 - mae: 1.3027 - val_loss: 3.0134 - val_mae: 1.3281\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.8264 - mae: 1.2424 - val_loss: 2.9668 - val_mae: 1.2926\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.7920 - mae: 1.2315 - val_loss: 2.9714 - val_mae: 1.3105\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.7786 - mae: 1.2313 - val_loss: 2.9475 - val_mae: 1.2885\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.7691 - mae: 1.2341 - val_loss: 2.9430 - val_mae: 1.2901\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.7379 - mae: 1.2228 - val_loss: 2.9399 - val_mae: 1.2894\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.7371 - mae: 1.2320 - val_loss: 2.9306 - val_mae: 1.2792\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2.7363 - mae: 1.2270 - val_loss: 2.9377 - val_mae: 1.2921\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.7461 - mae: 1.2107 - val_loss: 2.9225 - val_mae: 1.2676\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6986 - mae: 1.2112 - val_loss: 2.9322 - val_mae: 1.2892\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.7227 - mae: 1.2421 - val_loss: 2.9237 - val_mae: 1.2812\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.7051 - mae: 1.2146 - val_loss: 2.9128 - val_mae: 1.2582\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.7009 - mae: 1.1992 - val_loss: 2.9118 - val_mae: 1.2692\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.6835 - mae: 1.2181 - val_loss: 2.9230 - val_mae: 1.2861\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6844 - mae: 1.2244 - val_loss: 2.9085 - val_mae: 1.2714\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6778 - mae: 1.2055 - val_loss: 2.9057 - val_mae: 1.2604\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2.6797 - mae: 1.2137 - val_loss: 2.9003 - val_mae: 1.2572\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6697 - mae: 1.2013 - val_loss: 2.8977 - val_mae: 1.2595\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6816 - mae: 1.2239 - val_loss: 2.9030 - val_mae: 1.2671\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6868 - mae: 1.2026 - val_loss: 2.9085 - val_mae: 1.2738\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.6562 - mae: 1.2082 - val_loss: 2.8952 - val_mae: 1.2543\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6600 - mae: 1.1956 - val_loss: 2.8985 - val_mae: 1.2636\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6804 - mae: 1.2283 - val_loss: 2.9066 - val_mae: 1.2746\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6786 - mae: 1.1953 - val_loss: 2.8895 - val_mae: 1.2458\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.6731 - mae: 1.2159 - val_loss: 2.8881 - val_mae: 1.2542\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6522 - mae: 1.2070 - val_loss: 2.8914 - val_mae: 1.2543\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6486 - mae: 1.1926 - val_loss: 2.8901 - val_mae: 1.2531\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6384 - mae: 1.2032 - val_loss: 2.8874 - val_mae: 1.2540\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6512 - mae: 1.2103 - val_loss: 2.8871 - val_mae: 1.2520\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6318 - mae: 1.1894 - val_loss: 2.8838 - val_mae: 1.2485\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6366 - mae: 1.2034 - val_loss: 2.8950 - val_mae: 1.2677\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6465 - mae: 1.1943 - val_loss: 2.8837 - val_mae: 1.2565\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.6312 - mae: 1.2042 - val_loss: 2.8851 - val_mae: 1.2569\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6249 - mae: 1.2016 - val_loss: 2.8762 - val_mae: 1.2368\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2.6394 - mae: 1.1794 - val_loss: 2.8757 - val_mae: 1.2499\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6350 - mae: 1.2174 - val_loss: 2.8854 - val_mae: 1.2587\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6405 - mae: 1.1862 - val_loss: 2.8885 - val_mae: 1.2517\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6097 - mae: 1.1957 - val_loss: 2.8812 - val_mae: 1.2531\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6197 - mae: 1.1865 - val_loss: 2.8828 - val_mae: 1.2625\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6215 - mae: 1.2110 - val_loss: 2.8768 - val_mae: 1.2547\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6094 - mae: 1.1825 - val_loss: 2.8737 - val_mae: 1.2418\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6160 - mae: 1.1992 - val_loss: 2.8712 - val_mae: 1.2382\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.6184 - mae: 1.1826 - val_loss: 2.8785 - val_mae: 1.2505\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2.5980 - mae: 1.1966 - val_loss: 2.8711 - val_mae: 1.2484\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6187 - mae: 1.1967 - val_loss: 2.8708 - val_mae: 1.2430\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.6012 - mae: 1.1743 - val_loss: 2.8701 - val_mae: 1.2406\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.5932 - mae: 1.1858 - val_loss: 2.8665 - val_mae: 1.2401\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.6047 - mae: 1.1774 - val_loss: 2.8710 - val_mae: 1.2533\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.0050 - mae: 1.3472\n",
      "Mean Absolute Error on Test Data: 1.3471928834915161\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "R-squared: -0.018733339344768174\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 17ms/step - loss: 60.0703 - mae: 4.8824 - val_loss: 58.1523 - val_mae: 4.6419\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 44.9767 - mae: 3.7615 - val_loss: 42.6147 - val_mae: 3.9397\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.8351 - mae: 3.8001 - val_loss: 38.4471 - val_mae: 4.3147\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.4025 - mae: 4.0962 - val_loss: 38.2622 - val_mae: 4.1872\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.9285 - mae: 3.8771 - val_loss: 38.2033 - val_mae: 4.1043\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.7199 - mae: 3.8505 - val_loss: 37.7889 - val_mae: 4.1260\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.5451 - mae: 3.8434 - val_loss: 37.4566 - val_mae: 4.1205\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 34.3306 - mae: 3.8722 - val_loss: 37.1156 - val_mae: 4.1343\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.1834 - mae: 3.8842 - val_loss: 36.9001 - val_mae: 4.1054\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.9480 - mae: 3.8149 - val_loss: 36.8586 - val_mae: 4.0399\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.9784 - mae: 3.8679 - val_loss: 36.3673 - val_mae: 4.0796\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 33.8057 - mae: 3.7331 - val_loss: 36.6092 - val_mae: 3.9743\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.4432 - mae: 3.7678 - val_loss: 35.8884 - val_mae: 4.0769\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.5991 - mae: 3.9457 - val_loss: 35.6801 - val_mae: 4.0458\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.1608 - mae: 3.7620 - val_loss: 35.9174 - val_mae: 3.9441\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.1304 - mae: 3.7066 - val_loss: 35.6035 - val_mae: 3.9692\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 32.9902 - mae: 3.7420 - val_loss: 35.1120 - val_mae: 4.0180\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.9639 - mae: 3.7809 - val_loss: 35.1091 - val_mae: 3.9831\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.8133 - mae: 3.8003 - val_loss: 34.8488 - val_mae: 3.9925\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.8418 - mae: 3.6912 - val_loss: 34.8680 - val_mae: 3.9441\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.5740 - mae: 3.7184 - val_loss: 34.5604 - val_mae: 3.9723\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.5286 - mae: 3.7827 - val_loss: 34.4983 - val_mae: 3.9414\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.5079 - mae: 3.7464 - val_loss: 34.5611 - val_mae: 3.8961\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.3814 - mae: 3.7088 - val_loss: 34.2238 - val_mae: 3.9375\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 32.2269 - mae: 3.7214 - val_loss: 34.2068 - val_mae: 3.9083\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.2509 - mae: 3.6374 - val_loss: 34.1963 - val_mae: 3.8836\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.1470 - mae: 3.7044 - val_loss: 33.9278 - val_mae: 3.9092\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.0552 - mae: 3.6797 - val_loss: 33.8425 - val_mae: 3.9259\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.9666 - mae: 3.7116 - val_loss: 34.1159 - val_mae: 3.8630\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.8879 - mae: 3.6366 - val_loss: 33.7372 - val_mae: 3.8841\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 31.8132 - mae: 3.6796 - val_loss: 33.8006 - val_mae: 3.8809\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 31.8446 - mae: 3.6910 - val_loss: 33.8405 - val_mae: 3.8467\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 31.6731 - mae: 3.5929 - val_loss: 33.6985 - val_mae: 3.8610\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.5726 - mae: 3.6189 - val_loss: 33.4513 - val_mae: 3.9158\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.5850 - mae: 3.6834 - val_loss: 33.4447 - val_mae: 3.8708\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.5661 - mae: 3.6847 - val_loss: 33.2354 - val_mae: 3.9088\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.3900 - mae: 3.5951 - val_loss: 33.5066 - val_mae: 3.8602\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.3264 - mae: 3.6143 - val_loss: 33.3157 - val_mae: 3.8858\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.3183 - mae: 3.6046 - val_loss: 33.2289 - val_mae: 3.9303\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 31.2360 - mae: 3.6346 - val_loss: 33.3417 - val_mae: 3.8602\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.1083 - mae: 3.5813 - val_loss: 33.0447 - val_mae: 3.9128\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.0110 - mae: 3.6455 - val_loss: 33.1105 - val_mae: 3.8982\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.0083 - mae: 3.5793 - val_loss: 33.0444 - val_mae: 3.9281\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 31.2184 - mae: 3.6060 - val_loss: 33.0416 - val_mae: 3.9159\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 30.9469 - mae: 3.5866 - val_loss: 32.9200 - val_mae: 3.9240\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.8186 - mae: 3.6711 - val_loss: 33.0013 - val_mae: 3.9051\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 30.7908 - mae: 3.5260 - val_loss: 33.1343 - val_mae: 3.8723\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 31.1113 - mae: 3.6999 - val_loss: 33.5532 - val_mae: 3.8232\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.7208 - mae: 3.5046 - val_loss: 33.0377 - val_mae: 3.8815\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.6113 - mae: 3.5865 - val_loss: 32.9188 - val_mae: 3.9356\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 20.3939 - mae: 3.2239\n",
      "Mean Absolute Error on Test Data: 3.223860025405884\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.12921805398689634\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 14ms/step - loss: 165.1693 - mae: 9.5976 - val_loss: 132.2365 - val_mae: 8.0627\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 137.6422 - mae: 8.0668 - val_loss: 102.7169 - val_mae: 6.2319\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 98.6838 - mae: 5.9779 - val_loss: 72.0888 - val_mae: 4.9260\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 73.9916 - mae: 5.4102 - val_loss: 70.8369 - val_mae: 5.8109\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 73.4434 - mae: 5.8390 - val_loss: 68.2878 - val_mae: 5.4947\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 71.6064 - mae: 5.3778 - val_loss: 66.6110 - val_mae: 5.2164\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 70.1881 - mae: 5.3906 - val_loss: 66.3811 - val_mae: 5.3199\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 69.0691 - mae: 5.3272 - val_loss: 65.5715 - val_mae: 5.2275\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 68.1683 - mae: 5.2991 - val_loss: 65.2241 - val_mae: 5.2226\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 67.3821 - mae: 5.2708 - val_loss: 64.8121 - val_mae: 5.1887\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 66.7374 - mae: 5.2281 - val_loss: 64.5596 - val_mae: 5.1789\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 66.1498 - mae: 5.1915 - val_loss: 64.0770 - val_mae: 5.1004\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 65.9136 - mae: 5.2095 - val_loss: 64.1039 - val_mae: 5.1283\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 65.7151 - mae: 5.1824 - val_loss: 63.9115 - val_mae: 5.1038\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 64.9790 - mae: 5.0952 - val_loss: 63.6121 - val_mae: 5.0400\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 64.8664 - mae: 5.0617 - val_loss: 63.8100 - val_mae: 5.1084\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 64.9395 - mae: 5.2969 - val_loss: 64.0863 - val_mae: 5.1621\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 63.8979 - mae: 5.0647 - val_loss: 63.2361 - val_mae: 4.9716\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 63.8328 - mae: 5.1113 - val_loss: 63.5774 - val_mae: 5.0673\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 63.8880 - mae: 5.0307 - val_loss: 63.3393 - val_mae: 5.0273\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 63.4699 - mae: 5.1200 - val_loss: 63.2500 - val_mae: 5.0220\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 63.1164 - mae: 4.9867 - val_loss: 62.9670 - val_mae: 4.9690\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 63.0450 - mae: 5.0768 - val_loss: 63.4175 - val_mae: 5.0751\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 62.6351 - mae: 5.0222 - val_loss: 62.8263 - val_mae: 4.9223\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 62.3844 - mae: 4.9689 - val_loss: 63.0622 - val_mae: 4.9966\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 62.3394 - mae: 5.0323 - val_loss: 62.7893 - val_mae: 4.9192\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62.1529 - mae: 4.9392 - val_loss: 62.8604 - val_mae: 4.9477\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 61.8506 - mae: 4.9207 - val_loss: 62.8142 - val_mae: 4.9609\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 61.7642 - mae: 4.9859 - val_loss: 62.7016 - val_mae: 4.9513\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 61.4396 - mae: 4.9592 - val_loss: 62.7343 - val_mae: 4.9582\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 61.1672 - mae: 4.8886 - val_loss: 62.3333 - val_mae: 4.8352\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 61.2803 - mae: 4.9494 - val_loss: 63.0954 - val_mae: 5.0403\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 61.0788 - mae: 4.9751 - val_loss: 62.4539 - val_mae: 4.9066\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 61.1450 - mae: 4.8150 - val_loss: 62.2557 - val_mae: 4.8785\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 60.8229 - mae: 4.8762 - val_loss: 62.4865 - val_mae: 4.9383\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 60.5533 - mae: 4.9066 - val_loss: 62.6699 - val_mae: 4.9927\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 61.1970 - mae: 5.1423 - val_loss: 63.5522 - val_mae: 5.0826\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 60.4429 - mae: 4.8256 - val_loss: 62.2375 - val_mae: 4.7981\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 60.2470 - mae: 4.8631 - val_loss: 62.7647 - val_mae: 4.9745\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 60.1221 - mae: 4.9202 - val_loss: 62.4506 - val_mae: 4.9038\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 59.9944 - mae: 4.8871 - val_loss: 62.3996 - val_mae: 4.8781\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 59.9709 - mae: 4.8614 - val_loss: 62.2899 - val_mae: 4.8317\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 59.9552 - mae: 4.7465 - val_loss: 62.7536 - val_mae: 4.9619\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 59.8077 - mae: 4.9492 - val_loss: 62.6903 - val_mae: 4.9534\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 59.6369 - mae: 4.8756 - val_loss: 62.3446 - val_mae: 4.8238\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 59.5967 - mae: 4.8041 - val_loss: 62.3648 - val_mae: 4.8241\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 59.6574 - mae: 4.7454 - val_loss: 62.4426 - val_mae: 4.8637\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 59.1141 - mae: 4.8392 - val_loss: 63.1735 - val_mae: 5.0118\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 59.3426 - mae: 4.9059 - val_loss: 62.4952 - val_mae: 4.8586\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 59.2480 - mae: 4.7390 - val_loss: 62.4819 - val_mae: 4.8385\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 50.3668 - mae: 4.9482\n",
      "Mean Absolute Error on Test Data: 4.948178768157959\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.15609959247448701\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 15ms/step - loss: 93.5845 - mae: 8.0063 - val_loss: 89.9150 - val_mae: 7.6900\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 72.0836 - mae: 6.6020 - val_loss: 61.4552 - val_mae: 5.7901\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.2334 - mae: 4.4515 - val_loss: 32.5948 - val_mae: 3.9902\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 29.1598 - mae: 4.0088 - val_loss: 29.5443 - val_mae: 4.2291\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.5969 - mae: 3.9928 - val_loss: 29.5490 - val_mae: 3.9689\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.3334 - mae: 3.8470 - val_loss: 29.2130 - val_mae: 3.9825\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.1393 - mae: 3.8796 - val_loss: 29.0098 - val_mae: 3.9746\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.0905 - mae: 3.9053 - val_loss: 28.9325 - val_mae: 3.9569\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.9757 - mae: 3.8519 - val_loss: 28.6992 - val_mae: 3.9576\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.8971 - mae: 3.8749 - val_loss: 28.4930 - val_mae: 3.9599\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 27.8354 - mae: 3.8994 - val_loss: 28.2925 - val_mae: 3.9672\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.8136 - mae: 3.8840 - val_loss: 28.4144 - val_mae: 3.9214\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.8062 - mae: 3.8724 - val_loss: 28.2721 - val_mae: 3.9209\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.8291 - mae: 3.9000 - val_loss: 28.2763 - val_mae: 3.9069\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.6400 - mae: 3.8153 - val_loss: 28.2792 - val_mae: 3.8955\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.5738 - mae: 3.8753 - val_loss: 27.9642 - val_mae: 3.9227\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 27.5046 - mae: 3.8632 - val_loss: 28.0186 - val_mae: 3.9031\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 27.5816 - mae: 3.8331 - val_loss: 27.8209 - val_mae: 3.9095\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.4961 - mae: 3.8530 - val_loss: 27.8234 - val_mae: 3.8975\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 27.4294 - mae: 3.8552 - val_loss: 27.5870 - val_mae: 3.8981\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.4850 - mae: 3.8387 - val_loss: 27.7352 - val_mae: 3.8604\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.4286 - mae: 3.8699 - val_loss: 27.4761 - val_mae: 3.8746\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 27.3322 - mae: 3.8162 - val_loss: 27.6187 - val_mae: 3.8545\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.3765 - mae: 3.8006 - val_loss: 27.4510 - val_mae: 3.8622\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.3616 - mae: 3.8186 - val_loss: 27.3194 - val_mae: 3.8592\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.2223 - mae: 3.8217 - val_loss: 27.2175 - val_mae: 3.8639\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 27.3861 - mae: 3.9008 - val_loss: 27.2257 - val_mae: 3.8563\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 27.1874 - mae: 3.8204 - val_loss: 27.3136 - val_mae: 3.8461\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 27.2108 - mae: 3.7986 - val_loss: 27.4006 - val_mae: 3.8381\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.4711 - mae: 3.8718 - val_loss: 27.4197 - val_mae: 3.8352\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.1044 - mae: 3.8401 - val_loss: 27.0318 - val_mae: 3.8632\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.1062 - mae: 3.8333 - val_loss: 27.0203 - val_mae: 3.8492\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.3641 - mae: 3.9336 - val_loss: 27.0897 - val_mae: 3.8421\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 27.4690 - mae: 3.7744 - val_loss: 27.2855 - val_mae: 3.8170\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 27.4195 - mae: 3.9360 - val_loss: 26.8200 - val_mae: 3.8696\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 27.0873 - mae: 3.8125 - val_loss: 27.2654 - val_mae: 3.8150\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.0129 - mae: 3.8116 - val_loss: 26.7315 - val_mae: 3.8664\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.0272 - mae: 3.8306 - val_loss: 27.2067 - val_mae: 3.8188\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.9258 - mae: 3.7996 - val_loss: 26.7399 - val_mae: 3.8583\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.3557 - mae: 3.8979 - val_loss: 26.8379 - val_mae: 3.8251\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.9092 - mae: 3.8279 - val_loss: 26.8243 - val_mae: 3.8332\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 26.9110 - mae: 3.8341 - val_loss: 26.9621 - val_mae: 3.8178\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.0319 - mae: 3.7603 - val_loss: 26.9384 - val_mae: 3.8130\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.8363 - mae: 3.8153 - val_loss: 26.6483 - val_mae: 3.8299\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.8418 - mae: 3.8256 - val_loss: 26.7024 - val_mae: 3.8216\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.8532 - mae: 3.8131 - val_loss: 26.9723 - val_mae: 3.7951\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.2510 - mae: 3.7510 - val_loss: 26.6536 - val_mae: 3.8105\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 26.8006 - mae: 3.8214 - val_loss: 26.6802 - val_mae: 3.8001\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.9049 - mae: 3.7733 - val_loss: 26.5608 - val_mae: 3.8082\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.7281 - mae: 3.8020 - val_loss: 26.6317 - val_mae: 3.8114\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 30.5253 - mae: 3.9324\n",
      "Mean Absolute Error on Test Data: 3.9324095249176025\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.05535861519856433\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 12ms/step - loss: 68.3888 - mae: 6.7353 - val_loss: 53.3380 - val_mae: 5.6075\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 46.7572 - mae: 5.0738 - val_loss: 31.3683 - val_mae: 3.8570\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 26.2826 - mae: 3.6521 - val_loss: 22.1692 - val_mae: 3.4421\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.2644 - mae: 3.7565 - val_loss: 22.3080 - val_mae: 3.4999\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.4158 - mae: 3.5982 - val_loss: 21.6155 - val_mae: 3.3536\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.2463 - mae: 3.5082 - val_loss: 21.4868 - val_mae: 3.3153\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.1893 - mae: 3.5184 - val_loss: 21.4809 - val_mae: 3.3423\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.2025 - mae: 3.5283 - val_loss: 21.3672 - val_mae: 3.3089\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 22.4360 - mae: 3.4662 - val_loss: 21.3347 - val_mae: 3.3098\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 22.1303 - mae: 3.5668 - val_loss: 21.6265 - val_mae: 3.4172\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.0762 - mae: 3.5489 - val_loss: 21.4005 - val_mae: 3.3522\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.0335 - mae: 3.4919 - val_loss: 21.2835 - val_mae: 3.3007\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.0086 - mae: 3.4624 - val_loss: 21.2362 - val_mae: 3.2972\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.9247 - mae: 3.4960 - val_loss: 21.3376 - val_mae: 3.3516\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.9205 - mae: 3.5082 - val_loss: 21.2567 - val_mae: 3.3203\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 21.9032 - mae: 3.4915 - val_loss: 21.2420 - val_mae: 3.3069\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 21.9082 - mae: 3.4884 - val_loss: 21.2048 - val_mae: 3.3029\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.8785 - mae: 3.4833 - val_loss: 21.2859 - val_mae: 3.3541\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.8245 - mae: 3.4790 - val_loss: 21.1783 - val_mae: 3.3105\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.8111 - mae: 3.5209 - val_loss: 21.2873 - val_mae: 3.3619\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.7807 - mae: 3.4518 - val_loss: 21.1914 - val_mae: 3.3263\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.9283 - mae: 3.5620 - val_loss: 21.2642 - val_mae: 3.3366\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.7173 - mae: 3.4689 - val_loss: 21.2233 - val_mae: 3.3412\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 21.7577 - mae: 3.5279 - val_loss: 21.4185 - val_mae: 3.4151\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.4258 - mae: 3.6845 - val_loss: 21.1849 - val_mae: 3.3493\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.6078 - mae: 3.4298 - val_loss: 21.0539 - val_mae: 3.2689\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.8545 - mae: 3.5324 - val_loss: 21.1595 - val_mae: 3.3400\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.5263 - mae: 3.4664 - val_loss: 21.0446 - val_mae: 3.2822\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 21.6454 - mae: 3.4628 - val_loss: 21.2262 - val_mae: 3.3771\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.4159 - mae: 3.4642 - val_loss: 21.0383 - val_mae: 3.3074\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.4144 - mae: 3.4453 - val_loss: 21.0805 - val_mae: 3.3338\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.4784 - mae: 3.5125 - val_loss: 21.1187 - val_mae: 3.3540\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.7046 - mae: 3.4306 - val_loss: 21.1056 - val_mae: 3.3462\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.4378 - mae: 3.5022 - val_loss: 20.9976 - val_mae: 3.3104\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.2633 - mae: 3.4209 - val_loss: 20.9264 - val_mae: 3.2889\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.3899 - mae: 3.4724 - val_loss: 20.9936 - val_mae: 3.3321\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 21.4272 - mae: 3.4093 - val_loss: 20.9569 - val_mae: 3.3104\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.2696 - mae: 3.4749 - val_loss: 21.0272 - val_mae: 3.3469\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.1601 - mae: 3.4114 - val_loss: 20.9238 - val_mae: 3.3188\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.2610 - mae: 3.5278 - val_loss: 21.1148 - val_mae: 3.3771\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.2229 - mae: 3.4495 - val_loss: 20.9816 - val_mae: 3.3391\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.7097 - mae: 3.5363 - val_loss: 20.8642 - val_mae: 3.2994\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 21.0301 - mae: 3.4495 - val_loss: 21.0241 - val_mae: 3.3556\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 21.0414 - mae: 3.4396 - val_loss: 20.8485 - val_mae: 3.2936\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 20.9777 - mae: 3.4070 - val_loss: 20.9661 - val_mae: 3.3494\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 20.9410 - mae: 3.4366 - val_loss: 20.8713 - val_mae: 3.3235\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.9297 - mae: 3.4049 - val_loss: 20.8649 - val_mae: 3.3141\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 20.9118 - mae: 3.4094 - val_loss: 21.0024 - val_mae: 3.3650\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.9169 - mae: 3.4700 - val_loss: 20.7766 - val_mae: 3.2823\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.8642 - mae: 3.3910 - val_loss: 20.8595 - val_mae: 3.3108\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 24.2975 - mae: 3.4590\n",
      "Mean Absolute Error on Test Data: 3.4589779376983643\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.08712517470209868\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 19ms/step - loss: 6.9213 - mae: 1.7361 - val_loss: 8.0398 - val_mae: 1.5967\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.7928 - mae: 1.2327 - val_loss: 6.0301 - val_mae: 1.3099\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.1463 - mae: 1.2448 - val_loss: 5.6504 - val_mae: 1.3700\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.0856 - mae: 1.2725 - val_loss: 5.6884 - val_mae: 1.3130\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.0391 - mae: 1.2032 - val_loss: 5.7583 - val_mae: 1.3006\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0278 - mae: 1.1935 - val_loss: 5.7136 - val_mae: 1.3032\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.0299 - mae: 1.2182 - val_loss: 5.6678 - val_mae: 1.3103\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.0031 - mae: 1.2034 - val_loss: 5.6850 - val_mae: 1.3053\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.0006 - mae: 1.2070 - val_loss: 5.6884 - val_mae: 1.3052\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9903 - mae: 1.1938 - val_loss: 5.6905 - val_mae: 1.3058\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.9936 - mae: 1.2153 - val_loss: 5.6307 - val_mae: 1.3202\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9862 - mae: 1.2143 - val_loss: 5.6590 - val_mae: 1.3129\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9755 - mae: 1.1913 - val_loss: 5.6882 - val_mae: 1.3103\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9735 - mae: 1.2032 - val_loss: 5.6622 - val_mae: 1.3139\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9655 - mae: 1.2036 - val_loss: 5.6659 - val_mae: 1.3140\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9564 - mae: 1.1969 - val_loss: 5.6660 - val_mae: 1.3154\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9611 - mae: 1.1896 - val_loss: 5.6673 - val_mae: 1.3152\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.9463 - mae: 1.2055 - val_loss: 5.6279 - val_mae: 1.3234\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9740 - mae: 1.1983 - val_loss: 5.7028 - val_mae: 1.3124\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9298 - mae: 1.1961 - val_loss: 5.6122 - val_mae: 1.3258\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9494 - mae: 1.2066 - val_loss: 5.6247 - val_mae: 1.3243\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9410 - mae: 1.2016 - val_loss: 5.6271 - val_mae: 1.3240\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9434 - mae: 1.2089 - val_loss: 5.6523 - val_mae: 1.3202\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9288 - mae: 1.2030 - val_loss: 5.6091 - val_mae: 1.3292\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.9335 - mae: 1.2160 - val_loss: 5.6175 - val_mae: 1.3299\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9439 - mae: 1.1877 - val_loss: 5.7076 - val_mae: 1.3156\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9242 - mae: 1.1864 - val_loss: 5.6367 - val_mae: 1.3256\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9196 - mae: 1.2115 - val_loss: 5.6034 - val_mae: 1.3314\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9235 - mae: 1.2200 - val_loss: 5.6037 - val_mae: 1.3335\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9555 - mae: 1.1894 - val_loss: 5.7747 - val_mae: 1.3140\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9283 - mae: 1.2126 - val_loss: 5.5754 - val_mae: 1.3425\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9212 - mae: 1.2159 - val_loss: 5.6864 - val_mae: 1.3207\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9227 - mae: 1.2052 - val_loss: 5.6212 - val_mae: 1.3274\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9145 - mae: 1.1913 - val_loss: 5.7076 - val_mae: 1.3168\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9114 - mae: 1.2071 - val_loss: 5.5943 - val_mae: 1.3367\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9095 - mae: 1.2000 - val_loss: 5.6686 - val_mae: 1.3224\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9464 - mae: 1.2333 - val_loss: 5.6187 - val_mae: 1.3322\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.8898 - mae: 1.1908 - val_loss: 5.6966 - val_mae: 1.3197\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9182 - mae: 1.1881 - val_loss: 5.6166 - val_mae: 1.3307\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.9140 - mae: 1.2218 - val_loss: 5.6313 - val_mae: 1.3302\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9020 - mae: 1.1862 - val_loss: 5.7280 - val_mae: 1.3166\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.8974 - mae: 1.1943 - val_loss: 5.6358 - val_mae: 1.3273\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8870 - mae: 1.2087 - val_loss: 5.6189 - val_mae: 1.3300\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8790 - mae: 1.1979 - val_loss: 5.6384 - val_mae: 1.3265\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8774 - mae: 1.1966 - val_loss: 5.6282 - val_mae: 1.3283\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.8890 - mae: 1.2176 - val_loss: 5.6057 - val_mae: 1.3344\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.8760 - mae: 1.1894 - val_loss: 5.6906 - val_mae: 1.3171\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.8684 - mae: 1.1911 - val_loss: 5.6075 - val_mae: 1.3288\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.8907 - mae: 1.2222 - val_loss: 5.6263 - val_mae: 1.3289\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.8631 - mae: 1.1989 - val_loss: 5.6415 - val_mae: 1.3239\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.5100 - mae: 1.1128\n",
      "Mean Absolute Error on Test Data: 1.1128218173980713\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.021803697578666292\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 147.3321 - mae: 9.9784 - val_loss: 149.6711 - val_mae: 9.2956\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 120.6190 - mae: 8.6146 - val_loss: 120.1123 - val_mae: 7.7376\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 86.0227 - mae: 6.6537 - val_loss: 81.0315 - val_mae: 5.7293\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 52.7965 - mae: 4.8825 - val_loss: 60.4190 - val_mae: 5.4969\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 46.0213 - mae: 4.9429 - val_loss: 60.2021 - val_mae: 5.7206\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 44.9515 - mae: 4.7953 - val_loss: 59.7164 - val_mae: 5.5088\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.6997 - mae: 4.7135 - val_loss: 59.4132 - val_mae: 5.5077\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.6650 - mae: 4.7899 - val_loss: 59.2274 - val_mae: 5.5844\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 44.5141 - mae: 4.7485 - val_loss: 59.0489 - val_mae: 5.5024\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.4132 - mae: 4.7423 - val_loss: 58.8370 - val_mae: 5.5296\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.4090 - mae: 4.7018 - val_loss: 58.7888 - val_mae: 5.4554\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 44.2562 - mae: 4.7294 - val_loss: 58.5716 - val_mae: 5.5232\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.4348 - mae: 4.6847 - val_loss: 58.5411 - val_mae: 5.4277\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 44.2365 - mae: 4.7354 - val_loss: 58.3936 - val_mae: 5.5196\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.2364 - mae: 4.6648 - val_loss: 58.3189 - val_mae: 5.4230\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.9439 - mae: 4.6736 - val_loss: 58.2191 - val_mae: 5.4817\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.0393 - mae: 4.7232 - val_loss: 58.1218 - val_mae: 5.4612\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.8920 - mae: 4.6493 - val_loss: 58.1784 - val_mae: 5.3936\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 44.0537 - mae: 4.6220 - val_loss: 58.0751 - val_mae: 5.4010\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.8810 - mae: 4.6532 - val_loss: 57.9871 - val_mae: 5.4289\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.9406 - mae: 4.7045 - val_loss: 58.0250 - val_mae: 5.4924\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.9467 - mae: 4.6753 - val_loss: 57.9607 - val_mae: 5.3996\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.8137 - mae: 4.6556 - val_loss: 57.8878 - val_mae: 5.4355\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.8599 - mae: 4.6399 - val_loss: 57.8326 - val_mae: 5.4054\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 44.1225 - mae: 4.7368 - val_loss: 57.7588 - val_mae: 5.4317\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.4300 - mae: 4.5675 - val_loss: 57.9325 - val_mae: 5.3406\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.0683 - mae: 4.7135 - val_loss: 57.7247 - val_mae: 5.4600\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.6533 - mae: 4.6208 - val_loss: 57.8162 - val_mae: 5.3527\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 43.8298 - mae: 4.6517 - val_loss: 57.6498 - val_mae: 5.4495\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.7374 - mae: 4.6383 - val_loss: 57.7504 - val_mae: 5.3519\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.9167 - mae: 4.6785 - val_loss: 57.5501 - val_mae: 5.4277\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.6834 - mae: 4.6306 - val_loss: 57.6747 - val_mae: 5.3364\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.8121 - mae: 4.6737 - val_loss: 57.4659 - val_mae: 5.4327\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.6139 - mae: 4.6504 - val_loss: 57.4499 - val_mae: 5.3692\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.5792 - mae: 4.6302 - val_loss: 57.3981 - val_mae: 5.3688\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.6580 - mae: 4.6266 - val_loss: 57.3415 - val_mae: 5.3720\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.6061 - mae: 4.6118 - val_loss: 57.3531 - val_mae: 5.3547\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 43.6813 - mae: 4.5892 - val_loss: 57.3671 - val_mae: 5.3560\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.6754 - mae: 4.6790 - val_loss: 57.3036 - val_mae: 5.4283\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.6612 - mae: 4.6287 - val_loss: 57.3061 - val_mae: 5.3387\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.7235 - mae: 4.6922 - val_loss: 57.2003 - val_mae: 5.4381\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.5619 - mae: 4.6223 - val_loss: 57.1992 - val_mae: 5.3624\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.4833 - mae: 4.6318 - val_loss: 57.1534 - val_mae: 5.3743\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.4598 - mae: 4.6207 - val_loss: 57.0891 - val_mae: 5.3798\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.6496 - mae: 4.6879 - val_loss: 57.0431 - val_mae: 5.3669\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 43.5437 - mae: 4.5957 - val_loss: 57.0937 - val_mae: 5.3352\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 43.3980 - mae: 4.6247 - val_loss: 57.0066 - val_mae: 5.3943\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.4877 - mae: 4.6577 - val_loss: 56.9610 - val_mae: 5.3716\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.4792 - mae: 4.6169 - val_loss: 56.9258 - val_mae: 5.3454\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.3869 - mae: 4.6339 - val_loss: 56.8778 - val_mae: 5.3688\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 51.6333 - mae: 5.2195\n",
      "Mean Absolute Error on Test Data: 5.219466686248779\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.053768921040809325\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 15ms/step - loss: 42.5835 - mae: 5.2751 - val_loss: 30.8060 - val_mae: 4.4079\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.7727 - mae: 4.1081 - val_loss: 19.0648 - val_mae: 3.1195\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.2199 - mae: 2.9610 - val_loss: 11.4352 - val_mae: 2.5755\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.6312 - mae: 2.9444 - val_loss: 12.0421 - val_mae: 2.7521\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.5873 - mae: 2.9120 - val_loss: 11.3701 - val_mae: 2.5974\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 14.3954 - mae: 2.8392 - val_loss: 11.3847 - val_mae: 2.6112\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.3046 - mae: 2.8345 - val_loss: 11.3108 - val_mae: 2.5955\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.2376 - mae: 2.8229 - val_loss: 11.3156 - val_mae: 2.5987\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1991 - mae: 2.8279 - val_loss: 11.3177 - val_mae: 2.6001\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1543 - mae: 2.8297 - val_loss: 11.3391 - val_mae: 2.6068\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.1265 - mae: 2.8322 - val_loss: 11.2900 - val_mae: 2.5930\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.1055 - mae: 2.8035 - val_loss: 11.2845 - val_mae: 2.5916\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.0995 - mae: 2.7907 - val_loss: 11.2988 - val_mae: 2.5959\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 14.0599 - mae: 2.8284 - val_loss: 11.3404 - val_mae: 2.6105\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.0466 - mae: 2.8161 - val_loss: 11.2740 - val_mae: 2.5814\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.0089 - mae: 2.8023 - val_loss: 11.3558 - val_mae: 2.6109\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 14.0725 - mae: 2.7762 - val_loss: 11.2881 - val_mae: 2.5811\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.0308 - mae: 2.8352 - val_loss: 11.4690 - val_mae: 2.6360\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.9691 - mae: 2.7940 - val_loss: 11.3415 - val_mae: 2.5971\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.9547 - mae: 2.8085 - val_loss: 11.3583 - val_mae: 2.6035\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.9347 - mae: 2.7799 - val_loss: 11.3483 - val_mae: 2.5922\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.8804 - mae: 2.7794 - val_loss: 11.4252 - val_mae: 2.6195\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.8973 - mae: 2.7871 - val_loss: 11.3987 - val_mae: 2.6107\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.8778 - mae: 2.7946 - val_loss: 11.4609 - val_mae: 2.6280\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.8479 - mae: 2.7936 - val_loss: 11.3712 - val_mae: 2.5962\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.9297 - mae: 2.7633 - val_loss: 11.5047 - val_mae: 2.6390\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.8605 - mae: 2.8135 - val_loss: 11.3983 - val_mae: 2.6018\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.8764 - mae: 2.7442 - val_loss: 11.4041 - val_mae: 2.6018\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.9206 - mae: 2.8423 - val_loss: 11.4765 - val_mae: 2.6282\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.9237 - mae: 2.7457 - val_loss: 11.4064 - val_mae: 2.6003\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.7458 - mae: 2.7671 - val_loss: 11.4876 - val_mae: 2.6293\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.8126 - mae: 2.7869 - val_loss: 11.4112 - val_mae: 2.5941\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7499 - mae: 2.7652 - val_loss: 11.4688 - val_mae: 2.6206\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7499 - mae: 2.7722 - val_loss: 11.5133 - val_mae: 2.6329\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 13.7573 - mae: 2.7777 - val_loss: 11.4229 - val_mae: 2.5913\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7163 - mae: 2.7656 - val_loss: 11.4871 - val_mae: 2.6214\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7431 - mae: 2.7545 - val_loss: 11.4533 - val_mae: 2.5987\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.7182 - mae: 2.7789 - val_loss: 11.6034 - val_mae: 2.6519\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6971 - mae: 2.7743 - val_loss: 11.4912 - val_mae: 2.6162\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6731 - mae: 2.7429 - val_loss: 11.4885 - val_mae: 2.6122\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.6696 - mae: 2.7565 - val_loss: 11.5709 - val_mae: 2.6395\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6997 - mae: 2.7766 - val_loss: 11.5918 - val_mae: 2.6455\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6753 - mae: 2.7508 - val_loss: 11.5061 - val_mae: 2.6138\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6789 - mae: 2.7685 - val_loss: 11.5819 - val_mae: 2.6401\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6389 - mae: 2.7652 - val_loss: 11.5294 - val_mae: 2.6182\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.6102 - mae: 2.7711 - val_loss: 11.5064 - val_mae: 2.6064\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 13.6824 - mae: 2.7504 - val_loss: 11.5104 - val_mae: 2.5734\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 13.7593 - mae: 2.7782 - val_loss: 11.5570 - val_mae: 2.6243\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5911 - mae: 2.7207 - val_loss: 11.5280 - val_mae: 2.6104\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.5579 - mae: 2.7501 - val_loss: 11.5457 - val_mae: 2.6184\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 16.8700 - mae: 3.0259\n",
      "Mean Absolute Error on Test Data: 3.025857448577881\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "R-squared: 0.016882952952395947\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 1s 19ms/step - loss: 10.8104 - mae: 2.1712 - val_loss: 7.9265 - val_mae: 1.8076\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.7125 - mae: 1.5756 - val_loss: 5.5548 - val_mae: 1.3977\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.1976 - mae: 1.5093 - val_loss: 4.9984 - val_mae: 1.5021\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.9316 - mae: 1.5787 - val_loss: 4.9616 - val_mae: 1.4811\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.8396 - mae: 1.5295 - val_loss: 4.9375 - val_mae: 1.4431\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.7834 - mae: 1.4924 - val_loss: 4.9282 - val_mae: 1.4310\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 5.7125 - mae: 1.5024 - val_loss: 4.9106 - val_mae: 1.4703\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.6779 - mae: 1.5336 - val_loss: 4.9072 - val_mae: 1.4705\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.6165 - mae: 1.4934 - val_loss: 4.8975 - val_mae: 1.4533\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.5793 - mae: 1.4969 - val_loss: 4.9010 - val_mae: 1.4567\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.5516 - mae: 1.4780 - val_loss: 4.9087 - val_mae: 1.4441\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.5363 - mae: 1.5206 - val_loss: 4.9218 - val_mae: 1.4965\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.4753 - mae: 1.4784 - val_loss: 4.9195 - val_mae: 1.4438\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5.4571 - mae: 1.4817 - val_loss: 4.9285 - val_mae: 1.4622\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.4155 - mae: 1.4689 - val_loss: 4.9426 - val_mae: 1.4784\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.4146 - mae: 1.4701 - val_loss: 4.9448 - val_mae: 1.4796\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.4051 - mae: 1.5155 - val_loss: 4.9678 - val_mae: 1.5035\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.3611 - mae: 1.4679 - val_loss: 4.9648 - val_mae: 1.4714\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5.3253 - mae: 1.4682 - val_loss: 4.9785 - val_mae: 1.4943\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.2999 - mae: 1.4716 - val_loss: 4.9920 - val_mae: 1.4884\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.3262 - mae: 1.4942 - val_loss: 5.0146 - val_mae: 1.4902\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.2774 - mae: 1.4522 - val_loss: 5.0153 - val_mae: 1.4832\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.3046 - mae: 1.5064 - val_loss: 5.0393 - val_mae: 1.5067\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.2993 - mae: 1.4361 - val_loss: 5.0480 - val_mae: 1.4801\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.2641 - mae: 1.4994 - val_loss: 5.0927 - val_mae: 1.5301\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.2281 - mae: 1.4618 - val_loss: 5.0794 - val_mae: 1.4969\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.2226 - mae: 1.4657 - val_loss: 5.0808 - val_mae: 1.4889\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.2049 - mae: 1.4288 - val_loss: 5.0829 - val_mae: 1.4865\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.2315 - mae: 1.4833 - val_loss: 5.1030 - val_mae: 1.5007\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.2007 - mae: 1.4317 - val_loss: 5.0751 - val_mae: 1.4873\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.1924 - mae: 1.4247 - val_loss: 5.0905 - val_mae: 1.5172\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.1850 - mae: 1.4864 - val_loss: 5.0954 - val_mae: 1.5075\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.1520 - mae: 1.4383 - val_loss: 5.1254 - val_mae: 1.5189\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.1304 - mae: 1.4867 - val_loss: 5.1211 - val_mae: 1.5226\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 5.1014 - mae: 1.4468 - val_loss: 5.1191 - val_mae: 1.4963\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.1024 - mae: 1.4263 - val_loss: 5.1181 - val_mae: 1.5039\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.0896 - mae: 1.4588 - val_loss: 5.1244 - val_mae: 1.5013\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.1044 - mae: 1.4347 - val_loss: 5.1137 - val_mae: 1.5128\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.0498 - mae: 1.4359 - val_loss: 5.0991 - val_mae: 1.4875\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.0566 - mae: 1.4267 - val_loss: 5.1179 - val_mae: 1.5073\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.0620 - mae: 1.4281 - val_loss: 5.1337 - val_mae: 1.5245\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.0382 - mae: 1.4610 - val_loss: 5.1553 - val_mae: 1.5045\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.0358 - mae: 1.4279 - val_loss: 5.1470 - val_mae: 1.5018\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.0011 - mae: 1.4385 - val_loss: 5.1500 - val_mae: 1.5207\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4.9947 - mae: 1.4184 - val_loss: 5.1390 - val_mae: 1.4985\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4.9881 - mae: 1.4348 - val_loss: 5.1522 - val_mae: 1.5267\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.0093 - mae: 1.4324 - val_loss: 5.1589 - val_mae: 1.5058\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4.9808 - mae: 1.4738 - val_loss: 5.2129 - val_mae: 1.5553\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4.9633 - mae: 1.4124 - val_loss: 5.1660 - val_mae: 1.4942\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4.9583 - mae: 1.4464 - val_loss: 5.1580 - val_mae: 1.5080\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.3198 - mae: 1.3933\n",
      "Mean Absolute Error on Test Data: 1.3932815790176392\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.09259434073547745\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 79.0205 - mae: 6.4912 - val_loss: 50.7998 - val_mae: 5.0270\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 64.6502 - mae: 5.4422 - val_loss: 37.1424 - val_mae: 3.8665\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 45.6728 - mae: 4.1452 - val_loss: 25.1072 - val_mae: 3.2412\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 35.5328 - mae: 3.9844 - val_loss: 27.5602 - val_mae: 3.9563\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 34.8865 - mae: 4.1436 - val_loss: 25.5833 - val_mae: 3.6091\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.5339 - mae: 4.0095 - val_loss: 25.1837 - val_mae: 3.5419\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.5858 - mae: 3.9304 - val_loss: 25.1554 - val_mae: 3.5451\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.3795 - mae: 3.9954 - val_loss: 25.2674 - val_mae: 3.5751\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.3538 - mae: 4.0101 - val_loss: 25.4291 - val_mae: 3.6125\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.3913 - mae: 3.9502 - val_loss: 24.8416 - val_mae: 3.5080\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 34.3593 - mae: 4.0321 - val_loss: 25.2249 - val_mae: 3.5885\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.0725 - mae: 3.9811 - val_loss: 24.9315 - val_mae: 3.5378\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.0371 - mae: 3.9555 - val_loss: 24.9101 - val_mae: 3.5379\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 34.0915 - mae: 3.9830 - val_loss: 24.9410 - val_mae: 3.5491\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 34.1368 - mae: 4.0378 - val_loss: 24.9713 - val_mae: 3.5614\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.9343 - mae: 3.9277 - val_loss: 24.5257 - val_mae: 3.4769\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.9066 - mae: 3.9021 - val_loss: 24.7613 - val_mae: 3.5275\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.9144 - mae: 4.0317 - val_loss: 25.1132 - val_mae: 3.5971\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 33.9322 - mae: 3.9429 - val_loss: 24.7114 - val_mae: 3.5230\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.7960 - mae: 4.0004 - val_loss: 25.1917 - val_mae: 3.6178\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.8604 - mae: 3.9592 - val_loss: 24.8936 - val_mae: 3.5635\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.7085 - mae: 3.9840 - val_loss: 24.9291 - val_mae: 3.5711\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 33.6953 - mae: 3.9336 - val_loss: 24.5173 - val_mae: 3.4969\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 33.6523 - mae: 3.9783 - val_loss: 24.9261 - val_mae: 3.5794\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.6851 - mae: 3.9218 - val_loss: 24.5685 - val_mae: 3.5130\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.5465 - mae: 4.0082 - val_loss: 25.2163 - val_mae: 3.6341\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.5151 - mae: 3.9606 - val_loss: 24.4094 - val_mae: 3.4823\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.5262 - mae: 3.9470 - val_loss: 25.0677 - val_mae: 3.6109\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.3885 - mae: 3.9904 - val_loss: 24.5584 - val_mae: 3.5207\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.6118 - mae: 3.9012 - val_loss: 24.7631 - val_mae: 3.5594\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 33.3618 - mae: 3.9483 - val_loss: 24.4386 - val_mae: 3.5016\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.3913 - mae: 3.9904 - val_loss: 24.7943 - val_mae: 3.5677\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.2638 - mae: 3.9284 - val_loss: 24.5053 - val_mae: 3.5174\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.2349 - mae: 3.9393 - val_loss: 24.8415 - val_mae: 3.5826\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.2575 - mae: 3.9446 - val_loss: 24.7542 - val_mae: 3.5662\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.3371 - mae: 4.0393 - val_loss: 24.4101 - val_mae: 3.5052\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.4491 - mae: 3.8453 - val_loss: 24.0713 - val_mae: 3.4382\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 32.9979 - mae: 3.9498 - val_loss: 25.0280 - val_mae: 3.6202\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.2794 - mae: 4.0150 - val_loss: 24.2777 - val_mae: 3.4882\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.0098 - mae: 3.8845 - val_loss: 24.5392 - val_mae: 3.5381\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.3282 - mae: 4.0355 - val_loss: 24.3924 - val_mae: 3.5100\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 33.1160 - mae: 3.8495 - val_loss: 24.2066 - val_mae: 3.4787\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.9033 - mae: 3.9840 - val_loss: 25.0836 - val_mae: 3.6427\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.9676 - mae: 3.9230 - val_loss: 24.4578 - val_mae: 3.5351\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 32.8257 - mae: 3.9012 - val_loss: 24.6824 - val_mae: 3.5796\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.7665 - mae: 4.0091 - val_loss: 24.6897 - val_mae: 3.5865\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.7961 - mae: 3.8861 - val_loss: 24.1859 - val_mae: 3.4927\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.7281 - mae: 3.9859 - val_loss: 24.6994 - val_mae: 3.5905\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.6037 - mae: 3.9685 - val_loss: 24.4468 - val_mae: 3.5513\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 32.5373 - mae: 3.8857 - val_loss: 23.8787 - val_mae: 3.4389\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.9013 - mae: 3.6308\n",
      "Mean Absolute Error on Test Data: 3.6307802200317383\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.08939569901154454\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 15ms/step - loss: 114.0252 - mae: 8.4262 - val_loss: 92.6947 - val_mae: 7.8761\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 94.7656 - mae: 7.2360 - val_loss: 67.4616 - val_mae: 6.1947\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 64.4793 - mae: 5.1129 - val_loss: 34.9079 - val_mae: 4.0208\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 42.7758 - mae: 4.1816 - val_loss: 29.4427 - val_mae: 4.2908\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.6379 - mae: 4.4598 - val_loss: 28.7322 - val_mae: 3.9834\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.4624 - mae: 4.0900 - val_loss: 28.9993 - val_mae: 3.9132\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.0751 - mae: 4.3262 - val_loss: 28.8250 - val_mae: 4.1472\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.0009 - mae: 4.2495 - val_loss: 28.6921 - val_mae: 3.9775\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.7467 - mae: 4.1544 - val_loss: 28.6752 - val_mae: 3.9753\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 41.6507 - mae: 4.1715 - val_loss: 28.6369 - val_mae: 3.9852\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 41.6027 - mae: 4.2072 - val_loss: 28.5919 - val_mae: 3.9915\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.6760 - mae: 4.2178 - val_loss: 28.5362 - val_mae: 4.0363\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.6068 - mae: 4.1720 - val_loss: 28.6057 - val_mae: 3.9574\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.4716 - mae: 4.1570 - val_loss: 28.4657 - val_mae: 3.9785\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.4244 - mae: 4.1606 - val_loss: 28.4949 - val_mae: 3.9749\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 41.3895 - mae: 4.2156 - val_loss: 28.3960 - val_mae: 4.0133\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.3390 - mae: 4.1737 - val_loss: 28.5759 - val_mae: 3.9484\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 41.4157 - mae: 4.1294 - val_loss: 28.4149 - val_mae: 3.9839\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.2996 - mae: 4.2283 - val_loss: 28.3436 - val_mae: 3.9987\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.2291 - mae: 4.1975 - val_loss: 28.3471 - val_mae: 4.0006\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.2403 - mae: 4.2709 - val_loss: 28.3053 - val_mae: 4.0179\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.1053 - mae: 4.1927 - val_loss: 28.5181 - val_mae: 3.9352\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.2463 - mae: 4.1083 - val_loss: 28.4623 - val_mae: 3.9406\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 41.1555 - mae: 4.2010 - val_loss: 28.2988 - val_mae: 3.9901\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.1127 - mae: 4.1960 - val_loss: 28.2685 - val_mae: 3.9862\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 41.1258 - mae: 4.1799 - val_loss: 28.2523 - val_mae: 3.9737\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 41.0091 - mae: 4.2262 - val_loss: 28.2089 - val_mae: 4.0100\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 41.0474 - mae: 4.1841 - val_loss: 28.3729 - val_mae: 3.9638\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.0455 - mae: 4.1750 - val_loss: 28.2406 - val_mae: 3.9872\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.1827 - mae: 4.3247 - val_loss: 28.2640 - val_mae: 4.0427\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.8542 - mae: 4.2156 - val_loss: 28.2755 - val_mae: 3.9669\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.9542 - mae: 4.1303 - val_loss: 28.1438 - val_mae: 3.9738\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.6468 - mae: 4.3754 - val_loss: 28.1809 - val_mae: 4.0101\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.0140 - mae: 4.1112 - val_loss: 28.4116 - val_mae: 3.9193\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 40.8600 - mae: 4.1950 - val_loss: 28.1161 - val_mae: 4.0225\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.8083 - mae: 4.2069 - val_loss: 28.1860 - val_mae: 3.9825\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.7827 - mae: 4.2676 - val_loss: 28.0596 - val_mae: 3.9988\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.6906 - mae: 4.1640 - val_loss: 28.1667 - val_mae: 3.9495\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.6470 - mae: 4.1625 - val_loss: 28.0513 - val_mae: 3.9865\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.7556 - mae: 4.2554 - val_loss: 28.0770 - val_mae: 3.9733\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 40.7182 - mae: 4.1424 - val_loss: 27.9901 - val_mae: 3.9593\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 40.5731 - mae: 4.2187 - val_loss: 27.8852 - val_mae: 3.9779\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 40.4821 - mae: 4.1825 - val_loss: 27.9202 - val_mae: 3.9516\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.4581 - mae: 4.2116 - val_loss: 27.8228 - val_mae: 4.0056\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.6259 - mae: 4.1391 - val_loss: 27.9116 - val_mae: 3.9411\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.4869 - mae: 4.1993 - val_loss: 27.7767 - val_mae: 3.9855\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 40.8954 - mae: 4.3357 - val_loss: 27.7639 - val_mae: 3.9924\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.3264 - mae: 4.1773 - val_loss: 27.8736 - val_mae: 3.9456\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.3185 - mae: 4.1572 - val_loss: 27.8487 - val_mae: 3.9571\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.3057 - mae: 4.1814 - val_loss: 27.8034 - val_mae: 3.9495\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 43.0030 - mae: 4.1796\n",
      "Mean Absolute Error on Test Data: 4.1796345710754395\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.04269162051783004\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 2s 11ms/step - loss: 118.3598 - mae: 8.7282 - val_loss: 88.4528 - val_mae: 7.2146\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 93.0740 - mae: 7.2426 - val_loss: 62.7842 - val_mae: 5.4296\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 60.5849 - mae: 5.2751 - val_loss: 38.8598 - val_mae: 4.1656\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.5774 - mae: 4.5245 - val_loss: 37.9639 - val_mae: 4.6934\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 40.9180 - mae: 4.8502 - val_loss: 37.0173 - val_mae: 4.5640\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.9514 - mae: 4.4986 - val_loss: 36.0808 - val_mae: 4.3570\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.6165 - mae: 4.4666 - val_loss: 36.3498 - val_mae: 4.4480\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 39.3070 - mae: 4.5761 - val_loss: 36.9186 - val_mae: 4.5489\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.1589 - mae: 4.5444 - val_loss: 36.2583 - val_mae: 4.4208\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 38.9289 - mae: 4.4906 - val_loss: 36.5839 - val_mae: 4.4804\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.0261 - mae: 4.5885 - val_loss: 36.7375 - val_mae: 4.4943\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.6034 - mae: 4.4630 - val_loss: 36.1626 - val_mae: 4.3555\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.7092 - mae: 4.4497 - val_loss: 36.4498 - val_mae: 4.4203\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.6780 - mae: 4.5548 - val_loss: 37.0791 - val_mae: 4.5294\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.5880 - mae: 4.4821 - val_loss: 36.5094 - val_mae: 4.4217\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 38.5400 - mae: 4.4619 - val_loss: 36.7530 - val_mae: 4.4618\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.4307 - mae: 4.4790 - val_loss: 36.5190 - val_mae: 4.4171\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.4456 - mae: 4.5045 - val_loss: 36.7523 - val_mae: 4.4595\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.2865 - mae: 4.5189 - val_loss: 36.8447 - val_mae: 4.4707\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.2732 - mae: 4.4677 - val_loss: 36.5169 - val_mae: 4.4127\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 38.3193 - mae: 4.4328 - val_loss: 36.5110 - val_mae: 4.4066\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.2365 - mae: 4.5097 - val_loss: 36.9930 - val_mae: 4.4933\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.1833 - mae: 4.4958 - val_loss: 36.3972 - val_mae: 4.3739\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.0958 - mae: 4.4534 - val_loss: 36.5757 - val_mae: 4.4208\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 38.0216 - mae: 4.4541 - val_loss: 36.4439 - val_mae: 4.3911\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.0383 - mae: 4.5021 - val_loss: 36.9249 - val_mae: 4.4874\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.1302 - mae: 4.4460 - val_loss: 36.4255 - val_mae: 4.3857\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 37.9284 - mae: 4.4486 - val_loss: 36.7909 - val_mae: 4.4562\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.1642 - mae: 4.5290 - val_loss: 36.4545 - val_mae: 4.3848\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.9378 - mae: 4.4121 - val_loss: 36.2183 - val_mae: 4.3418\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.1932 - mae: 4.4939 - val_loss: 36.7265 - val_mae: 4.4513\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 38.0340 - mae: 4.4078 - val_loss: 36.1207 - val_mae: 4.3180\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 37.8052 - mae: 4.4146 - val_loss: 36.6605 - val_mae: 4.4454\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 37.9215 - mae: 4.4546 - val_loss: 36.2410 - val_mae: 4.3500\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.8857 - mae: 4.4851 - val_loss: 36.6029 - val_mae: 4.4343\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.7336 - mae: 4.4336 - val_loss: 36.3158 - val_mae: 4.3786\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.6965 - mae: 4.4242 - val_loss: 36.5001 - val_mae: 4.4163\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.7506 - mae: 4.4832 - val_loss: 36.4374 - val_mae: 4.4120\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.7559 - mae: 4.4167 - val_loss: 36.2919 - val_mae: 4.3966\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.5942 - mae: 4.4570 - val_loss: 36.8206 - val_mae: 4.4910\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.6926 - mae: 4.5301 - val_loss: 37.0603 - val_mae: 4.5278\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.6159 - mae: 4.4459 - val_loss: 36.1278 - val_mae: 4.3473\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.7255 - mae: 4.3867 - val_loss: 36.2281 - val_mae: 4.3759\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.5292 - mae: 4.4089 - val_loss: 36.4839 - val_mae: 4.4370\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.4587 - mae: 4.4696 - val_loss: 36.4513 - val_mae: 4.4260\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.4197 - mae: 4.4170 - val_loss: 36.0371 - val_mae: 4.3293\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.4840 - mae: 4.4399 - val_loss: 36.3357 - val_mae: 4.3993\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.4996 - mae: 4.3732 - val_loss: 35.9473 - val_mae: 4.3197\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.4462 - mae: 4.4475 - val_loss: 36.5564 - val_mae: 4.4420\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.3877 - mae: 4.4584 - val_loss: 36.2016 - val_mae: 4.3548\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 46.1731 - mae: 4.4110\n",
      "Mean Absolute Error on Test Data: 4.410952091217041\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.08427506488289505\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s 19ms/step - loss: 4.0223 - mae: 1.5632 - val_loss: 3.2500 - val_mae: 1.2574\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.4449 - mae: 1.0293 - val_loss: 2.1310 - val_mae: 0.8730\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6597 - mae: 0.8623 - val_loss: 1.9269 - val_mae: 0.9894\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6349 - mae: 0.9498 - val_loss: 1.9583 - val_mae: 1.0192\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6131 - mae: 0.9225 - val_loss: 1.9066 - val_mae: 0.9639\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5718 - mae: 0.8835 - val_loss: 1.9060 - val_mae: 0.9518\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5713 - mae: 0.8762 - val_loss: 1.9047 - val_mae: 0.9599\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5565 - mae: 0.8905 - val_loss: 1.9147 - val_mae: 0.9837\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.5628 - mae: 0.9057 - val_loss: 1.9147 - val_mae: 0.9832\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5492 - mae: 0.8845 - val_loss: 1.9057 - val_mae: 0.9588\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.5471 - mae: 0.8758 - val_loss: 1.9072 - val_mae: 0.9649\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5411 - mae: 0.8777 - val_loss: 1.9106 - val_mae: 0.9723\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5384 - mae: 0.8895 - val_loss: 1.9168 - val_mae: 0.9830\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5388 - mae: 0.8817 - val_loss: 1.9118 - val_mae: 0.9675\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.5271 - mae: 0.8727 - val_loss: 1.9149 - val_mae: 0.9707\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5290 - mae: 0.8846 - val_loss: 1.9203 - val_mae: 0.9881\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.5178 - mae: 0.8818 - val_loss: 1.9163 - val_mae: 0.9785\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5191 - mae: 0.8675 - val_loss: 1.9125 - val_mae: 0.9661\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.5185 - mae: 0.8822 - val_loss: 1.9203 - val_mae: 0.9909\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5034 - mae: 0.8788 - val_loss: 1.9033 - val_mae: 0.9682\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.5042 - mae: 0.8631 - val_loss: 1.9064 - val_mae: 0.9611\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4974 - mae: 0.8631 - val_loss: 1.9048 - val_mae: 0.9780\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4967 - mae: 0.8814 - val_loss: 1.9169 - val_mae: 1.0014\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.5003 - mae: 0.8699 - val_loss: 1.9007 - val_mae: 0.9585\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.4945 - mae: 0.8667 - val_loss: 1.9134 - val_mae: 0.9916\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4789 - mae: 0.8710 - val_loss: 1.9059 - val_mae: 0.9763\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.4801 - mae: 0.8578 - val_loss: 1.9073 - val_mae: 0.9766\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4696 - mae: 0.8571 - val_loss: 1.9046 - val_mae: 0.9758\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4675 - mae: 0.8552 - val_loss: 1.9019 - val_mae: 0.9723\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4702 - mae: 0.8602 - val_loss: 1.9074 - val_mae: 0.9775\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.4641 - mae: 0.8512 - val_loss: 1.9095 - val_mae: 0.9818\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4584 - mae: 0.8604 - val_loss: 1.9135 - val_mae: 0.9823\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4535 - mae: 0.8504 - val_loss: 1.9187 - val_mae: 0.9829\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4525 - mae: 0.8495 - val_loss: 1.9205 - val_mae: 0.9841\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4486 - mae: 0.8465 - val_loss: 1.9211 - val_mae: 0.9845\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4440 - mae: 0.8534 - val_loss: 1.9266 - val_mae: 0.9965\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.4436 - mae: 0.8461 - val_loss: 1.9251 - val_mae: 0.9786\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4504 - mae: 0.8654 - val_loss: 1.9432 - val_mae: 1.0138\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.4323 - mae: 0.8527 - val_loss: 1.9333 - val_mae: 0.9802\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4644 - mae: 0.8283 - val_loss: 1.9316 - val_mae: 0.9717\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4784 - mae: 0.8737 - val_loss: 1.9406 - val_mae: 1.0156\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4287 - mae: 0.8545 - val_loss: 1.9268 - val_mae: 0.9772\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4309 - mae: 0.8363 - val_loss: 1.9306 - val_mae: 0.9817\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4232 - mae: 0.8421 - val_loss: 1.9266 - val_mae: 0.9908\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.4288 - mae: 0.8547 - val_loss: 1.9400 - val_mae: 0.9938\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4263 - mae: 0.8385 - val_loss: 1.9423 - val_mae: 0.9911\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4187 - mae: 0.8476 - val_loss: 1.9305 - val_mae: 1.0037\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4269 - mae: 0.8431 - val_loss: 1.9321 - val_mae: 0.9784\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4139 - mae: 0.8438 - val_loss: 1.9581 - val_mae: 1.0179\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4111 - mae: 0.8492 - val_loss: 1.9429 - val_mae: 0.9925\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2402 - mae: 0.8334\n",
      "Mean Absolute Error on Test Data: 0.8333821296691895\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.15217965245839915\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 12ms/step - loss: 84.6134 - mae: 7.7534 - val_loss: 102.5199 - val_mae: 7.6621\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 59.2841 - mae: 6.0085 - val_loss: 68.7392 - val_mae: 5.4009\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.5373 - mae: 3.9290 - val_loss: 43.3539 - val_mae: 4.1098\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 24.4513 - mae: 3.7393 - val_loss: 41.9806 - val_mae: 4.3529\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.1716 - mae: 3.6989 - val_loss: 42.6982 - val_mae: 4.1189\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.1789 - mae: 3.5359 - val_loss: 42.9470 - val_mae: 4.0974\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 23.8661 - mae: 3.5820 - val_loss: 41.8652 - val_mae: 4.1831\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.9818 - mae: 3.6041 - val_loss: 42.2455 - val_mae: 4.1204\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.9393 - mae: 3.6091 - val_loss: 42.1215 - val_mae: 4.1245\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 23.7925 - mae: 3.5505 - val_loss: 42.5252 - val_mae: 4.0851\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.8768 - mae: 3.5324 - val_loss: 42.0015 - val_mae: 4.1106\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.7678 - mae: 3.5743 - val_loss: 41.8690 - val_mae: 4.1133\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.7481 - mae: 3.5674 - val_loss: 41.7891 - val_mae: 4.1200\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.7559 - mae: 3.5745 - val_loss: 41.5933 - val_mae: 4.1432\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 23.6507 - mae: 3.5671 - val_loss: 41.9268 - val_mae: 4.0944\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 23.6792 - mae: 3.5415 - val_loss: 41.8180 - val_mae: 4.1003\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.7903 - mae: 3.6150 - val_loss: 41.4391 - val_mae: 4.1340\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.6657 - mae: 3.5332 - val_loss: 41.9351 - val_mae: 4.0869\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.6819 - mae: 3.5434 - val_loss: 41.4826 - val_mae: 4.1248\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 23.5662 - mae: 3.5554 - val_loss: 41.7321 - val_mae: 4.0950\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 23.5216 - mae: 3.5364 - val_loss: 41.6794 - val_mae: 4.0896\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.6283 - mae: 3.5992 - val_loss: 41.3105 - val_mae: 4.1090\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.5723 - mae: 3.5291 - val_loss: 41.5799 - val_mae: 4.0782\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.7039 - mae: 3.5325 - val_loss: 41.3423 - val_mae: 4.1048\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 23.4725 - mae: 3.5612 - val_loss: 41.7757 - val_mae: 4.0679\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.4825 - mae: 3.5180 - val_loss: 41.6490 - val_mae: 4.0752\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 23.4166 - mae: 3.5414 - val_loss: 41.6175 - val_mae: 4.0871\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.6256 - mae: 3.4916 - val_loss: 41.5957 - val_mae: 4.0949\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 23.6499 - mae: 3.6361 - val_loss: 41.3071 - val_mae: 4.1258\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.4129 - mae: 3.5497 - val_loss: 41.6263 - val_mae: 4.0737\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 23.2921 - mae: 3.5086 - val_loss: 41.5443 - val_mae: 4.0889\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.2784 - mae: 3.5128 - val_loss: 41.6226 - val_mae: 4.0743\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 23.2699 - mae: 3.5092 - val_loss: 41.2066 - val_mae: 4.1208\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3223 - mae: 3.5055 - val_loss: 41.6616 - val_mae: 4.0742\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.2395 - mae: 3.5390 - val_loss: 41.1628 - val_mae: 4.1299\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 23.2551 - mae: 3.5070 - val_loss: 41.9332 - val_mae: 4.0627\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3674 - mae: 3.5651 - val_loss: 41.3092 - val_mae: 4.1094\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3725 - mae: 3.4885 - val_loss: 41.5060 - val_mae: 4.0858\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 23.1984 - mae: 3.5040 - val_loss: 41.0847 - val_mae: 4.1377\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.2064 - mae: 3.5303 - val_loss: 41.6807 - val_mae: 4.0759\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.1136 - mae: 3.5058 - val_loss: 41.3299 - val_mae: 4.1175\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 23.2138 - mae: 3.5554 - val_loss: 41.5068 - val_mae: 4.0687\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.0502 - mae: 3.4857 - val_loss: 41.3294 - val_mae: 4.0784\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 23.0426 - mae: 3.4988 - val_loss: 41.1354 - val_mae: 4.0926\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.1091 - mae: 3.4670 - val_loss: 41.6679 - val_mae: 4.0695\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.6569 - mae: 3.6102 - val_loss: 41.8710 - val_mae: 4.0624\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.0416 - mae: 3.4686 - val_loss: 41.6069 - val_mae: 4.0866\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.9594 - mae: 3.4804 - val_loss: 41.2300 - val_mae: 4.1137\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.9420 - mae: 3.4847 - val_loss: 41.3264 - val_mae: 4.0848\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.9639 - mae: 3.4773 - val_loss: 41.1669 - val_mae: 4.1155\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 45.6598 - mae: 4.2151\n",
      "Mean Absolute Error on Test Data: 4.215127468109131\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.05514983491144776\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 16ms/step - loss: 94.1857 - mae: 7.8665 - val_loss: 72.3392 - val_mae: 6.7655\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 72.2070 - mae: 6.4202 - val_loss: 50.3393 - val_mae: 5.0981\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 47.6281 - mae: 4.5879 - val_loss: 28.4270 - val_mae: 3.5917\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.1379 - mae: 3.7584 - val_loss: 24.9074 - val_mae: 3.8505\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 29.6014 - mae: 3.8800 - val_loss: 24.3448 - val_mae: 3.7200\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 29.4654 - mae: 3.7587 - val_loss: 24.2385 - val_mae: 3.7271\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 29.0850 - mae: 3.7469 - val_loss: 24.0222 - val_mae: 3.6759\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 28.8981 - mae: 3.7343 - val_loss: 23.8541 - val_mae: 3.6501\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.7763 - mae: 3.7206 - val_loss: 23.8113 - val_mae: 3.6790\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.6774 - mae: 3.7742 - val_loss: 23.7960 - val_mae: 3.7175\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.8080 - mae: 3.7038 - val_loss: 23.5489 - val_mae: 3.6387\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.6793 - mae: 3.8294 - val_loss: 23.8134 - val_mae: 3.7723\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 28.3636 - mae: 3.7244 - val_loss: 23.3391 - val_mae: 3.6109\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 28.5111 - mae: 3.6635 - val_loss: 23.3007 - val_mae: 3.6374\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.4485 - mae: 3.7934 - val_loss: 23.3737 - val_mae: 3.6967\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.3125 - mae: 3.6773 - val_loss: 23.1169 - val_mae: 3.6006\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 28.0761 - mae: 3.6578 - val_loss: 23.1078 - val_mae: 3.6176\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.1224 - mae: 3.7448 - val_loss: 23.1937 - val_mae: 3.6670\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.9568 - mae: 3.7334 - val_loss: 23.0428 - val_mae: 3.6278\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.9526 - mae: 3.6717 - val_loss: 22.9849 - val_mae: 3.6166\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.9108 - mae: 3.6671 - val_loss: 22.9892 - val_mae: 3.6452\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.8122 - mae: 3.6902 - val_loss: 22.9378 - val_mae: 3.6308\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.7979 - mae: 3.6890 - val_loss: 22.9804 - val_mae: 3.6561\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 27.7024 - mae: 3.6802 - val_loss: 22.8642 - val_mae: 3.6207\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.7649 - mae: 3.7188 - val_loss: 22.9098 - val_mae: 3.6455\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 27.6764 - mae: 3.6904 - val_loss: 22.8024 - val_mae: 3.5982\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 27.7427 - mae: 3.6347 - val_loss: 22.7312 - val_mae: 3.5566\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 27.7964 - mae: 3.6281 - val_loss: 22.9493 - val_mae: 3.6648\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 27.6467 - mae: 3.7494 - val_loss: 23.0926 - val_mae: 3.7255\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.6268 - mae: 3.6903 - val_loss: 22.7126 - val_mae: 3.6161\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.5422 - mae: 3.7252 - val_loss: 22.8359 - val_mae: 3.6693\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.5273 - mae: 3.6680 - val_loss: 22.6123 - val_mae: 3.5796\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.5891 - mae: 3.6343 - val_loss: 22.6990 - val_mae: 3.6362\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 27.5862 - mae: 3.7199 - val_loss: 22.5923 - val_mae: 3.5874\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.5190 - mae: 3.6312 - val_loss: 22.6052 - val_mae: 3.6066\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.4695 - mae: 3.7258 - val_loss: 22.8253 - val_mae: 3.6844\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.5149 - mae: 3.7550 - val_loss: 22.6526 - val_mae: 3.6297\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.6034 - mae: 3.6060 - val_loss: 22.4978 - val_mae: 3.5507\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.5416 - mae: 3.7737 - val_loss: 23.1365 - val_mae: 3.7522\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 27.3213 - mae: 3.6788 - val_loss: 22.5396 - val_mae: 3.5828\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.3431 - mae: 3.6400 - val_loss: 22.5239 - val_mae: 3.6012\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.2404 - mae: 3.6892 - val_loss: 22.6825 - val_mae: 3.6599\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.4567 - mae: 3.7313 - val_loss: 22.4716 - val_mae: 3.5958\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.1587 - mae: 3.6701 - val_loss: 22.5990 - val_mae: 3.6446\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.1628 - mae: 3.6635 - val_loss: 22.5063 - val_mae: 3.6027\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 27.1522 - mae: 3.6286 - val_loss: 22.5029 - val_mae: 3.6019\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.9912 - mae: 3.6728 - val_loss: 23.0450 - val_mae: 3.7365\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.2694 - mae: 3.7128 - val_loss: 22.5715 - val_mae: 3.6102\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.2697 - mae: 3.7066 - val_loss: 22.4415 - val_mae: 3.5775\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 27.3001 - mae: 3.6073 - val_loss: 22.4454 - val_mae: 3.6002\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 28.6642 - mae: 3.9348\n",
      "Mean Absolute Error on Test Data: 3.934840679168701\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.01780044885897991\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 1s 16ms/step - loss: 8.8991 - mae: 2.1967 - val_loss: 6.5053 - val_mae: 1.7103\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.2457 - mae: 1.4711 - val_loss: 4.0774 - val_mae: 1.3447\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.0436 - mae: 1.4418 - val_loss: 3.9738 - val_mae: 1.4970\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0369 - mae: 1.5018 - val_loss: 3.9026 - val_mae: 1.4301\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 3.9447 - mae: 1.4199 - val_loss: 3.9041 - val_mae: 1.3968\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.9383 - mae: 1.4165 - val_loss: 3.8944 - val_mae: 1.4157\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.9119 - mae: 1.4228 - val_loss: 3.8958 - val_mae: 1.4057\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.9241 - mae: 1.3900 - val_loss: 3.9090 - val_mae: 1.3895\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.9098 - mae: 1.4529 - val_loss: 3.9099 - val_mae: 1.4467\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 3.8881 - mae: 1.4138 - val_loss: 3.9106 - val_mae: 1.3947\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.8661 - mae: 1.4097 - val_loss: 3.9024 - val_mae: 1.4151\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.8523 - mae: 1.4195 - val_loss: 3.9046 - val_mae: 1.4068\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.8574 - mae: 1.3947 - val_loss: 3.9035 - val_mae: 1.4000\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.8670 - mae: 1.4588 - val_loss: 3.9153 - val_mae: 1.4431\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.8608 - mae: 1.4024 - val_loss: 3.9312 - val_mae: 1.3853\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.8341 - mae: 1.4251 - val_loss: 3.9189 - val_mae: 1.4318\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.8150 - mae: 1.4107 - val_loss: 3.9221 - val_mae: 1.4114\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.8024 - mae: 1.4065 - val_loss: 3.9192 - val_mae: 1.4098\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.8042 - mae: 1.4238 - val_loss: 3.9222 - val_mae: 1.4277\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.7917 - mae: 1.4124 - val_loss: 3.9434 - val_mae: 1.4025\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7913 - mae: 1.3990 - val_loss: 3.9251 - val_mae: 1.4108\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.7788 - mae: 1.3964 - val_loss: 3.9198 - val_mae: 1.4128\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.7779 - mae: 1.4105 - val_loss: 3.9220 - val_mae: 1.4172\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7838 - mae: 1.4273 - val_loss: 3.9205 - val_mae: 1.4130\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.7816 - mae: 1.3732 - val_loss: 3.9396 - val_mae: 1.3923\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7784 - mae: 1.4087 - val_loss: 3.9340 - val_mae: 1.4440\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.7607 - mae: 1.3930 - val_loss: 3.9275 - val_mae: 1.4082\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.7614 - mae: 1.4152 - val_loss: 3.9286 - val_mae: 1.4246\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.7347 - mae: 1.3937 - val_loss: 3.9514 - val_mae: 1.4008\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 3.7469 - mae: 1.3941 - val_loss: 3.9410 - val_mae: 1.4106\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.7394 - mae: 1.4129 - val_loss: 3.9390 - val_mae: 1.4236\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.7225 - mae: 1.3896 - val_loss: 3.9458 - val_mae: 1.4280\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7081 - mae: 1.4086 - val_loss: 3.9463 - val_mae: 1.4121\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.7531 - mae: 1.3548 - val_loss: 3.9271 - val_mae: 1.4113\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 3.7097 - mae: 1.4108 - val_loss: 3.9292 - val_mae: 1.4298\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7045 - mae: 1.3871 - val_loss: 3.9327 - val_mae: 1.4308\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6886 - mae: 1.4119 - val_loss: 3.9528 - val_mae: 1.4359\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7357 - mae: 1.3694 - val_loss: 3.9330 - val_mae: 1.4280\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.6776 - mae: 1.4155 - val_loss: 3.9438 - val_mae: 1.4303\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 3.6706 - mae: 1.3786 - val_loss: 3.9265 - val_mae: 1.4370\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6567 - mae: 1.4002 - val_loss: 3.9487 - val_mae: 1.4366\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6710 - mae: 1.3726 - val_loss: 3.9504 - val_mae: 1.4362\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6492 - mae: 1.4139 - val_loss: 3.9520 - val_mae: 1.4327\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.6474 - mae: 1.3510 - val_loss: 3.9544 - val_mae: 1.4186\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 3.6475 - mae: 1.4068 - val_loss: 3.9597 - val_mae: 1.4325\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.6211 - mae: 1.3757 - val_loss: 3.9564 - val_mae: 1.4293\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.6155 - mae: 1.3901 - val_loss: 3.9715 - val_mae: 1.4432\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6224 - mae: 1.3630 - val_loss: 3.9756 - val_mae: 1.4464\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6840 - mae: 1.4445 - val_loss: 3.9748 - val_mae: 1.4272\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 3.6395 - mae: 1.3422 - val_loss: 3.9362 - val_mae: 1.4370\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.6512 - mae: 1.3883\n",
      "Mean Absolute Error on Test Data: 1.3883378505706787\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.039185030859196335\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 1s 33ms/step - loss: 2.6634 - mae: 1.2939 - val_loss: 2.2131 - val_mae: 1.1028\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6125 - mae: 0.8733 - val_loss: 1.4152 - val_mae: 0.7522\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1.1354 - mae: 0.7029 - val_loss: 1.1833 - val_mae: 0.8604\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.0558 - mae: 0.7714 - val_loss: 1.1893 - val_mae: 0.8916\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.0479 - mae: 0.7731 - val_loss: 1.1440 - val_mae: 0.8509\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1.0291 - mae: 0.7272 - val_loss: 1.1405 - val_mae: 0.8001\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1.0077 - mae: 0.7092 - val_loss: 1.1148 - val_mae: 0.8155\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.9931 - mae: 0.7236 - val_loss: 1.1003 - val_mae: 0.8268\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.9847 - mae: 0.7258 - val_loss: 1.0886 - val_mae: 0.8190\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.9768 - mae: 0.7154 - val_loss: 1.0800 - val_mae: 0.8115\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.9787 - mae: 0.7235 - val_loss: 1.0694 - val_mae: 0.8220\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9614 - mae: 0.7088 - val_loss: 1.0690 - val_mae: 0.7971\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9603 - mae: 0.6967 - val_loss: 1.0593 - val_mae: 0.8010\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.9579 - mae: 0.7192 - val_loss: 1.0510 - val_mae: 0.8219\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.9487 - mae: 0.7131 - val_loss: 1.0493 - val_mae: 0.8007\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9432 - mae: 0.7031 - val_loss: 1.0432 - val_mae: 0.8079\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.9375 - mae: 0.7086 - val_loss: 1.0396 - val_mae: 0.8094\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9436 - mae: 0.6991 - val_loss: 1.0368 - val_mae: 0.7878\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9280 - mae: 0.7002 - val_loss: 1.0277 - val_mae: 0.8130\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9338 - mae: 0.7246 - val_loss: 1.0282 - val_mae: 0.8122\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.9242 - mae: 0.7044 - val_loss: 1.0290 - val_mae: 0.7785\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.9232 - mae: 0.6976 - val_loss: 1.0170 - val_mae: 0.7951\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.9158 - mae: 0.6998 - val_loss: 1.0133 - val_mae: 0.7863\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9134 - mae: 0.7018 - val_loss: 1.0086 - val_mae: 0.7982\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.9142 - mae: 0.6981 - val_loss: 1.0071 - val_mae: 0.7850\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9048 - mae: 0.7004 - val_loss: 1.0015 - val_mae: 0.7885\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9001 - mae: 0.6986 - val_loss: 1.0039 - val_mae: 0.7861\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9000 - mae: 0.6941 - val_loss: 1.0046 - val_mae: 0.7835\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.8931 - mae: 0.6950 - val_loss: 0.9993 - val_mae: 0.7940\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8997 - mae: 0.7136 - val_loss: 0.9950 - val_mae: 0.7830\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.9093 - mae: 0.6808 - val_loss: 0.9997 - val_mae: 0.7662\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8929 - mae: 0.7081 - val_loss: 1.0022 - val_mae: 0.8164\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8947 - mae: 0.7055 - val_loss: 1.0059 - val_mae: 0.7690\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8890 - mae: 0.6782 - val_loss: 0.9916 - val_mae: 0.7936\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.8860 - mae: 0.7085 - val_loss: 0.9881 - val_mae: 0.7912\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8796 - mae: 0.6996 - val_loss: 0.9854 - val_mae: 0.7810\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8784 - mae: 0.6846 - val_loss: 0.9885 - val_mae: 0.7768\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.8806 - mae: 0.6828 - val_loss: 0.9885 - val_mae: 0.7784\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.9076 - mae: 0.7205 - val_loss: 0.9915 - val_mae: 0.8027\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8795 - mae: 0.6761 - val_loss: 1.0088 - val_mae: 0.7591\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8846 - mae: 0.6800 - val_loss: 0.9921 - val_mae: 0.8061\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.8704 - mae: 0.7068 - val_loss: 0.9869 - val_mae: 0.7771\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8803 - mae: 0.6726 - val_loss: 0.9848 - val_mae: 0.7786\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8690 - mae: 0.6968 - val_loss: 0.9887 - val_mae: 0.7950\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8610 - mae: 0.6886 - val_loss: 0.9841 - val_mae: 0.7828\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.8716 - mae: 0.6843 - val_loss: 0.9823 - val_mae: 0.7805\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.8584 - mae: 0.6925 - val_loss: 0.9860 - val_mae: 0.7982\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8592 - mae: 0.6888 - val_loss: 0.9866 - val_mae: 0.7788\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8572 - mae: 0.6895 - val_loss: 0.9881 - val_mae: 0.7935\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8525 - mae: 0.6906 - val_loss: 0.9851 - val_mae: 0.7842\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.7624 - mae: 0.8471\n",
      "Mean Absolute Error on Test Data: 0.8470959663391113\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "R-squared: -0.12464863180302599\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 16ms/step - loss: 23.9660 - mae: 3.5557 - val_loss: 23.3173 - val_mae: 3.1064\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3881 - mae: 2.5992 - val_loss: 15.5849 - val_mae: 2.3673\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.6922 - mae: 2.2967 - val_loss: 13.8216 - val_mae: 2.4886\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.1051 - mae: 2.3423 - val_loss: 13.8027 - val_mae: 2.3380\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 11.0359 - mae: 2.2331 - val_loss: 13.6860 - val_mae: 2.3423\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.9981 - mae: 2.2335 - val_loss: 13.6155 - val_mae: 2.3533\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.0287 - mae: 2.3506 - val_loss: 13.5503 - val_mae: 2.3716\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.8433 - mae: 2.2306 - val_loss: 13.6689 - val_mae: 2.3101\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 10.8755 - mae: 2.2095 - val_loss: 13.5521 - val_mae: 2.3322\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7989 - mae: 2.2546 - val_loss: 13.5021 - val_mae: 2.3618\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7819 - mae: 2.2779 - val_loss: 13.4886 - val_mae: 2.3369\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7363 - mae: 2.2581 - val_loss: 13.4876 - val_mae: 2.3243\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7851 - mae: 2.2075 - val_loss: 13.4332 - val_mae: 2.3345\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.6800 - mae: 2.2623 - val_loss: 13.3960 - val_mae: 2.3516\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7274 - mae: 2.2898 - val_loss: 13.4276 - val_mae: 2.3329\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 10.7104 - mae: 2.2797 - val_loss: 13.3955 - val_mae: 2.3322\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7486 - mae: 2.1951 - val_loss: 13.4306 - val_mae: 2.3194\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.6924 - mae: 2.2618 - val_loss: 13.3910 - val_mae: 2.3211\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.6217 - mae: 2.2143 - val_loss: 13.4591 - val_mae: 2.3125\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7151 - mae: 2.2339 - val_loss: 13.3212 - val_mae: 2.3679\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 10.6698 - mae: 2.2332 - val_loss: 13.4095 - val_mae: 2.3163\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.6689 - mae: 2.2756 - val_loss: 13.3100 - val_mae: 2.3365\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5656 - mae: 2.2176 - val_loss: 13.4309 - val_mae: 2.3141\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 10.5443 - mae: 2.2190 - val_loss: 13.2963 - val_mae: 2.3481\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.5438 - mae: 2.2525 - val_loss: 13.3132 - val_mae: 2.3312\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 10.5708 - mae: 2.2320 - val_loss: 13.3252 - val_mae: 2.3338\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5358 - mae: 2.2159 - val_loss: 13.3633 - val_mae: 2.3282\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5790 - mae: 2.2601 - val_loss: 13.3302 - val_mae: 2.3461\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5803 - mae: 2.2038 - val_loss: 13.3454 - val_mae: 2.3326\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4958 - mae: 2.2376 - val_loss: 13.2696 - val_mae: 2.3609\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5237 - mae: 2.2663 - val_loss: 13.2751 - val_mae: 2.3568\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 10.4788 - mae: 2.2382 - val_loss: 13.2892 - val_mae: 2.3393\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.4786 - mae: 2.2431 - val_loss: 13.3266 - val_mae: 2.3332\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4997 - mae: 2.2430 - val_loss: 13.2986 - val_mae: 2.3405\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.5130 - mae: 2.2081 - val_loss: 13.3196 - val_mae: 2.3516\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.4850 - mae: 2.2813 - val_loss: 13.2796 - val_mae: 2.3410\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 10.4983 - mae: 2.1826 - val_loss: 13.3981 - val_mae: 2.3177\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 10.4369 - mae: 2.2150 - val_loss: 13.2476 - val_mae: 2.3629\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4427 - mae: 2.2326 - val_loss: 13.2594 - val_mae: 2.3560\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4439 - mae: 2.2713 - val_loss: 13.3515 - val_mae: 2.3362\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4635 - mae: 2.1958 - val_loss: 13.2738 - val_mae: 2.3459\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4564 - mae: 2.2840 - val_loss: 13.3044 - val_mae: 2.3438\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 10.4694 - mae: 2.1979 - val_loss: 13.3339 - val_mae: 2.3356\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3786 - mae: 2.2332 - val_loss: 13.3268 - val_mae: 2.3405\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4221 - mae: 2.1906 - val_loss: 13.2936 - val_mae: 2.3515\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4569 - mae: 2.2692 - val_loss: 13.2820 - val_mae: 2.3357\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3869 - mae: 2.2103 - val_loss: 13.3761 - val_mae: 2.3336\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3923 - mae: 2.2646 - val_loss: 13.2539 - val_mae: 2.3744\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 10.3530 - mae: 2.2287 - val_loss: 13.3172 - val_mae: 2.3419\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3458 - mae: 2.2346 - val_loss: 13.3374 - val_mae: 2.3357\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 11.2672 - mae: 2.4165\n",
      "Mean Absolute Error on Test Data: 2.4165005683898926\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.04968570776046832\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 1s 16ms/step - loss: 10.1293 - mae: 2.1450 - val_loss: 5.2206 - val_mae: 1.5849\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 6.6124 - mae: 1.5461 - val_loss: 3.5241 - val_mae: 1.5077\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 5.7416 - mae: 1.6504 - val_loss: 3.6454 - val_mae: 1.5688\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.6545 - mae: 1.5665 - val_loss: 3.5011 - val_mae: 1.4828\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.5422 - mae: 1.5336 - val_loss: 3.5443 - val_mae: 1.5144\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.4806 - mae: 1.5536 - val_loss: 3.5797 - val_mae: 1.5259\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.4437 - mae: 1.5477 - val_loss: 3.5728 - val_mae: 1.5103\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.4182 - mae: 1.5500 - val_loss: 3.6119 - val_mae: 1.5207\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.3736 - mae: 1.5253 - val_loss: 3.6635 - val_mae: 1.5367\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 5.3772 - mae: 1.5266 - val_loss: 3.6968 - val_mae: 1.5416\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.3174 - mae: 1.5547 - val_loss: 3.7258 - val_mae: 1.5443\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.2886 - mae: 1.5398 - val_loss: 3.7440 - val_mae: 1.5406\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.2719 - mae: 1.5204 - val_loss: 3.7944 - val_mae: 1.5597\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.2512 - mae: 1.5342 - val_loss: 3.7697 - val_mae: 1.5367\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 5.2532 - mae: 1.4876 - val_loss: 3.8717 - val_mae: 1.5836\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.2141 - mae: 1.5460 - val_loss: 3.8562 - val_mae: 1.5553\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.1873 - mae: 1.4928 - val_loss: 3.8861 - val_mae: 1.5731\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.1580 - mae: 1.5193 - val_loss: 3.9622 - val_mae: 1.5997\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.1921 - mae: 1.4931 - val_loss: 3.9474 - val_mae: 1.5982\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.1527 - mae: 1.5342 - val_loss: 3.9356 - val_mae: 1.5888\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.1495 - mae: 1.4863 - val_loss: 4.0132 - val_mae: 1.6132\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 5.0964 - mae: 1.5200 - val_loss: 3.9611 - val_mae: 1.5832\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.0771 - mae: 1.4969 - val_loss: 4.0237 - val_mae: 1.6106\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.0653 - mae: 1.4988 - val_loss: 3.9915 - val_mae: 1.5939\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 5.0488 - mae: 1.4957 - val_loss: 4.1896 - val_mae: 1.6603\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.0469 - mae: 1.5432 - val_loss: 4.0210 - val_mae: 1.5725\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.0424 - mae: 1.4800 - val_loss: 4.0246 - val_mae: 1.5785\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 5.0231 - mae: 1.4885 - val_loss: 4.1298 - val_mae: 1.6437\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.1039 - mae: 1.4913 - val_loss: 4.1726 - val_mae: 1.6618\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.0015 - mae: 1.5410 - val_loss: 4.0485 - val_mae: 1.6043\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.9858 - mae: 1.4565 - val_loss: 4.1020 - val_mae: 1.6261\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.9575 - mae: 1.5095 - val_loss: 4.1377 - val_mae: 1.6360\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.9498 - mae: 1.4628 - val_loss: 4.0423 - val_mae: 1.6064\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.9282 - mae: 1.5183 - val_loss: 4.1356 - val_mae: 1.6247\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.9509 - mae: 1.4368 - val_loss: 4.1501 - val_mae: 1.6369\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.0063 - mae: 1.5568 - val_loss: 4.0813 - val_mae: 1.5741\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.9906 - mae: 1.4643 - val_loss: 4.2676 - val_mae: 1.6827\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.9152 - mae: 1.4714 - val_loss: 4.1256 - val_mae: 1.6142\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.8682 - mae: 1.4921 - val_loss: 4.1854 - val_mae: 1.6509\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 4.8381 - mae: 1.4812 - val_loss: 4.1428 - val_mae: 1.6150\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.8566 - mae: 1.4516 - val_loss: 4.1648 - val_mae: 1.6363\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.8567 - mae: 1.4780 - val_loss: 4.1316 - val_mae: 1.6120\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.8337 - mae: 1.4822 - val_loss: 4.1426 - val_mae: 1.6163\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.8011 - mae: 1.4704 - val_loss: 4.2792 - val_mae: 1.6579\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.8248 - mae: 1.4720 - val_loss: 4.2542 - val_mae: 1.6612\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.7801 - mae: 1.4552 - val_loss: 4.1966 - val_mae: 1.6325\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 4.7736 - mae: 1.4738 - val_loss: 4.2335 - val_mae: 1.6423\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.7747 - mae: 1.4642 - val_loss: 4.2331 - val_mae: 1.6354\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.7437 - mae: 1.4451 - val_loss: 4.3386 - val_mae: 1.6865\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.7341 - mae: 1.4772 - val_loss: 4.1892 - val_mae: 1.6274\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.9597 - mae: 1.7199\n",
      "Mean Absolute Error on Test Data: 1.719933032989502\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.06034871835325606\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 4.6897 - mae: 1.4838 - val_loss: 2.1180 - val_mae: 0.9312\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.8071 - mae: 1.1034 - val_loss: 1.9030 - val_mae: 1.0722\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5731 - mae: 1.1588 - val_loss: 1.8522 - val_mae: 1.0463\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4882 - mae: 1.0969 - val_loss: 1.7845 - val_mae: 1.0021\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4695 - mae: 1.0730 - val_loss: 1.7660 - val_mae: 0.9874\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4494 - mae: 1.0865 - val_loss: 1.8239 - val_mae: 1.0328\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4122 - mae: 1.0886 - val_loss: 1.7789 - val_mae: 1.0000\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4172 - mae: 1.0524 - val_loss: 1.7825 - val_mae: 0.9967\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3795 - mae: 1.0886 - val_loss: 1.8731 - val_mae: 1.0570\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3824 - mae: 1.1030 - val_loss: 1.7935 - val_mae: 1.0094\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3413 - mae: 1.0582 - val_loss: 1.7889 - val_mae: 1.0074\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.3280 - mae: 1.0588 - val_loss: 1.8042 - val_mae: 1.0170\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3137 - mae: 1.0547 - val_loss: 1.8023 - val_mae: 1.0176\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3157 - mae: 1.0490 - val_loss: 1.8114 - val_mae: 1.0219\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.3097 - mae: 1.0772 - val_loss: 1.8442 - val_mae: 1.0387\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2992 - mae: 1.0418 - val_loss: 1.8171 - val_mae: 1.0180\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2768 - mae: 1.0576 - val_loss: 1.8305 - val_mae: 1.0319\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2791 - mae: 1.0685 - val_loss: 1.8241 - val_mae: 1.0242\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 2.2656 - mae: 1.0508 - val_loss: 1.8569 - val_mae: 1.0437\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2845 - mae: 1.0841 - val_loss: 1.8057 - val_mae: 1.0095\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2935 - mae: 1.0210 - val_loss: 1.8083 - val_mae: 1.0166\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2754 - mae: 1.0721 - val_loss: 1.8178 - val_mae: 1.0168\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2479 - mae: 1.0332 - val_loss: 1.8337 - val_mae: 1.0318\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.2656 - mae: 1.0717 - val_loss: 1.7963 - val_mae: 1.0069\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2423 - mae: 1.0360 - val_loss: 1.8539 - val_mae: 1.0477\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2364 - mae: 1.0415 - val_loss: 1.8090 - val_mae: 1.0216\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2321 - mae: 1.0423 - val_loss: 1.8527 - val_mae: 1.0436\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2664 - mae: 1.0362 - val_loss: 1.9051 - val_mae: 1.0695\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2325 - mae: 1.0619 - val_loss: 1.8147 - val_mae: 1.0210\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2385 - mae: 1.0156 - val_loss: 1.7873 - val_mae: 1.0017\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 2.2589 - mae: 1.0854 - val_loss: 1.8515 - val_mae: 1.0438\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2331 - mae: 1.0187 - val_loss: 1.8029 - val_mae: 1.0125\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2241 - mae: 1.0522 - val_loss: 1.8892 - val_mae: 1.0623\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2159 - mae: 1.0354 - val_loss: 1.8188 - val_mae: 1.0174\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2151 - mae: 1.0273 - val_loss: 1.8651 - val_mae: 1.0459\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2190 - mae: 1.0431 - val_loss: 1.8691 - val_mae: 1.0562\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2089 - mae: 1.0513 - val_loss: 1.8176 - val_mae: 1.0206\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.2108 - mae: 1.0404 - val_loss: 1.8024 - val_mae: 1.0051\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2426 - mae: 1.0095 - val_loss: 1.8888 - val_mae: 1.0648\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2421 - mae: 1.0730 - val_loss: 1.7741 - val_mae: 0.9901\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2175 - mae: 1.0208 - val_loss: 1.9129 - val_mae: 1.0767\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2020 - mae: 1.0489 - val_loss: 1.8258 - val_mae: 1.0192\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2132 - mae: 1.0109 - val_loss: 1.8627 - val_mae: 1.0508\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2256 - mae: 1.0877 - val_loss: 1.7822 - val_mae: 1.0051\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2154 - mae: 1.0104 - val_loss: 1.7771 - val_mae: 0.9968\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2489 - mae: 1.0786 - val_loss: 1.8830 - val_mae: 1.0527\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2557 - mae: 1.0126 - val_loss: 1.8876 - val_mae: 1.0576\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2091 - mae: 1.0611 - val_loss: 1.8049 - val_mae: 1.0056\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.1961 - mae: 1.0077 - val_loss: 1.8278 - val_mae: 1.0212\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1829 - mae: 1.0398 - val_loss: 1.8534 - val_mae: 1.0373\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.8863 - mae: 1.1870\n",
      "Mean Absolute Error on Test Data: 1.1870090961456299\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.043278535942359864\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 18.5088 - mae: 3.2085 - val_loss: 21.5329 - val_mae: 3.0589\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12.7989 - mae: 2.3516 - val_loss: 15.0375 - val_mae: 2.3755\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.7107 - mae: 1.9770 - val_loss: 12.3254 - val_mae: 2.2917\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.2176 - mae: 2.0933 - val_loss: 12.2706 - val_mae: 2.2770\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.0818 - mae: 2.0152 - val_loss: 12.3631 - val_mae: 2.2490\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.0856 - mae: 2.0040 - val_loss: 12.2737 - val_mae: 2.2422\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.0439 - mae: 1.9856 - val_loss: 12.1997 - val_mae: 2.2362\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.0114 - mae: 1.9917 - val_loss: 12.1390 - val_mae: 2.2328\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9930 - mae: 1.9934 - val_loss: 12.1305 - val_mae: 2.2237\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9865 - mae: 1.9733 - val_loss: 12.1058 - val_mae: 2.2179\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9702 - mae: 2.0038 - val_loss: 12.0165 - val_mae: 2.2209\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9535 - mae: 1.9954 - val_loss: 12.0089 - val_mae: 2.2138\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.9703 - mae: 1.9794 - val_loss: 12.0229 - val_mae: 2.2052\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9365 - mae: 1.9711 - val_loss: 12.0184 - val_mae: 2.1988\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9553 - mae: 2.0055 - val_loss: 11.9254 - val_mae: 2.2043\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9137 - mae: 1.9774 - val_loss: 11.9967 - val_mae: 2.1937\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9279 - mae: 1.9713 - val_loss: 11.8855 - val_mae: 2.2010\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9320 - mae: 1.9714 - val_loss: 11.9362 - val_mae: 2.1881\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 7.9355 - mae: 2.0057 - val_loss: 11.8838 - val_mae: 2.1900\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9713 - mae: 1.9473 - val_loss: 11.9799 - val_mae: 2.1819\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8978 - mae: 2.0128 - val_loss: 11.8032 - val_mae: 2.2066\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9183 - mae: 1.9785 - val_loss: 11.9642 - val_mae: 2.1811\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8761 - mae: 1.9860 - val_loss: 11.8113 - val_mae: 2.1990\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9040 - mae: 1.9707 - val_loss: 11.9640 - val_mae: 2.1737\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 7.9246 - mae: 1.9983 - val_loss: 11.8923 - val_mae: 2.1832\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8689 - mae: 1.9584 - val_loss: 11.8686 - val_mae: 2.1837\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8604 - mae: 2.0005 - val_loss: 11.8079 - val_mae: 2.1853\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9371 - mae: 1.9569 - val_loss: 11.9638 - val_mae: 2.1689\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9628 - mae: 2.0251 - val_loss: 11.8630 - val_mae: 2.1808\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8413 - mae: 1.9638 - val_loss: 11.9084 - val_mae: 2.1724\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.8327 - mae: 1.9662 - val_loss: 11.7895 - val_mae: 2.1840\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8376 - mae: 1.9734 - val_loss: 11.8386 - val_mae: 2.1789\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8444 - mae: 1.9579 - val_loss: 11.8624 - val_mae: 2.1727\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8531 - mae: 2.0021 - val_loss: 11.8206 - val_mae: 2.1793\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.8232 - mae: 1.9515 - val_loss: 11.9186 - val_mae: 2.1667\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.8661 - mae: 1.9840 - val_loss: 11.7506 - val_mae: 2.1826\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7996 - mae: 1.9793 - val_loss: 11.8581 - val_mae: 2.1710\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8017 - mae: 1.9462 - val_loss: 11.8918 - val_mae: 2.1710\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8119 - mae: 1.9744 - val_loss: 11.7546 - val_mae: 2.1928\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7960 - mae: 1.9827 - val_loss: 11.8190 - val_mae: 2.1787\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8053 - mae: 1.9724 - val_loss: 11.9983 - val_mae: 2.1620\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7771 - mae: 1.9524 - val_loss: 11.8231 - val_mae: 2.1799\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.7592 - mae: 1.9868 - val_loss: 11.8541 - val_mae: 2.1750\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7943 - mae: 1.9394 - val_loss: 11.8738 - val_mae: 2.1740\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7899 - mae: 1.9910 - val_loss: 11.8533 - val_mae: 2.1678\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7503 - mae: 1.9485 - val_loss: 11.8106 - val_mae: 2.1751\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7692 - mae: 1.9789 - val_loss: 11.9117 - val_mae: 2.1718\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7405 - mae: 1.9537 - val_loss: 11.8643 - val_mae: 2.1771\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.7436 - mae: 1.9809 - val_loss: 11.8304 - val_mae: 2.1758\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7561 - mae: 1.9413 - val_loss: 11.8610 - val_mae: 2.1654\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.9005 - mae: 1.8694\n",
      "Mean Absolute Error on Test Data: 1.8693714141845703\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.07664125288584989\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 15ms/step - loss: 102.7841 - mae: 8.3167 - val_loss: 109.1945 - val_mae: 8.0836\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 74.0821 - mae: 6.5224 - val_loss: 73.0942 - val_mae: 5.9298\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.8318 - mae: 4.4948 - val_loss: 43.2358 - val_mae: 4.4010\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 32.8859 - mae: 4.3515 - val_loss: 40.3648 - val_mae: 4.6710\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 32.0026 - mae: 4.3057 - val_loss: 41.2383 - val_mae: 4.4411\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 32.0682 - mae: 4.1515 - val_loss: 41.1722 - val_mae: 4.4477\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 31.8324 - mae: 4.1882 - val_loss: 40.7433 - val_mae: 4.4848\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.9239 - mae: 4.2284 - val_loss: 41.0035 - val_mae: 4.4491\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.8704 - mae: 4.2127 - val_loss: 40.9171 - val_mae: 4.4540\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.8073 - mae: 4.2206 - val_loss: 40.6728 - val_mae: 4.4700\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 31.7489 - mae: 4.1942 - val_loss: 41.0321 - val_mae: 4.4429\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.8135 - mae: 4.1637 - val_loss: 40.8899 - val_mae: 4.4572\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 31.7617 - mae: 4.1628 - val_loss: 40.8881 - val_mae: 4.4519\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.7263 - mae: 4.2035 - val_loss: 40.5890 - val_mae: 4.4656\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.7805 - mae: 4.2339 - val_loss: 40.8854 - val_mae: 4.4443\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.6754 - mae: 4.1736 - val_loss: 40.7048 - val_mae: 4.4499\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 31.6514 - mae: 4.1692 - val_loss: 40.6732 - val_mae: 4.4387\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 31.6710 - mae: 4.1668 - val_loss: 40.8771 - val_mae: 4.4241\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.7110 - mae: 4.2208 - val_loss: 40.7512 - val_mae: 4.4387\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.6888 - mae: 4.1426 - val_loss: 40.8568 - val_mae: 4.4349\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 31.6705 - mae: 4.2178 - val_loss: 40.8230 - val_mae: 4.4469\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.7287 - mae: 4.1039 - val_loss: 40.9350 - val_mae: 4.4286\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 32.0670 - mae: 4.3110 - val_loss: 40.4113 - val_mae: 4.4638\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.9710 - mae: 4.0921 - val_loss: 41.4191 - val_mae: 4.3933\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.5303 - mae: 4.1970 - val_loss: 40.2605 - val_mae: 4.4818\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.6925 - mae: 4.2511 - val_loss: 40.9707 - val_mae: 4.4150\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.5633 - mae: 4.1239 - val_loss: 40.7968 - val_mae: 4.4157\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.4694 - mae: 4.2101 - val_loss: 40.1443 - val_mae: 4.4822\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 31.6049 - mae: 4.2762 - val_loss: 40.4612 - val_mae: 4.4321\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.4743 - mae: 4.1297 - val_loss: 40.8520 - val_mae: 4.4004\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.5501 - mae: 4.1445 - val_loss: 40.4683 - val_mae: 4.4373\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.3980 - mae: 4.1555 - val_loss: 41.1076 - val_mae: 4.3994\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 31.4831 - mae: 4.1556 - val_loss: 40.6537 - val_mae: 4.4226\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 31.4197 - mae: 4.1902 - val_loss: 40.4756 - val_mae: 4.4402\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 31.4160 - mae: 4.1738 - val_loss: 40.8237 - val_mae: 4.4100\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.3823 - mae: 4.1286 - val_loss: 40.9338 - val_mae: 4.3926\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.3534 - mae: 4.1258 - val_loss: 40.3536 - val_mae: 4.4353\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.4803 - mae: 4.2113 - val_loss: 41.0102 - val_mae: 4.3991\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 31.3370 - mae: 4.1238 - val_loss: 40.5097 - val_mae: 4.4275\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.3644 - mae: 4.2042 - val_loss: 40.2940 - val_mae: 4.4436\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.4582 - mae: 4.1461 - val_loss: 40.3820 - val_mae: 4.4354\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.3796 - mae: 4.2172 - val_loss: 40.5326 - val_mae: 4.4254\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.3396 - mae: 4.1343 - val_loss: 40.9467 - val_mae: 4.3995\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.4423 - mae: 4.0918 - val_loss: 40.3346 - val_mae: 4.4449\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.4653 - mae: 4.2686 - val_loss: 40.5176 - val_mae: 4.4265\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.2616 - mae: 4.0921 - val_loss: 41.2819 - val_mae: 4.3795\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 31.5040 - mae: 4.1682 - val_loss: 39.9852 - val_mae: 4.4935\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.4212 - mae: 4.1165 - val_loss: 41.1542 - val_mae: 4.3889\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.3505 - mae: 4.2085 - val_loss: 40.3602 - val_mae: 4.4405\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.3234 - mae: 4.1087 - val_loss: 40.6904 - val_mae: 4.4049\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 51.8168 - mae: 4.5539\n",
      "Mean Absolute Error on Test Data: 4.553873538970947\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: -0.007709624932532799\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 15ms/step - loss: 18.6106 - mae: 3.1939 - val_loss: 16.4059 - val_mae: 2.8668\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.4580 - mae: 2.4174 - val_loss: 11.4239 - val_mae: 2.1303\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.2492 - mae: 1.9476 - val_loss: 8.1047 - val_mae: 1.8481\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.2031 - mae: 2.0137 - val_loss: 7.8971 - val_mae: 1.9400\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.1727 - mae: 2.0080 - val_loss: 7.8756 - val_mae: 1.8656\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.1021 - mae: 1.9446 - val_loss: 7.9247 - val_mae: 1.8448\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 8.0801 - mae: 1.9551 - val_loss: 7.8261 - val_mae: 1.8613\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.0456 - mae: 1.9384 - val_loss: 7.8315 - val_mae: 1.8462\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.0297 - mae: 1.9719 - val_loss: 7.7601 - val_mae: 1.8605\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9741 - mae: 1.9550 - val_loss: 7.7512 - val_mae: 1.8517\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9544 - mae: 1.9459 - val_loss: 7.7530 - val_mae: 1.8390\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9538 - mae: 1.9481 - val_loss: 7.7206 - val_mae: 1.8386\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.9397 - mae: 1.9205 - val_loss: 7.7731 - val_mae: 1.8293\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9371 - mae: 1.9528 - val_loss: 7.6641 - val_mae: 1.8678\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9101 - mae: 1.9495 - val_loss: 7.6912 - val_mae: 1.8352\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9206 - mae: 1.9470 - val_loss: 7.6598 - val_mae: 1.8548\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9128 - mae: 1.9318 - val_loss: 7.6796 - val_mae: 1.8267\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8822 - mae: 1.9663 - val_loss: 7.6351 - val_mae: 1.8571\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.8790 - mae: 1.9293 - val_loss: 7.7234 - val_mae: 1.8230\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8600 - mae: 1.9470 - val_loss: 7.6415 - val_mae: 1.8472\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8608 - mae: 1.9478 - val_loss: 7.6957 - val_mae: 1.8223\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8547 - mae: 1.9262 - val_loss: 7.6378 - val_mae: 1.8366\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8521 - mae: 1.9650 - val_loss: 7.6197 - val_mae: 1.8716\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.8443 - mae: 1.9553 - val_loss: 7.7048 - val_mae: 1.8157\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8312 - mae: 1.9210 - val_loss: 7.6394 - val_mae: 1.8345\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8159 - mae: 1.9321 - val_loss: 7.6263 - val_mae: 1.8437\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8275 - mae: 1.9670 - val_loss: 7.6194 - val_mae: 1.8470\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8046 - mae: 1.9376 - val_loss: 7.6471 - val_mae: 1.8374\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8244 - mae: 1.9210 - val_loss: 7.6496 - val_mae: 1.8348\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 7.8002 - mae: 1.9617 - val_loss: 7.6350 - val_mae: 1.8652\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8164 - mae: 1.9797 - val_loss: 7.6784 - val_mae: 1.8278\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.8255 - mae: 1.9094 - val_loss: 7.6836 - val_mae: 1.8254\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7925 - mae: 1.9171 - val_loss: 7.6153 - val_mae: 1.8525\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7955 - mae: 1.9714 - val_loss: 7.6287 - val_mae: 1.8526\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.8091 - mae: 1.9261 - val_loss: 7.6721 - val_mae: 1.8378\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7829 - mae: 1.9342 - val_loss: 7.6904 - val_mae: 1.8286\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7623 - mae: 1.9287 - val_loss: 7.6128 - val_mae: 1.8569\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7669 - mae: 1.9557 - val_loss: 7.6739 - val_mae: 1.8425\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7971 - mae: 1.9148 - val_loss: 7.6533 - val_mae: 1.8510\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.7705 - mae: 1.9634 - val_loss: 7.6659 - val_mae: 1.8441\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7502 - mae: 1.9294 - val_loss: 7.6722 - val_mae: 1.8354\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7276 - mae: 1.9267 - val_loss: 7.6794 - val_mae: 1.8524\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7792 - mae: 1.9708 - val_loss: 7.7016 - val_mae: 1.8447\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7969 - mae: 1.9017 - val_loss: 7.7202 - val_mae: 1.8337\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.8253 - mae: 1.9900 - val_loss: 7.6670 - val_mae: 1.8596\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7417 - mae: 1.9111 - val_loss: 7.6781 - val_mae: 1.8354\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7165 - mae: 1.9422 - val_loss: 7.6983 - val_mae: 1.8495\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7091 - mae: 1.9256 - val_loss: 7.7043 - val_mae: 1.8313\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.7027 - mae: 1.9331 - val_loss: 7.6984 - val_mae: 1.8589\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7014 - mae: 1.9287 - val_loss: 7.6978 - val_mae: 1.8533\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8534 - mae: 1.7813\n",
      "Mean Absolute Error on Test Data: 1.7813308238983154\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.0066214396275144916\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 28.7911 - mae: 4.3975 - val_loss: 24.5169 - val_mae: 3.7568\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 18.0405 - mae: 3.1990 - val_loss: 14.0728 - val_mae: 2.6056\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1701 - mae: 2.3149 - val_loss: 11.2293 - val_mae: 2.5853\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.1808 - mae: 2.3227 - val_loss: 10.9244 - val_mae: 2.4693\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.9448 - mae: 2.2145 - val_loss: 10.9267 - val_mae: 2.4721\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 8.9037 - mae: 2.2347 - val_loss: 10.9522 - val_mae: 2.4876\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.8269 - mae: 2.2100 - val_loss: 10.9249 - val_mae: 2.4645\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.8311 - mae: 2.2058 - val_loss: 10.9525 - val_mae: 2.4813\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.7926 - mae: 2.2246 - val_loss: 10.9495 - val_mae: 2.4745\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.8014 - mae: 2.2284 - val_loss: 10.9620 - val_mae: 2.4780\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.7699 - mae: 2.2029 - val_loss: 10.9556 - val_mae: 2.4697\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.7235 - mae: 2.2104 - val_loss: 11.0122 - val_mae: 2.4955\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.7188 - mae: 2.2257 - val_loss: 10.9714 - val_mae: 2.4715\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.7224 - mae: 2.2005 - val_loss: 11.0092 - val_mae: 2.4891\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.6990 - mae: 2.2213 - val_loss: 10.9878 - val_mae: 2.4772\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 8.6768 - mae: 2.2147 - val_loss: 11.0032 - val_mae: 2.4807\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.6916 - mae: 2.2073 - val_loss: 11.0279 - val_mae: 2.4927\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.6575 - mae: 2.2130 - val_loss: 11.0075 - val_mae: 2.4758\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.6986 - mae: 2.2156 - val_loss: 11.0004 - val_mae: 2.4599\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.7686 - mae: 2.2321 - val_loss: 11.0492 - val_mae: 2.4917\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.6451 - mae: 2.1887 - val_loss: 11.0162 - val_mae: 2.4570\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.6969 - mae: 2.2297 - val_loss: 11.0981 - val_mae: 2.5046\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.6521 - mae: 2.2100 - val_loss: 11.0443 - val_mae: 2.4796\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.6175 - mae: 2.1945 - val_loss: 11.0509 - val_mae: 2.4844\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.6609 - mae: 2.2398 - val_loss: 11.0356 - val_mae: 2.4767\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.6063 - mae: 2.1961 - val_loss: 11.0466 - val_mae: 2.4840\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 8.5979 - mae: 2.2142 - val_loss: 11.0678 - val_mae: 2.4910\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5799 - mae: 2.2016 - val_loss: 11.0518 - val_mae: 2.4814\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5685 - mae: 2.2061 - val_loss: 11.0565 - val_mae: 2.4824\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5645 - mae: 2.1946 - val_loss: 11.0438 - val_mae: 2.4785\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5731 - mae: 2.2188 - val_loss: 11.0828 - val_mae: 2.4925\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 8.5880 - mae: 2.1828 - val_loss: 11.0522 - val_mae: 2.4743\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5356 - mae: 2.2064 - val_loss: 11.0931 - val_mae: 2.4944\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5689 - mae: 2.2242 - val_loss: 11.0856 - val_mae: 2.4891\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5472 - mae: 2.1900 - val_loss: 11.0524 - val_mae: 2.4782\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5594 - mae: 2.1862 - val_loss: 11.0509 - val_mae: 2.4755\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 8.5732 - mae: 2.2339 - val_loss: 11.0711 - val_mae: 2.4840\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.5053 - mae: 2.1810 - val_loss: 11.0526 - val_mae: 2.4599\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5061 - mae: 2.1923 - val_loss: 11.0708 - val_mae: 2.4855\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5043 - mae: 2.1910 - val_loss: 11.0658 - val_mae: 2.4761\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5324 - mae: 2.2138 - val_loss: 11.0682 - val_mae: 2.4740\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5006 - mae: 2.1944 - val_loss: 11.0562 - val_mae: 2.4653\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 8.5040 - mae: 2.1697 - val_loss: 11.0710 - val_mae: 2.4758\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.5053 - mae: 2.2255 - val_loss: 11.0978 - val_mae: 2.4953\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.5870 - mae: 2.1917 - val_loss: 11.1210 - val_mae: 2.4998\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.4490 - mae: 2.1916 - val_loss: 11.0891 - val_mae: 2.4809\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.4713 - mae: 2.1921 - val_loss: 11.0732 - val_mae: 2.4611\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 8.4499 - mae: 2.1917 - val_loss: 11.0872 - val_mae: 2.4856\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.5296 - mae: 2.1952 - val_loss: 11.1618 - val_mae: 2.5123\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.4192 - mae: 2.1991 - val_loss: 11.1024 - val_mae: 2.4789\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.3906 - mae: 2.3765\n",
      "Mean Absolute Error on Test Data: 2.3765289783477783\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.014464891712135497\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 10ms/step - loss: 74.1992 - mae: 7.2400 - val_loss: 73.7319 - val_mae: 6.6894\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 54.3961 - mae: 5.7625 - val_loss: 48.9595 - val_mae: 4.7277\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 29.6808 - mae: 3.7737 - val_loss: 29.3277 - val_mae: 3.4184\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 20.8774 - mae: 3.4075 - val_loss: 28.9528 - val_mae: 3.6385\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.8056 - mae: 3.4295 - val_loss: 28.6322 - val_mae: 3.4634\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.6452 - mae: 3.3045 - val_loss: 28.7133 - val_mae: 3.4335\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.5112 - mae: 3.2948 - val_loss: 28.4759 - val_mae: 3.4774\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.4586 - mae: 3.2939 - val_loss: 28.4738 - val_mae: 3.4754\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.4613 - mae: 3.3521 - val_loss: 28.4758 - val_mae: 3.4660\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.3440 - mae: 3.2909 - val_loss: 28.5756 - val_mae: 3.4405\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.3017 - mae: 3.2954 - val_loss: 28.4744 - val_mae: 3.4695\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.2109 - mae: 3.2820 - val_loss: 28.5040 - val_mae: 3.4664\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 20.1831 - mae: 3.2858 - val_loss: 28.5021 - val_mae: 3.4678\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.2194 - mae: 3.2817 - val_loss: 28.5648 - val_mae: 3.4472\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.0858 - mae: 3.2664 - val_loss: 28.4934 - val_mae: 3.4967\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.2859 - mae: 3.3981 - val_loss: 28.4553 - val_mae: 3.4958\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.0616 - mae: 3.2682 - val_loss: 28.5257 - val_mae: 3.4521\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 20.0120 - mae: 3.2921 - val_loss: 28.4730 - val_mae: 3.4927\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.1360 - mae: 3.2949 - val_loss: 28.5564 - val_mae: 3.4485\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.9541 - mae: 3.2935 - val_loss: 28.5249 - val_mae: 3.5014\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.9513 - mae: 3.2871 - val_loss: 28.5349 - val_mae: 3.4689\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.9849 - mae: 3.3048 - val_loss: 28.5380 - val_mae: 3.4888\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 19.9203 - mae: 3.2941 - val_loss: 28.5662 - val_mae: 3.4569\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.8658 - mae: 3.2622 - val_loss: 28.6057 - val_mae: 3.4814\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.8643 - mae: 3.2888 - val_loss: 28.6444 - val_mae: 3.4584\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.9399 - mae: 3.2372 - val_loss: 28.6777 - val_mae: 3.5016\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 19.8301 - mae: 3.3004 - val_loss: 28.5969 - val_mae: 3.4810\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 19.8473 - mae: 3.2918 - val_loss: 28.6295 - val_mae: 3.4479\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.9509 - mae: 3.2429 - val_loss: 28.5983 - val_mae: 3.5086\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.8314 - mae: 3.2913 - val_loss: 28.6157 - val_mae: 3.4827\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.8401 - mae: 3.2824 - val_loss: 28.7934 - val_mae: 3.4338\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.8543 - mae: 3.2127 - val_loss: 28.6309 - val_mae: 3.4736\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 19.7037 - mae: 3.2723 - val_loss: 28.6189 - val_mae: 3.4763\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.7699 - mae: 3.2952 - val_loss: 28.6060 - val_mae: 3.4851\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.8864 - mae: 3.2395 - val_loss: 28.6394 - val_mae: 3.5016\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 19.7300 - mae: 3.2710 - val_loss: 28.6063 - val_mae: 3.4840\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.7951 - mae: 3.2381 - val_loss: 28.6209 - val_mae: 3.4752\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 19.8357 - mae: 3.3294 - val_loss: 28.7403 - val_mae: 3.4407\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 19.9203 - mae: 3.1889 - val_loss: 28.7007 - val_mae: 3.4732\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 19.7139 - mae: 3.3088 - val_loss: 28.6372 - val_mae: 3.4802\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.8178 - mae: 3.2532 - val_loss: 28.5958 - val_mae: 3.4973\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 19.6543 - mae: 3.2544 - val_loss: 28.6952 - val_mae: 3.4649\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.5542 - mae: 3.2410 - val_loss: 28.6844 - val_mae: 3.4940\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.7980 - mae: 3.3535 - val_loss: 28.7866 - val_mae: 3.4501\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 19.7147 - mae: 3.2175 - val_loss: 28.7110 - val_mae: 3.4770\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 19.5385 - mae: 3.2641 - val_loss: 28.6887 - val_mae: 3.4869\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.5434 - mae: 3.2508 - val_loss: 28.7071 - val_mae: 3.4795\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.4892 - mae: 3.2550 - val_loss: 28.7597 - val_mae: 3.4814\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 19.4826 - mae: 3.2183 - val_loss: 28.7207 - val_mae: 3.4789\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 19.4814 - mae: 3.2639 - val_loss: 28.7576 - val_mae: 3.4739\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.2881 - mae: 3.6250\n",
      "Mean Absolute Error on Test Data: 3.625039577484131\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.061872000580122544\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 13ms/step - loss: 14.6453 - mae: 2.7931 - val_loss: 11.2210 - val_mae: 2.2275\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.7991 - mae: 1.9397 - val_loss: 6.5835 - val_mae: 1.7110\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.9695 - mae: 1.9618 - val_loss: 6.4460 - val_mae: 1.8596\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.7701 - mae: 1.9412 - val_loss: 6.3595 - val_mae: 1.7440\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.6557 - mae: 1.8505 - val_loss: 6.4051 - val_mae: 1.7163\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.6268 - mae: 1.8485 - val_loss: 6.3608 - val_mae: 1.7418\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.5850 - mae: 1.8814 - val_loss: 6.3744 - val_mae: 1.7426\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5705 - mae: 1.8456 - val_loss: 6.3956 - val_mae: 1.7270\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5361 - mae: 1.8464 - val_loss: 6.3745 - val_mae: 1.7441\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5218 - mae: 1.8604 - val_loss: 6.3869 - val_mae: 1.7409\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5121 - mae: 1.8429 - val_loss: 6.3836 - val_mae: 1.7244\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.5468 - mae: 1.8886 - val_loss: 6.4031 - val_mae: 1.7362\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.4886 - mae: 1.8191 - val_loss: 6.4405 - val_mae: 1.7114\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.4799 - mae: 1.8275 - val_loss: 6.3717 - val_mae: 1.7453\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.4740 - mae: 1.8485 - val_loss: 6.3914 - val_mae: 1.7240\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4436 - mae: 1.8352 - val_loss: 6.3869 - val_mae: 1.7318\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4921 - mae: 1.8306 - val_loss: 6.3748 - val_mae: 1.7388\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5382 - mae: 1.9166 - val_loss: 6.3600 - val_mae: 1.7467\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.4749 - mae: 1.8207 - val_loss: 6.4494 - val_mae: 1.7073\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.4528 - mae: 1.8575 - val_loss: 6.3714 - val_mae: 1.7508\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.4529 - mae: 1.8263 - val_loss: 6.4106 - val_mae: 1.7276\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.3687 - mae: 1.8372 - val_loss: 6.3654 - val_mae: 1.7380\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.3749 - mae: 1.8474 - val_loss: 6.3845 - val_mae: 1.7261\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.3720 - mae: 1.8229 - val_loss: 6.3781 - val_mae: 1.7294\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.3641 - mae: 1.8673 - val_loss: 6.3782 - val_mae: 1.7512\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.3893 - mae: 1.8152 - val_loss: 6.4144 - val_mae: 1.7362\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.3486 - mae: 1.8550 - val_loss: 6.3757 - val_mae: 1.7352\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.3567 - mae: 1.8070 - val_loss: 6.3820 - val_mae: 1.7399\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2969 - mae: 1.8317 - val_loss: 6.3807 - val_mae: 1.7429\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.2894 - mae: 1.8457 - val_loss: 6.3585 - val_mae: 1.7560\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2834 - mae: 1.8165 - val_loss: 6.4330 - val_mae: 1.7265\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2799 - mae: 1.8223 - val_loss: 6.4287 - val_mae: 1.7474\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2455 - mae: 1.8264 - val_loss: 6.3870 - val_mae: 1.7421\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.2645 - mae: 1.8158 - val_loss: 6.3878 - val_mae: 1.7542\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.2900 - mae: 1.8107 - val_loss: 6.4041 - val_mae: 1.7591\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2195 - mae: 1.8070 - val_loss: 6.4115 - val_mae: 1.7440\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2140 - mae: 1.8182 - val_loss: 6.3862 - val_mae: 1.7587\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2249 - mae: 1.8337 - val_loss: 6.4513 - val_mae: 1.7523\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2530 - mae: 1.7817 - val_loss: 6.4218 - val_mae: 1.7598\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2011 - mae: 1.8453 - val_loss: 6.4415 - val_mae: 1.7609\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.1669 - mae: 1.8082 - val_loss: 6.4556 - val_mae: 1.7704\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.1866 - mae: 1.8427 - val_loss: 6.4817 - val_mae: 1.7448\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.1876 - mae: 1.7737 - val_loss: 6.4296 - val_mae: 1.7611\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.1469 - mae: 1.8137 - val_loss: 6.4284 - val_mae: 1.7785\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.1428 - mae: 1.8177 - val_loss: 6.4697 - val_mae: 1.7579\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.1013 - mae: 1.7987 - val_loss: 6.4749 - val_mae: 1.7544\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0874 - mae: 1.7894 - val_loss: 6.5157 - val_mae: 1.7764\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.0955 - mae: 1.7920 - val_loss: 6.5416 - val_mae: 1.7713\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.1878 - mae: 1.8563 - val_loss: 6.5733 - val_mae: 1.7506\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.1437 - mae: 1.7765 - val_loss: 6.4941 - val_mae: 1.7910\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.5512 - mae: 1.9545\n",
      "Mean Absolute Error on Test Data: 1.9544589519500732\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "R-squared: -0.009238990496981403\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 33.4346 - mae: 3.9628 - val_loss: 14.7649 - val_mae: 2.7534\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 23.9278 - mae: 3.0050 - val_loss: 8.6902 - val_mae: 2.1354\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.2411 - mae: 2.8058 - val_loss: 9.5474 - val_mae: 2.5260\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.7569 - mae: 2.9052 - val_loss: 8.8573 - val_mae: 2.3805\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.4369 - mae: 2.8190 - val_loss: 8.9888 - val_mae: 2.4070\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.3433 - mae: 2.8091 - val_loss: 8.8737 - val_mae: 2.3753\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 17.1922 - mae: 2.8019 - val_loss: 8.8710 - val_mae: 2.3697\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0854 - mae: 2.7906 - val_loss: 8.8796 - val_mae: 2.3676\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0766 - mae: 2.8161 - val_loss: 8.9560 - val_mae: 2.3791\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.0391 - mae: 2.7406 - val_loss: 8.7104 - val_mae: 2.3116\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8695 - mae: 2.7775 - val_loss: 9.1203 - val_mae: 2.4084\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.8788 - mae: 2.7809 - val_loss: 8.8778 - val_mae: 2.3439\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8342 - mae: 2.7292 - val_loss: 8.9186 - val_mae: 2.3503\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.8560 - mae: 2.8089 - val_loss: 8.9316 - val_mae: 2.3510\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.7590 - mae: 2.7159 - val_loss: 8.8793 - val_mae: 2.3344\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6969 - mae: 2.7344 - val_loss: 8.9132 - val_mae: 2.3398\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 16.6976 - mae: 2.7284 - val_loss: 8.7617 - val_mae: 2.2972\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6895 - mae: 2.7508 - val_loss: 9.0754 - val_mae: 2.3732\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6668 - mae: 2.7144 - val_loss: 8.8209 - val_mae: 2.3107\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.6260 - mae: 2.7340 - val_loss: 8.9117 - val_mae: 2.3339\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5733 - mae: 2.7196 - val_loss: 8.8452 - val_mae: 2.3103\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.6835 - mae: 2.6896 - val_loss: 8.7387 - val_mae: 2.2786\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.7537 - mae: 2.7887 - val_loss: 9.0085 - val_mae: 2.3496\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.6075 - mae: 2.6910 - val_loss: 8.8391 - val_mae: 2.3084\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5734 - mae: 2.7485 - val_loss: 9.1085 - val_mae: 2.3700\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5472 - mae: 2.6879 - val_loss: 8.7886 - val_mae: 2.2924\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.5043 - mae: 2.6954 - val_loss: 8.7969 - val_mae: 2.3040\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4971 - mae: 2.7243 - val_loss: 8.8275 - val_mae: 2.3143\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4604 - mae: 2.6854 - val_loss: 8.7112 - val_mae: 2.2858\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.4505 - mae: 2.6810 - val_loss: 8.8927 - val_mae: 2.3295\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4448 - mae: 2.7343 - val_loss: 8.8804 - val_mae: 2.3257\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.5387 - mae: 2.6542 - val_loss: 8.6444 - val_mae: 2.2760\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.5137 - mae: 2.7816 - val_loss: 9.0781 - val_mae: 2.3745\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.4092 - mae: 2.6787 - val_loss: 8.4995 - val_mae: 2.2244\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3492 - mae: 2.6825 - val_loss: 9.0410 - val_mae: 2.3618\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3463 - mae: 2.7356 - val_loss: 8.8252 - val_mae: 2.3089\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 16.3403 - mae: 2.6721 - val_loss: 8.7699 - val_mae: 2.3023\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3148 - mae: 2.7118 - val_loss: 8.8471 - val_mae: 2.3150\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2938 - mae: 2.6872 - val_loss: 8.5734 - val_mae: 2.2500\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2994 - mae: 2.6567 - val_loss: 8.8825 - val_mae: 2.3337\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.3495 - mae: 2.7436 - val_loss: 8.6136 - val_mae: 2.2614\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.3247 - mae: 2.6650 - val_loss: 8.8693 - val_mae: 2.3299\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2735 - mae: 2.6772 - val_loss: 8.8054 - val_mae: 2.3194\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2682 - mae: 2.7489 - val_loss: 8.6385 - val_mae: 2.2763\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 16.2449 - mae: 2.6347 - val_loss: 8.6380 - val_mae: 2.2703\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.2122 - mae: 2.6994 - val_loss: 8.8872 - val_mae: 2.3436\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1972 - mae: 2.6688 - val_loss: 8.6770 - val_mae: 2.2960\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.1125 - mae: 2.6835 - val_loss: 8.7556 - val_mae: 2.3087\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0707 - mae: 2.6714 - val_loss: 8.7628 - val_mae: 2.3172\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.0881 - mae: 2.7012 - val_loss: 8.6840 - val_mae: 2.3009\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.7372 - mae: 2.7291\n",
      "Mean Absolute Error on Test Data: 2.729062795639038\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.0657402429571392\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 14ms/step - loss: 63.0537 - mae: 6.4043 - val_loss: 58.0169 - val_mae: 5.8337\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.4132 - mae: 4.7305 - val_loss: 33.3987 - val_mae: 3.8730\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.4860 - mae: 3.4364 - val_loss: 22.6104 - val_mae: 3.3577\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 21.0912 - mae: 3.5151 - val_loss: 22.5959 - val_mae: 3.2802\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.7849 - mae: 3.3879 - val_loss: 22.6628 - val_mae: 3.2397\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.8201 - mae: 3.3653 - val_loss: 22.4977 - val_mae: 3.2536\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 20.8074 - mae: 3.4486 - val_loss: 22.3688 - val_mae: 3.2726\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 20.8365 - mae: 3.3662 - val_loss: 22.6161 - val_mae: 3.2149\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.7605 - mae: 3.3911 - val_loss: 22.2258 - val_mae: 3.2569\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.7563 - mae: 3.4068 - val_loss: 22.4147 - val_mae: 3.2235\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 20.6730 - mae: 3.3903 - val_loss: 22.2697 - val_mae: 3.2438\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 20.6656 - mae: 3.3885 - val_loss: 22.1716 - val_mae: 3.2439\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.7424 - mae: 3.4491 - val_loss: 22.0632 - val_mae: 3.2744\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.6614 - mae: 3.4251 - val_loss: 22.1076 - val_mae: 3.2519\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.8233 - mae: 3.3763 - val_loss: 22.3472 - val_mae: 3.2198\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 20.7913 - mae: 3.4687 - val_loss: 22.0653 - val_mae: 3.3001\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.6174 - mae: 3.4115 - val_loss: 22.0785 - val_mae: 3.2287\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 20.6136 - mae: 3.4241 - val_loss: 22.1033 - val_mae: 3.2345\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.7998 - mae: 3.3449 - val_loss: 22.3145 - val_mae: 3.2132\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.6535 - mae: 3.4172 - val_loss: 22.0925 - val_mae: 3.2521\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 20.5504 - mae: 3.3928 - val_loss: 22.0501 - val_mae: 3.2431\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.5236 - mae: 3.3984 - val_loss: 22.1102 - val_mae: 3.2258\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.5220 - mae: 3.3852 - val_loss: 22.1121 - val_mae: 3.2230\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.6343 - mae: 3.3577 - val_loss: 22.2030 - val_mae: 3.2304\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.5358 - mae: 3.3749 - val_loss: 22.0809 - val_mae: 3.2377\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.5186 - mae: 3.3706 - val_loss: 22.2150 - val_mae: 3.2186\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.5141 - mae: 3.4051 - val_loss: 22.1011 - val_mae: 3.2556\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.6701 - mae: 3.3463 - val_loss: 22.2982 - val_mae: 3.2201\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.4453 - mae: 3.3863 - val_loss: 22.0575 - val_mae: 3.2469\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 20.4324 - mae: 3.3756 - val_loss: 22.2183 - val_mae: 3.2105\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.4444 - mae: 3.3686 - val_loss: 22.0571 - val_mae: 3.2406\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.4137 - mae: 3.3824 - val_loss: 22.1693 - val_mae: 3.2201\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.5725 - mae: 3.4294 - val_loss: 22.0922 - val_mae: 3.2200\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 20.3977 - mae: 3.3403 - val_loss: 22.2187 - val_mae: 3.2016\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.4591 - mae: 3.3950 - val_loss: 21.9663 - val_mae: 3.2315\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 20.4194 - mae: 3.3512 - val_loss: 21.9995 - val_mae: 3.2297\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.3671 - mae: 3.3643 - val_loss: 21.9930 - val_mae: 3.2235\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.3904 - mae: 3.4178 - val_loss: 22.0164 - val_mae: 3.2432\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 20.4552 - mae: 3.3459 - val_loss: 21.9864 - val_mae: 3.2219\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.2924 - mae: 3.3876 - val_loss: 22.0144 - val_mae: 3.2417\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.3082 - mae: 3.3587 - val_loss: 22.1853 - val_mae: 3.2097\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.3694 - mae: 3.3588 - val_loss: 21.9487 - val_mae: 3.2385\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 20.2425 - mae: 3.3535 - val_loss: 22.1260 - val_mae: 3.2112\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 20.3046 - mae: 3.3752 - val_loss: 21.9132 - val_mae: 3.2434\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 20.2093 - mae: 3.3675 - val_loss: 22.1856 - val_mae: 3.1985\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 20.2393 - mae: 3.3444 - val_loss: 21.8303 - val_mae: 3.2588\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.4953 - mae: 3.4462 - val_loss: 21.8874 - val_mae: 3.2030\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.2411 - mae: 3.3412 - val_loss: 21.9971 - val_mae: 3.2030\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.2013 - mae: 3.3310 - val_loss: 22.0816 - val_mae: 3.2153\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.1804 - mae: 3.3684 - val_loss: 21.8818 - val_mae: 3.2277\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.8240 - mae: 3.2976\n",
      "Mean Absolute Error on Test Data: 3.297578811645508\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "R-squared: 0.056150404586466585\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 137.1941 - mae: 9.6773 - val_loss: 129.2069 - val_mae: 9.4907\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 113.5195 - mae: 8.3821 - val_loss: 98.3045 - val_mae: 7.7603\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 78.5014 - mae: 6.2397 - val_loss: 56.4902 - val_mae: 5.1765\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 46.6680 - mae: 4.3302 - val_loss: 37.0072 - val_mae: 4.4693\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.5343 - mae: 4.6548 - val_loss: 36.7762 - val_mae: 4.4658\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 43.2211 - mae: 4.3705 - val_loss: 37.2591 - val_mae: 4.4056\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.1942 - mae: 4.2906 - val_loss: 36.9445 - val_mae: 4.4071\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 42.8526 - mae: 4.3311 - val_loss: 36.8920 - val_mae: 4.4054\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.7363 - mae: 4.3226 - val_loss: 36.8711 - val_mae: 4.3975\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 42.6488 - mae: 4.3349 - val_loss: 36.8502 - val_mae: 4.3932\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.9175 - mae: 4.2895 - val_loss: 36.8502 - val_mae: 4.3954\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.5406 - mae: 4.3768 - val_loss: 36.7187 - val_mae: 4.4025\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 42.5035 - mae: 4.3706 - val_loss: 36.8570 - val_mae: 4.3903\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 42.4782 - mae: 4.3515 - val_loss: 37.1425 - val_mae: 4.3781\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.3592 - mae: 4.3067 - val_loss: 37.0985 - val_mae: 4.3792\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.5076 - mae: 4.2846 - val_loss: 37.1218 - val_mae: 4.3816\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 42.3049 - mae: 4.3444 - val_loss: 37.0497 - val_mae: 4.3826\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.3547 - mae: 4.3671 - val_loss: 37.0022 - val_mae: 4.3886\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 42.4574 - mae: 4.2783 - val_loss: 37.4438 - val_mae: 4.3772\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.3382 - mae: 4.3741 - val_loss: 36.8698 - val_mae: 4.4143\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.3063 - mae: 4.3092 - val_loss: 37.4062 - val_mae: 4.3789\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.1984 - mae: 4.3665 - val_loss: 36.9621 - val_mae: 4.4087\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 42.8942 - mae: 4.5880 - val_loss: 37.0179 - val_mae: 4.3891\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 43.0763 - mae: 4.2370 - val_loss: 38.1303 - val_mae: 4.3826\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.5523 - mae: 4.4086 - val_loss: 36.8764 - val_mae: 4.4051\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.0136 - mae: 4.3665 - val_loss: 37.5050 - val_mae: 4.3756\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 42.2174 - mae: 4.3145 - val_loss: 37.2899 - val_mae: 4.3804\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.1956 - mae: 4.4087 - val_loss: 37.1711 - val_mae: 4.3884\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.1065 - mae: 4.3641 - val_loss: 37.4242 - val_mae: 4.3797\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.1568 - mae: 4.3574 - val_loss: 37.0617 - val_mae: 4.3924\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.0777 - mae: 4.3446 - val_loss: 37.4589 - val_mae: 4.3822\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 42.0911 - mae: 4.3645 - val_loss: 37.1480 - val_mae: 4.3922\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.0934 - mae: 4.3516 - val_loss: 37.6321 - val_mae: 4.3783\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 42.0829 - mae: 4.2779 - val_loss: 37.2175 - val_mae: 4.3858\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.2557 - mae: 4.4730 - val_loss: 37.2960 - val_mae: 4.3842\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 42.4068 - mae: 4.2614 - val_loss: 37.8390 - val_mae: 4.3788\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.9757 - mae: 4.3123 - val_loss: 37.2095 - val_mae: 4.3948\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.9884 - mae: 4.3901 - val_loss: 37.4919 - val_mae: 4.3848\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.9843 - mae: 4.3382 - val_loss: 37.4269 - val_mae: 4.3863\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 41.9743 - mae: 4.3134 - val_loss: 37.6623 - val_mae: 4.3874\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.0140 - mae: 4.3693 - val_loss: 37.6489 - val_mae: 4.3860\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 42.0075 - mae: 4.2937 - val_loss: 37.5420 - val_mae: 4.3905\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 42.2037 - mae: 4.4439 - val_loss: 37.3169 - val_mae: 4.3862\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 41.9050 - mae: 4.3707 - val_loss: 37.5207 - val_mae: 4.3894\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.9315 - mae: 4.3126 - val_loss: 37.8185 - val_mae: 4.3843\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.9375 - mae: 4.3988 - val_loss: 37.4742 - val_mae: 4.3896\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 42.0136 - mae: 4.3724 - val_loss: 37.7041 - val_mae: 4.3878\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.8877 - mae: 4.3022 - val_loss: 37.5948 - val_mae: 4.3814\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 41.7929 - mae: 4.3372 - val_loss: 37.5639 - val_mae: 4.3816\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.8560 - mae: 4.3951 - val_loss: 37.5564 - val_mae: 4.3816\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.0133 - mae: 4.2962\n",
      "Mean Absolute Error on Test Data: 4.296183109283447\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "R-squared: 0.04280879086442435\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "#merged_all[]\n",
    "# all_in_one    (runtime: 6m 40s (auto), 4m (no GPU), 5m59s (nothing))\n",
    "\n",
    "# gpu deactivate\n",
    "tf.config.set_visible_devices([],'GPU') # 2m 19s\n",
    "\n",
    "# gpu ayarlanmasi\n",
    "#tf.config.set_soft_device_placement(True) # otomatik dogru cihaz kullanimi\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "#tf.config.set_visible_devices(tf.config.list_physical_devices('GPU')[1], 'GPU') # 2. gpu ayari\n",
    "#tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "#tf.config.experimental.set_visible_devices(physical_devices[1], 'GPU')\n",
    "\n",
    "for df in dict_test_merged.values():\n",
    "    df.rename(columns={'bildirimli_sum': 'Bildirimli_sum'}, inplace=True)\n",
    "\n",
    "df = merged_all\n",
    "df_test = dict_test_merged\n",
    "features = ['Bildirimli_sum','Sicaklik','Bayram_Flag','Bagil_nem','Ruzgar_hizi','Yagis',\"Sicaklik_max\", \"Sicaklik_min\",\"Bagil_nem_max\",\n",
    "    \"Bagil_nem_min\",\"Ruzgar_hizi_max\", \"Ruzgar_hizi_min\",\"Yagis_max\", \"Yagis_min\"]\n",
    "features_gun = ['Bildirimli_sum','Sicaklik','Bayram_Flag','Bagil_nem','Ruzgar_hizi','Yagis','Gün',\"Sicaklik_max\", \"Sicaklik_min\",\"Bagil_nem_max\",\n",
    "    \"Bagil_nem_min\",\"Ruzgar_hizi_max\", \"Ruzgar_hizi_min\",\"Yagis_max\", \"Yagis_min\"]\n",
    "features_bayramsiz = ['Bildirimli_sum','Sicaklik','Bagil_nem','Ruzgar_hizi','Yagis',\"Sicaklik_max\", \"Sicaklik_min\",\"Bagil_nem_max\",\n",
    "    \"Bagil_nem_min\",\"Ruzgar_hizi_max\", \"Ruzgar_hizi_min\",\"Yagis_max\", \"Yagis_min\"]\n",
    "features_output = ['Bildirimli_sum','Bildirimsiz_sum','Sicaklik','Bayram_Flag','Bagil_nem','Ruzgar_hizi','Yagis',\"Sicaklik_max\", \"Sicaklik_min\",\"Bagil_nem_max\",\n",
    "    \"Bagil_nem_min\",\"Ruzgar_hizi_max\", \"Ruzgar_hizi_min\",\"Yagis_max\", \"Yagis_min\"]\n",
    "output_var = df\n",
    "target = 'Bildirimsiz_sum'\n",
    "# ilceler = []\n",
    "\n",
    "# NN 3\n",
    "# ilceler = ['izmir-konak','izmir-kinik']\n",
    "all_submissions = []\n",
    "for ilce in ilceler:\n",
    "    df = merged_all[ilce]\n",
    "    df_test = dict_test_merged[ilce]\n",
    "    output_var = df['Bildirimsiz_sum']\n",
    "\n",
    "    # ilcelerin numerizasyonu\n",
    "    columns_tonumerate = ['Bayram_Flag']\n",
    "    for column in columns_tonumerate:\n",
    "        encoder = LabelEncoder()\n",
    "        df[column] = encoder.fit_transform(df[column])\n",
    "\n",
    "    # test csv dosyasi numerizasyon\n",
    "    for column in columns_tonumerate:\n",
    "        encoder = LabelEncoder()\n",
    "        df_test[column] = encoder.fit_transform(df_test[column])\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    feature_transform = scaler.fit_transform(df[features])\n",
    "    feature_transform = pd.DataFrame(columns=features, data=feature_transform, index=df.index)\n",
    "    feature_transform_gun = scaler.fit_transform(df[features_gun])\n",
    "    feature_transform_gun = pd.DataFrame(columns=features_gun, data=feature_transform_gun, index=df.index)\n",
    "    scaler2 = MinMaxScaler()\n",
    "    feature_test = scaler2.fit_transform(df_test[features])\n",
    "    feature_test = pd.DataFrame(columns=features, data=feature_test, index=df_test.index)\n",
    "\n",
    "\n",
    "    #with strategy.scope(): # strategy ayarlamasi\n",
    "    X = feature_transform\n",
    "    y = output_var\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=53)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(14,)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='mean_squared_error',\n",
    "                metrics=['mae'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.3)\n",
    "\n",
    "    loss, mae = model.evaluate(X_test, y_test)\n",
    "    print(\"Mean Absolute Error on Test Data:\", mae)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    r2 = metrics.r2_score(y_test, predictions)\n",
    "    print(\"R-squared:\", r2)\n",
    "\n",
    "    predictions_new = model.predict(feature_test)\n",
    "    predictions_new = np.round(predictions_new).astype(int)\n",
    "    df_test['bildirimsiz_sum'] = predictions_new\n",
    "    df_test.to_csv('test_with_predictions.csv', index=False)\n",
    "\n",
    "    df_test.rename(columns={'Ilce': 'ilce'}, inplace=True)\n",
    "    df_test.rename(columns={'Tarih': 'tarih'}, inplace=True)\n",
    "    df_test.rename(columns={'Bildirimli_sum': 'bildirimli_sum'}, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    all_submissions.append(df_test)\n",
    "#Mean Absolute Error on Test Data: 1.9544589519500732"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bildirimsiz_sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\okkes\\anaconda3\\envs\\pyokkes\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'bildirimsiz_sum'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m df_test \u001b[38;5;241m=\u001b[39m test \u001b[38;5;66;03m#test csv birlestirilmis hazir dosyasi\u001b[39;00m\n\u001b[0;32m      4\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbildirimli_sum\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msicaklik vs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#kalan ozellikler de yazilmali\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m output_var \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbildirimsiz_sum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbildirimsiz_sum\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m ilceler \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\okkes\\anaconda3\\envs\\pyokkes\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\okkes\\anaconda3\\envs\\pyokkes\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'bildirimsiz_sum'"
     ]
    }
   ],
   "source": [
    "#merged_all[]\n",
    "df = merged_all['izmir-konak'] #ml icin hazir csv dosyasi\n",
    "df_test = test #test csv birlestirilmis hazir dosyasi\n",
    "features = ['bildirimli_sum','sicaklik vs'] #kalan ozellikler de yazilmali\n",
    "output_var = df['bildirimsiz_sum']\n",
    "target = 'bildirimsiz_sum'\n",
    "ilceler = []\n",
    "\n",
    "dict = {}\n",
    "for label, group in train.groupby(\"ilce\"):\n",
    "    dict[label] = group\n",
    "ilceler = list(dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ilcelerin numerizasyonu -------- NEW olmasa da direkt sayilar olsa daha iyi olabilir\n",
    "columns_tonumerate = ['ilce','BAYRAM_FLAG','vs vs.']\n",
    "for column in columns_tonumerate:\n",
    "    encoder = LabelEncoder()\n",
    "    encode = encoder.fit_transform(df[column])\n",
    "    df[column + '_NEW'] = encode #buraya _NEW eklemeli miyim tekrar bakmak gerek\n",
    "    df.drop(columns=[column], inplace=True)\n",
    "\n",
    "# csv dosyasi numerizasyon - sadece numarizasyon degil ayni zamanda weather ile birlestirme de yapilmali!!\n",
    "for column in columns_tonumerate:\n",
    "    encoder = LabelEncoder()\n",
    "    encode = encoder.fit_transform(df_test[column])\n",
    "    df_test[column + '_NEW'] = encode\n",
    "    df_test.drop(columns=[column], inplace=True)\n",
    "\n",
    "#Scaling\n",
    "scaler = MinMaxScaler()\n",
    "feature_transform = scaler.fit_transform(df[features])\n",
    "feature_transform = pd.DataFrame(columns=features, data=feature_transform, index=df.index)\n",
    "feature_transform.head()\n",
    "\n",
    "\n",
    "# test.csv numerizasyonu da gerekiyor ayni sekilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-y test-train elde edimi\n",
    "x = df[features]\n",
    "y = output_var # = df[\"target_var\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=53, shuffle=True)\n",
    "\n",
    "#Splitting to Training set and Test set --- burasi timeseries icin split\n",
    "timesplit = TimeSeriesSplit(n_splits=15)\n",
    "for train_index, test_index in timesplit.split(feature_transform):\n",
    "        X_tr, X_te = feature_transform[:len(train_index)], feature_transform[len(train_index): (len(train_index)+len(test_index))]\n",
    "        y_tr, y_te = output_var[:len(train_index)].values.ravel(), output_var[len(train_index): (len(train_index)+len(test_index))].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "#Process the data for LSTM\n",
    "trainX = np.array(X_tr)\n",
    "testX = np.array(X_te)\n",
    "X_tr = trainX.reshape(X_tr.shape[0], 1, X_tr.shape[1])\n",
    "X_te = testX.reshape(X_te.shape[0], 1, X_te.shape[1])\n",
    "\n",
    "#Building the LSTM Model\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(32, input_shape=(1, trainX.shape[1]), activation='relu', return_sequences=False))\n",
    "lstm.add(Dense(1))\n",
    "lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "#Model Training\n",
    "history=lstm.fit(X_tr, y_tr, epochs=100, batch_size=8, verbose=1, shuffle=False)\n",
    "\n",
    "#LSTM Prediction\n",
    "y_pr= lstm.predict(X_te)\n",
    "\n",
    "# Predicted vs True Adj Close Value – LSTM  --burasi copy paste\n",
    "plt.plot(y_te, label='True Value')\n",
    "plt.plot(y_pr, label='LSTM Value')\n",
    "plt.title(\"Prediction by LSTM\")\n",
    "plt.xlabel('Time Scale')\n",
    "plt.ylabel('Scaled USD')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# test_pred = lstm.predict(gercek test)\n",
    "# csv ye yazdir vs vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "X = df[features].values()\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=53, shuffle=True)\n",
    "\n",
    "k=17\n",
    "neigh = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "y_hat = neigh.predict(X_test)\n",
    "\n",
    "test_accuracy = neigh.score(X_test, y_test)\n",
    "\n",
    "print(\"Test accuracy with class weights:\", test_accuracy)\n",
    "print(\"egitim verisi dogrulugu \", metrics.accuracy_score(y_train,neigh.predict(X_train)))\n",
    "print(\"test verisi dogrulugu \", metrics.accuracy_score(y_test,y_hat))\n",
    "\n",
    "# test tahmin\n",
    "y_hat = neigh.predict(isteburayatestdosyasi)\n",
    "submission = pd.read_csv(\"sample_submission.csv\", low_memory=False)\n",
    "submission.iloc[:, 1] = y_hat\n",
    "# submission.to_csv(\"knnsubmission.csv\", index=False)\n",
    "\n",
    "# optimal k degeri\n",
    "\n",
    "# # Define the range of k values to try\n",
    "# k_values = range(1, 21)\n",
    "\n",
    "# # Perform cross-validation for each value of k\n",
    "# cv_scores = []\n",
    "# for k in k_values:\n",
    "#     neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "#     scores = cross_val_score(neigh, X_train, y_train, cv=5)\n",
    "#     cv_scores.append(scores.mean())\n",
    "\n",
    "# # Find the optimal value of k with the highest cross-validation score\n",
    "# optimal_k = k_values[cv_scores.index(max(cv_scores))]\n",
    "# print(\"Optimal k:\", optimal_k)\n",
    "\n",
    "# # Train the model with the optimal k value\n",
    "# neigh = KNeighborsClassifier(n_neighbors=optimal_k).fit(X_train, y_train)\n",
    "# test_accuracy = neigh.score(X_test, y_test)\n",
    "# print(\"Test accuracy with optimal k:\", test_accuracy)\n",
    "# print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN\n",
    "# alinan kaynakta goruntu isleme icin kullaniliyordu bazi uyusmazliklar olabilir\n",
    "# Cast the records into float values \n",
    "# x_train = x_train.astype('float32') \n",
    "# x_test = x_test.astype('float32') \n",
    "\n",
    "print(\"Feature matrix:\", x_train.shape) \n",
    "print(\"Target matrix:\", x_test.shape) \n",
    "print(\"Feature matrix:\", y_train.shape) \n",
    "print(\"Target matrix:\", y_test.shape)  \n",
    "model = Sequential([ \n",
    "    Flatten(input_shape=(x_train.shape)), \n",
    "    \n",
    "    # dense layer 1 \n",
    "    Dense(256, activation='sigmoid'),   \n",
    "    \n",
    "    # dense layer 2 \n",
    "    Dense(128, activation='sigmoid'),  \n",
    "    \n",
    "    # output layer \n",
    "    Dense(10, activation='sigmoid'),   \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.fit(x_train, y_train, epochs=10,  \n",
    "          batch_size=2000,  \n",
    "          validation_split=0.2)\n",
    "\n",
    "results = model.evaluate(x_test,  y_test, verbose = 0) \n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential() specifies that the network is a linear stack of layers\n",
    "\n",
    "model.add() adds the hidden layer.\n",
    "\n",
    "Dense means that neurons between layers are fully connected\n",
    "\n",
    "input_dim defines the number of features in the training dataset\n",
    "\n",
    "activation defines the activation function\n",
    "\n",
    "loss selects the cost function\n",
    "\n",
    "optimizer selects the learning algorithm\n",
    "\n",
    "metrics selects the performance metrics to be saved for further analysis\n",
    "\n",
    "model.fit() initialize the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN2\n",
    "\n",
    "X = df[features] #features\n",
    "y = df['target_var'] #expected values\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy', 'mean_squared_error'])\n",
    "\n",
    "history = model.fit(X, y, epochs=3000, verbose=0)\n",
    "\n",
    "y_pred = model.predict(X).round()\n",
    "num_correct_predictions = (y_pred == y).sum()\n",
    "accuracy = (num_correct_predictions / y.shape[0]) * 100\n",
    "print('Multi-layer perceptron accuracy: %.2f%%' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
