{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    Her ilce icin esit sayida veri yok. Bu sayilar ilce_tarih_sayilari degiskeninde tutulu.\\n\\n    Yapilmasi gerekenler:\\n        - Weather'daki verileri gunluge cevir. ++++\\n        - Her ilce icin hava durumu verilerini(bir gun icin ortalama alaraktan), tarihleri, tatil_flag'lari\\n        kesinti sayilarini tutan bir DataFrame olustur. ++++\\n        - Kesinti sayilarinin tarihe bagli ayri ayri grafiklerini cikart. (veya beraber de olabilir)\\n        - Hava kosullarindan iyi, orta, kotu, cok kotu gibi bir bilgi cikartmaya calis. Belki burada yapay zeka\\n        kullanabilirsin. orda bir formül belirlemek lazim ona göre siniflandirilir.\\n        \\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -1-) Notlar\n",
    "\"\"\"\n",
    "    Her ilce icin esit sayida veri yok. Bu sayilar ilce_tarih_sayilari degiskeninde tutulu.\n",
    "\n",
    "    Yapilmasi gerekenler:\n",
    "        - Weather'daki verileri gunluge cevir. ++++\n",
    "        - Her ilce icin hava durumu verilerini(bir gun icin ortalama alaraktan), tarihleri, tatil_flag'lari\n",
    "        kesinti sayilarini tutan bir DataFrame olustur. ++++\n",
    "        - Kesinti sayilarinin tarihe bagli ayri ayri grafiklerini cikart. (veya beraber de olabilir)\n",
    "        - Hava kosullarindan iyi, orta, kotu, cok kotu gibi bir bilgi cikartmaya calis. Belki burada yapay zeka\n",
    "        kullanabilirsin. orda bir formül belirlemek lazim ona göre siniflandirilir.\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-) Import required moduls and libraries\n",
    "\n",
    "# bildirimisiz_sum tahmin edilecek\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import math\n",
    "import os\n",
    "from unidecode import unidecode # to convert Turkish characters to English\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Flatten \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Activation\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['izmir-aliaga', 'izmir-balcova', 'izmir-bayindir', 'izmir-bayrakli', 'izmir-bergama', 'izmir-beydag', 'izmir-bornova', 'izmir-buca', 'izmir-cesme', 'izmir-cigli', 'izmir-dikili', 'izmir-foca', 'izmir-gaziemir', 'izmir-guzelbahce', 'izmir-karabaglar', 'izmir-karaburun', 'izmir-karsiyaka', 'izmir-kemalpasa', 'izmir-kinik', 'izmir-kiraz', 'izmir-konak', 'izmir-menderes', 'izmir-menemen', 'izmir-narlidere', 'izmir-odemis', 'izmir-seferihisar', 'izmir-selcuk', 'izmir-tire', 'izmir-torbali', 'izmir-urla', 'manisa-ahmetli', 'manisa-akhisar', 'manisa-alasehir', 'manisa-demirci', 'manisa-golmarmara', 'manisa-gordes', 'manisa-kirkagac', 'manisa-koprubasi', 'manisa-kula', 'manisa-salihli', 'manisa-sarigol', 'manisa-saruhanli', 'manisa-sehzadeler', 'manisa-selendi', 'manisa-soma', 'manisa-turgutlu', 'manisa-yunusemre'])\n"
     ]
    }
   ],
   "source": [
    "# 1-) read and preproccess train.csv\n",
    "train = pd.read_csv(\"./train.csv\", low_memory=False) # 46.944 satir, 4 kolon\n",
    "\n",
    "# print(train) # 1.098 farkli tarih var, 47 farkli ilce var\n",
    "\n",
    "tarihler = []\n",
    "for i in train[\"tarih\"]:\n",
    "    tarihler.append(datetime.strptime(i, \"%Y-%m-%d\"))\n",
    "train[\"tarih\"] = tarihler\n",
    "\n",
    "# print(train.dtypes)\n",
    "\n",
    "dict = {}\n",
    "for label, group in train.groupby(\"ilce\"):\n",
    "    dict[label] = group\n",
    "\n",
    "ilceler = (list(dict.keys()))\n",
    "print(dict.keys()) # keys olarak her ilceyi, values olarak o ilcelerin bulundugu satirlari icerir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'izmir-aliaga': 1078, 'izmir-balcova': 681, 'izmir-bayindir': 1078, 'izmir-bayrakli': 1059, 'izmir-bergama': 1092, 'izmir-beydag': 658, 'izmir-bornova': 1096, 'izmir-buca': 1087, 'izmir-cesme': 1097, 'izmir-cigli': 1044, 'izmir-dikili': 1091, 'izmir-foca': 1058, 'izmir-gaziemir': 898, 'izmir-guzelbahce': 835, 'izmir-karabaglar': 1072, 'izmir-karaburun': 1063, 'izmir-karsiyaka': 1057, 'izmir-kemalpasa': 1091, 'izmir-kinik': 889, 'izmir-kiraz': 1069, 'izmir-konak': 1096, 'izmir-menderes': 1097, 'izmir-menemen': 1091, 'izmir-narlidere': 758, 'izmir-odemis': 1096, 'izmir-seferihisar': 1086, 'izmir-selcuk': 853, 'izmir-tire': 1079, 'izmir-torbali': 1096, 'izmir-urla': 1094, 'manisa-ahmetli': 600, 'manisa-akhisar': 1098, 'manisa-alasehir': 1091, 'manisa-demirci': 918, 'manisa-golmarmara': 555, 'manisa-gordes': 1033, 'manisa-kirkagac': 925, 'manisa-koprubasi': 781, 'manisa-kula': 1013, 'manisa-salihli': 1098, 'manisa-sarigol': 1000, 'manisa-saruhanli': 1079, 'manisa-sehzadeler': 1095, 'manisa-selendi': 971, 'manisa-soma': 1058, 'manisa-turgutlu': 1093, 'manisa-yunusemre': 1097}\n"
     ]
    }
   ],
   "source": [
    "# 2-) extract ilce and keep preprocessing train.csv\n",
    "\"\"\"\n",
    "for label in dict.keys(): # her ilce icin bildirimsiz ve bildirimli olarak grafiklerini cikart\n",
    "    print(dict[label][\"bildirimsiz_sum\"])\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.bar(dict[label][\"tarih\"],dict[label][\"bildirimsiz_sum\"])\n",
    "    plt.title(label)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.bar(dict[\"izmir-konak\"][\"tarih\"],dict[\"izmir-konak\"][\"bildirimsiz_sum\"])\n",
    "plt.title(label)\n",
    "plt.margins(0.01)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# ilce tarih sayilarini al hepsinde esit veri yok\n",
    "ilce_tarih_sayilari = {}\n",
    "for name in dict.keys():\n",
    "    ilce_tarih_sayilari[name] = len(list(dict[name][\"tarih\"].to_dict().values()))\n",
    "\n",
    "print(ilce_tarih_sayilari)\n",
    "for name in dict.keys():\n",
    "    dict[name].set_index(\"tarih\", inplace=True)\n",
    "\n",
    "# train.set_index(\"tarih\", inplace=True) # train'in tarih kolonunu indexe cevir\n",
    "# print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'lat', 'lon', 't_2m:C', 'effective_cloud_cover:p',\n",
      "       'global_rad:W', 'relative_humidity_2m:p', 'wind_dir_10m:d',\n",
      "       'wind_speed_10m:ms', 'prob_precip_1h:p', 't_apparent:C', 'ilce'],\n",
      "      dtype='object')\n",
      "bitti\n"
     ]
    }
   ],
   "source": [
    "# 3-) read and preprocess weather.csv\n",
    "\n",
    "weather = pd.read_csv(\"./weather.csv\", low_memory=False)\n",
    "print(weather.columns) # onemli kolonlar: date, t_apparent:C (hissedilen sicaklik), wind_dir_10m:d (ruzgar yonu),\n",
    "# wind_speed_10m:ms (ruzgar hizi), prob_precip_1h:p (yagis), ilce\n",
    "\n",
    "# ilceleri ayir\n",
    "ilce_weather = {} # keys olarak ilceleri, values olarak o ilcelerin saatlik hava durumklarini tutar\n",
    "for label, group in weather.groupby(\"ilce\"):\n",
    "    ilce_weather[label] = group\n",
    "\n",
    "\n",
    "# tarihleri tarih formatina cevir\n",
    "#print(ilce_weather[\"izmir-konak\"].dtypes)\n",
    "for name in ilce_weather.keys():\n",
    "    tarihler = []\n",
    "    for date in ilce_weather[name][\"date\"]:\n",
    "        tarihler.append(datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\"))\n",
    "    ilce_weather[name][\"date\"] = tarihler\n",
    "# print(\"bitti\")\n",
    "#print(ilce_weather[\"izmir-konak\"].dtypes)\n",
    "\n",
    "\n",
    "# tarihleri indexe cevir\n",
    "# for name in ilce_weather.keys():\n",
    "    # ilce_weather[name].set_index(\"date\", inplace=True)\n",
    "\n",
    "\n",
    "# tarhileri gun olarak birlestir\n",
    "# for name in ilce_weather.keys():\n",
    "    # ilce_weather[name] = ilce_weather[name].resample(\"D\").mean()\n",
    "# print(ilce_weather[\"izmir-konak\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Bayram_Flag      Tarih\n",
      "0                                  Yılbaşı 2021-01-01\n",
      "1        Ulusal Egemenlik ve Çocuk Bayramı 2021-04-23\n",
      "2                   Emek ve Dayanışma Günü 2021-05-01\n",
      "3  Atatürk'ü Anma, Gençlik ve Spor Bayramı 2021-05-19\n",
      "4           Demokrasi ve Millî Birlik Günü 2021-07-15\n"
     ]
    }
   ],
   "source": [
    "# 4-) read and preprocess holidays.csv\n",
    "\n",
    "holiday = pd.read_csv(\"./holidays.csv\", low_memory=False)\n",
    "\n",
    "# print(holiday.head())\n",
    "\n",
    "holiday[\"Tarih\"] = holiday['Yıl'].astype(str) + '-' + holiday['Ay'].astype(str) + '-' + holiday['Gün'].astype(str)\n",
    "holiday['Tarih'] = pd.to_datetime(holiday['Tarih'], format='%Y-%m-%d')\n",
    "# holiday.set_index(\"Tarih\", inplace=True)\n",
    "holiday = holiday.drop(columns=[\"Yıl\", \"Ay\", \"Gün\"])\n",
    "\n",
    "print(holiday.head()) # index olarak tarihi (YY-AA-GG), Bayram_Flag olarak da bayram ismini tutar\n",
    "# print(holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            ilce  bildirimsiz_sum  bildirimli_sum Bayram_Flag\n",
      "tarih                                                                        \n",
      "2021-01-01 00:00:00  izmir-konak                9               0         NaN\n",
      "2021-01-02 00:00:00  izmir-konak                5               0         NaN\n",
      "2021-01-03 00:00:00  izmir-konak                5               0         NaN\n",
      "2021-01-04 00:00:00  izmir-konak               11               0         NaN\n",
      "2021-01-05 00:00:00  izmir-konak               11               0         NaN\n",
      "...                          ...              ...             ...         ...\n",
      "2023-12-30 00:00:00  izmir-konak               10               1         NaN\n",
      "2023-12-31 00:00:00  izmir-konak                9               0         NaN\n",
      "2024-01-01 00:00:00  izmir-konak               11               0         NaN\n",
      "2024-01-02 00:00:00  izmir-konak                9               1         NaN\n",
      "2024-01-03 00:00:00  izmir-konak                8               1         NaN\n",
      "\n",
      "[1096 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 5-) merge the train data and holidays, return a new dict called dict_holiday\n",
    "\n",
    "def merge_holiday(df1, df2):\n",
    "    merged_df = pd.merge(df1, df2[\"Bayram_Flag\"], left_index=True, right_index=True, how=\"left\")\n",
    "    #df1[\"Bayramlar\"] = df2[\"Bayram_Flag\"]\n",
    "    return merged_df\n",
    "\n",
    "dict_holiday = {}\n",
    "for name in dict.keys():\n",
    "    dict_holiday[name] = merge_holiday(dict[name],holiday)\n",
    "    \n",
    "print(dict_holiday[\"izmir-konak\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          ilce_x  bildirimsiz_sum  bildirimli_sum Bayram_Flag  \\\n",
      "tarih                                                                           \n",
      "2021-01-01 00:00:00  izmir-konak                9               0         NaN   \n",
      "2021-01-02 00:00:00  izmir-konak                5               0         NaN   \n",
      "2021-01-03 00:00:00  izmir-konak                5               0         NaN   \n",
      "2021-01-04 00:00:00  izmir-konak               11               0         NaN   \n",
      "2021-01-05 00:00:00  izmir-konak               11               0         NaN   \n",
      "\n",
      "                    date  lat  lon  t_2m:C  effective_cloud_cover:p  \\\n",
      "tarih                                                                 \n",
      "2021-01-01 00:00:00  NaT  NaN  NaN     NaN                      NaN   \n",
      "2021-01-02 00:00:00  NaT  NaN  NaN     NaN                      NaN   \n",
      "2021-01-03 00:00:00  NaT  NaN  NaN     NaN                      NaN   \n",
      "2021-01-04 00:00:00  NaT  NaN  NaN     NaN                      NaN   \n",
      "2021-01-05 00:00:00  NaT  NaN  NaN     NaN                      NaN   \n",
      "\n",
      "                     global_rad:W  relative_humidity_2m:p  wind_dir_10m:d  \\\n",
      "tarih                                                                       \n",
      "2021-01-01 00:00:00           NaN                     NaN             NaN   \n",
      "2021-01-02 00:00:00           NaN                     NaN             NaN   \n",
      "2021-01-03 00:00:00           NaN                     NaN             NaN   \n",
      "2021-01-04 00:00:00           NaN                     NaN             NaN   \n",
      "2021-01-05 00:00:00           NaN                     NaN             NaN   \n",
      "\n",
      "                     wind_speed_10m:ms  prob_precip_1h:p  t_apparent:C ilce_y  \n",
      "tarih                                                                          \n",
      "2021-01-01 00:00:00                NaN               NaN           NaN    NaN  \n",
      "2021-01-02 00:00:00                NaN               NaN           NaN    NaN  \n",
      "2021-01-03 00:00:00                NaN               NaN           NaN    NaN  \n",
      "2021-01-04 00:00:00                NaN               NaN           NaN    NaN  \n",
      "2021-01-05 00:00:00                NaN               NaN           NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "# 5-) merge the dict_holiday and weather, return merged_all which contains all of the required columns\n",
    "\n",
    "def merge_weather(df1, df2):\n",
    "    merged_df = pd.merge(df1, df2, left_index=True, right_index=True, how=\"left\")\n",
    "    return merged_df\n",
    "\n",
    "merged_all = {} # key olarak tum ilceler, values olarak kesintiler, bayramlar, hava durumu verilerini tutan df'i tutar\n",
    "for name in dict_holiday.keys():\n",
    "    merged_all[name] = merge_weather(dict_holiday[name], ilce_weather[name])\n",
    "print(merged_all[\"izmir-konak\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKINE OGRENMESI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = #ml icin hazir csv dosyasi\n",
    "df_test = #test csv birlestirilmis hazir dosyasi\n",
    "features = ['bildirimli_sum','sicaklik vs']\n",
    "output_var = df['bildirimsiz_sum']\n",
    "target = 'bildirimsiz_sum'\n",
    "ilceler = []\n",
    "\n",
    "dict = {}\n",
    "for label, group in train.groupby(\"ilce\"):\n",
    "    dict[label] = group\n",
    "ilceler = list(dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ilcelerin numerizasyonu -------- NEW olmasa da direkt sayilar olsa daha iyi olabilir\n",
    "columns_tonumerate = ['ilce','BAYRAM_FLAG','vs vs.']\n",
    "for column in columns_tonumerate:\n",
    "    encoder = LabelEncoder()\n",
    "    encode = encoder.fit_transform(df[column])\n",
    "    df[column + '_NEW'] = encode\n",
    "    df.drop(columns=[column], inplace=True)\n",
    "\n",
    "# test dosyasi numerizasyon - sadece numarizasyon degil ayni zamanda weather ile birlestirme de yapilmali!!\n",
    "for column in columns_tonumerate:\n",
    "    encoder = LabelEncoder()\n",
    "    encode = encoder.fit_transform(df_test[column])\n",
    "    df_test[column + '_NEW'] = encode\n",
    "    df_test.drop(columns=[column], inplace=True)\n",
    "\n",
    "#Scaling\n",
    "scaler = MinMaxScaler()\n",
    "feature_transform = scaler.fit_transform(df[features])\n",
    "feature_transform = pd.DataFrame(columns=features, data=feature_transform, index=df.index)\n",
    "feature_transform.head()\n",
    "\n",
    "\n",
    "# test.csv numerizasyonu da gerekiyor ayni sekilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-y test-train elde edimi\n",
    "x = df[features]\n",
    "y = output_var # = df[\"target_var\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=53, shuffle=True)\n",
    "\n",
    "#Splitting to Training set and Test set\n",
    "timesplit = TimeSeriesSplit(n_splits=15)\n",
    "for train_index, test_index in timesplit.split(feature_transform):\n",
    "        X_tr, X_te = feature_transform[:len(train_index)], feature_transform[len(train_index): (len(train_index)+len(test_index))]\n",
    "        y_tr, y_te = output_var[:len(train_index)].values.ravel(), output_var[len(train_index): (len(train_index)+len(test_index))].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "#Process the data for LSTM\n",
    "trainX = np.array(X_tr)\n",
    "testX = np.array(X_te)\n",
    "X_tr = trainX.reshape(X_tr.shape[0], 1, X_tr.shape[1])\n",
    "X_te = testX.reshape(X_te.shape[0], 1, X_te.shape[1])\n",
    "\n",
    "#Building the LSTM Model\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(32, input_shape=(1, trainX.shape[1]), activation='relu', return_sequences=False))\n",
    "lstm.add(Dense(1))\n",
    "lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "#Model Training\n",
    "history=lstm.fit(X_tr, y_tr, epochs=100, batch_size=8, verbose=1, shuffle=False)\n",
    "\n",
    "#LSTM Prediction\n",
    "y_pr= lstm.predict(X_te)\n",
    "\n",
    "# Predicted vs True Adj Close Value – LSTM\n",
    "plt.plot(y_te, label='True Value')\n",
    "plt.plot(y_pr, label='LSTM Value')\n",
    "plt.title(\"Prediction by LSTM\")\n",
    "plt.xlabel('Time Scale')\n",
    "plt.ylabel('Scaled USD')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# test_pred = lstm.predict(gercek test)\n",
    "# csv ye yazdir vs vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "X = df[features].values()\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=53, shuffle=True)\n",
    "\n",
    "k=17\n",
    "neigh = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "y_hat = neigh.predict(X_test)\n",
    "\n",
    "test_accuracy = neigh.score(X_test, y_test)\n",
    "\n",
    "print(\"Test accuracy with class weights:\", test_accuracy)\n",
    "print(\"egitim verisi dogrulugu \", metrics.accuracy_score(y_train,neigh.predict(X_train)))\n",
    "print(\"test verisi dogrulugu \", metrics.accuracy_score(y_test,y_hat))\n",
    "\n",
    "# test tahmin\n",
    "y_hat = neigh.predict(isteburayatestdosyasi)\n",
    "submission = pd.read_csv(\"sample_submission.csv\", low_memory=False)\n",
    "submission.iloc[:, 1] = y_hat\n",
    "# submission.to_csv(\"knnsubmission.csv\", index=False)\n",
    "\n",
    "# optimal k degeri\n",
    "\n",
    "# # Define the range of k values to try\n",
    "# k_values = range(1, 21)\n",
    "\n",
    "# # Perform cross-validation for each value of k\n",
    "# cv_scores = []\n",
    "# for k in k_values:\n",
    "#     neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "#     scores = cross_val_score(neigh, X_train, y_train, cv=5)\n",
    "#     cv_scores.append(scores.mean())\n",
    "\n",
    "# # Find the optimal value of k with the highest cross-validation score\n",
    "# optimal_k = k_values[cv_scores.index(max(cv_scores))]\n",
    "# print(\"Optimal k:\", optimal_k)\n",
    "\n",
    "# # Train the model with the optimal k value\n",
    "# neigh = KNeighborsClassifier(n_neighbors=optimal_k).fit(X_train, y_train)\n",
    "# test_accuracy = neigh.score(X_test, y_test)\n",
    "# print(\"Test accuracy with optimal k:\", test_accuracy)\n",
    "# print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN\n",
    "# alinan kaynakta goruntu isleme icin kullaniliyordu bazi uyusmazliklar olabilir\n",
    "# Cast the records into float values \n",
    "# x_train = x_train.astype('float32') \n",
    "# x_test = x_test.astype('float32') \n",
    "\n",
    "print(\"Feature matrix:\", x_train.shape) \n",
    "print(\"Target matrix:\", x_test.shape) \n",
    "print(\"Feature matrix:\", y_train.shape) \n",
    "print(\"Target matrix:\", y_test.shape)  \n",
    "model = Sequential([ \n",
    "    Flatten(input_shape=(x_train.shape)), \n",
    "    \n",
    "    # dense layer 1 \n",
    "    Dense(256, activation='sigmoid'),   \n",
    "    \n",
    "    # dense layer 2 \n",
    "    Dense(128, activation='sigmoid'),  \n",
    "    \n",
    "    # output layer \n",
    "    Dense(10, activation='sigmoid'),   \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.fit(x_train, y_train, epochs=10,  \n",
    "          batch_size=2000,  \n",
    "          validation_split=0.2)\n",
    "\n",
    "results = model.evaluate(x_test,  y_test, verbose = 0) \n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential() specifies that the network is a linear stack of layers\n",
    "\n",
    "model.add() adds the hidden layer.\n",
    "\n",
    "Dense means that neurons between layers are fully connected\n",
    "\n",
    "input_dim defines the number of features in the training dataset\n",
    "\n",
    "activation defines the activation function\n",
    "\n",
    "loss selects the cost function\n",
    "\n",
    "optimizer selects the learning algorithm\n",
    "\n",
    "metrics selects the performance metrics to be saved for further analysis\n",
    "\n",
    "model.fit() initialize the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN2\n",
    "\n",
    "X = df[features] #features\n",
    "y = df['target_var'] #expected values\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy', 'mean_squared_error'])\n",
    "\n",
    "history = model.fit(X, y, epochs=3000, verbose=0)\n",
    "\n",
    "y_pred = model.predict(X).round()\n",
    "num_correct_predictions = (y_pred == y).sum()\n",
    "accuracy = (num_correct_predictions / y.shape[0]) * 100\n",
    "print('Multi-layer perceptron accuracy: %.2f%%' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
